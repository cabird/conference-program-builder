[
    {
        "object": "paper",
        "pid": 4,
        "title": "LeakPair: Proactive Repairing of Memory Leaks in Single Page Web Applications",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-529a3f969757c73e4d295e2878c6af7a891127389752c32342be482a5c74afa5",
            "timestamp": 1683374135,
            "size": 821291,
            "pages": 12
        },
        "abstract": "Modern web applications often resort to application development frameworks such as React, Vue.js, and Angular. While the frameworks facilitate the development of web applications with several useful components, they are inevitably vulnerable to unmanaged memory consumption since the frameworks often produce Single Page Applications (SPAs). Web applications can be alive for hours and days with behavior loops, in such cases, even a single memory leak in a SPA app can cause performance degradation on the client side. However, recent debugging techniques for web applications still focus on memory leak detection, which requires manual tasks and produces imprecise results.\r\n\r\nWe propose LeakPair, a technique to repair memory leaks in single page applications. Given the insight that memory leaks are mostly non-functional bugs and fixing them might not change the behavior of an application, the technique is designed to proactively generate patches to fix memory leaks, without leak detection, which is often heavy and tedious. To generate effective patches, LeakPair follows the idea of pattern-based program repair since the automated repair strategy shows successful results in many recent studies. We evaluate the technique on more than 20 open-source projects without using explicit leak detection. The patches generated by our technique are also submitted to the projects as pull requests. The results show that LeakPair can generate effective patches to reduce memory consumption that are acceptable to developers. In addition, we execute the test suites given by the projects after applying the patches, and it turns out that the patches do not cause any functionality breakage; this might imply that LeakPair can generate non-intrusive patches for memory leaks.",
        "authors": [
            {
                "email": "arooba.shahoor@gmail.com",
                "first": "Arooba",
                "last": "Shahoor",
                "affiliation": "Kyungpook National University",
                "contact": true
            },
            {
                "email": "KHAMIT.ASKAR@UNIST.AC.KR",
                "first": "ASKAR YELTAYULY",
                "last": "KHAMIT",
                "affiliation": "Ulsan National Institute of Science and Technology",
                "contact": true
            },
            {
                "email": "jooyong@unist.ac.kr",
                "first": "Jooyong",
                "last": "Yi",
                "affiliation": "Ulsan National Institute of Science and Technology",
                "contact": true
            },
            {
                "email": "darkrsw@gmail.com",
                "first": "Dongsun",
                "last": "Kim",
                "affiliation": "Kyungpook National University",
                "contact": true
            }
        ],
        "topics": [
            "Maintenance and Evolution"
        ],
        "pc_conflicts": {
            "lilicoding@ieee.org": true,
            "mnayebi@yorku.ca": true,
            "davidlo@smu.edu.sg": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683308192,
        "modified_at": 1683374135,
        "tags": [
            "accept#0",
            "dpa_candidate#0",
            "dpa_yes#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 6,
        "title": "The MAP metric in Information Retrieval Fault Localization",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-598919ead1665d1d2be0c974c066579931e36d296ac3bd10946673e86c233a48",
            "timestamp": 1681378713,
            "size": 360194,
            "pages": 12
        },
        "abstract": "The MAP (Mean Average Precision) metric is one of the most popular performance metrics in the field of Information Retrieval Fault Localization (IRFL). However, there are problematic implementations of this MAP metric used in IRFL research. These implementations deviate from the text book definitions of MAP, rendering the metric sensitive to the truncation of retrieval results and inaccuracies and impurities of the used datasets. The application of such a deviating metric can lead to performance overestimation. This can pose a problem for comparability, transferability, and validity of IRFL performance results. In this paper, we discuss the definition and mathematical properties of MAP and common deviations and pitfalls in its implementation. We investigate and discuss the conditions enabling such overestimation: the truncation of retrieval results in combination with ground truths spanning multiple files and improper handling of undefined AP results. We demonstrate the overestimation effects using the Bench4BL benchmark and five well known IRFL techniques. Our results indicate that a flawed implementation of the MAP metric can lead to an overestimation of the IRFL performance, in extreme cases by up to 70%. We argue for a strict adherence to the text book version of MAP with the extension of undefined AP values to be set to 0 for all IRFL experiments. We hope that this work will help to improve comparability and transferability in IRFL research.",
        "authors": [
            {
                "email": "thirsch@ist.tugraz.at",
                "first": "Thomas",
                "last": "Hirsch",
                "affiliation": "Graz University of Technology",
                "contact": true
            },
            {
                "email": "bhofer@ist.tugraz.at",
                "first": "Birgit",
                "last": "Hofer",
                "affiliation": "Graz University of Technology",
                "contact": true
            }
        ],
        "topics": [
            "Dependability, Safety, and Reliability",
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "shaowei.wang@umanitoba.ca": true,
            "haodan@pku.edu.cn": true,
            "hemmati@yorku.ca": true,
            "hongyujohn@gmail.com": true,
            "mnayebi@yorku.ca": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1681378768,
        "modified_at": 1684472836,
        "tags": [
            "chair_help#0",
            "needs_expert#0"
        ]
    },
    {
        "object": "paper",
        "pid": 7,
        "title": "An Energy-Aware Approach to Design Self-Adaptive AI-based Applications on the Edge",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-166d101f5a863d6be7a725eb603497007b4c93f4e92ddeead212f7d11dbdb841",
            "timestamp": 1683363693,
            "size": 3623097,
            "pages": 12
        },
        "abstract": "The advent of edge devices dedicated to machine learning tasks enabled the execution of AI-based applications that efficiently process and classify the data acquired by the resource-constrained devices populating the Internet of Things. The proliferation of such applications (e.g., critical monitoring in smart cities) demands new strategies to make these systems also sustainable from an energetic point of view.  \r\n\r\nWe present here an energy-aware approach for the design and deployment of self-adaptive AI-based applications that can balance application objectives (e.g., accuracy in object detection and frames processing rate) with energy consumption. We address the problem of determining  the set of configurations that can be used to self-adapt the system with a meta-heuristic search procedure that only needs a small number of empirical samples. The final set of configurations are selected using weighted gray relational analysis, and mapped to the operation modes of the self-adaptive application.\r\n \r\nWe validate our approach on an AI-based application for pedestrian detection.\r\nResults show that our self-adaptive application can outperform non-adaptive baseline configurations by saving up to 81\\% of energy while loosing only between 2\\% to 6\\% in accuracy.",
        "authors": [
            {
                "email": "alessandro.tundo@unimib.it",
                "first": "Alessandro",
                "last": "Tundo",
                "affiliation": "University of Milano-Bicocca",
                "contact": true
            },
            {
                "email": "marco.mobilio@unimib.it",
                "first": "Marco",
                "last": "Mobilio",
                "affiliation": "University of Milano-Bicocca",
                "contact": true
            },
            {
                "email": "shashikant.ilager@tuwien.ac.at",
                "first": "Shashikant",
                "last": "Ilager",
                "affiliation": "Vienna University of Technology"
            },
            {
                "email": "ivona.brandic@tuwien.ac.at",
                "first": "Ivona",
                "last": "Brandic",
                "affiliation": "Vienna University of Technology",
                "contact": true
            },
            {
                "email": "ezio.bartocci@tuwien.ac.at",
                "first": "Ezio",
                "last": "Bartocci",
                "affiliation": "Vienna University of Technology",
                "contact": true
            },
            {
                "email": "leonardo.mariani@unimib.it",
                "first": "Leonardo",
                "last": "Mariani",
                "affiliation": "University of Milano-Bicocca",
                "contact": true
            }
        ],
        "supplementary_material": {
            "mimetype": "application\/zip",
            "hash": "sha2-6ca749990264e2e892785877a27e0eefc915d7d18829cdbd67a0b0978d0f070f",
            "timestamp": 1683213109,
            "size": 534257976,
            "filename": "test-video.zip"
        },
        "topics": [
            "AI and Software Engineering",
            "Social Aspects of Software Engineering"
        ],
        "pc_conflicts": {
            "dirk.beyer@sosy-lab.org": true,
            "a.filieri@imperial.ac.uk": true,
            "luciano.baresi@polimi.it": true,
            "domenico.bianculli@uni.lu": true,
            "daniela.micucci@unimib.it": true,
            "alessandra.gorla@imdea.org": true,
            "leonardo.mariani@unimib.it": "collaborator author",
            "fabrizio.pastore@uni.lu": true,
            "amarlop@us.es": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683216332,
        "modified_at": 1683363693,
        "tags": [
            "accept#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 11,
        "title": "Delving into Commit-Issue Correlation to Enhance Commit Message Generation Models",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-c1df3167a0ea9d38228c182850e27e6949f5df64d19f237423482cd541da4e1b",
            "timestamp": 1690824960,
            "size": 884209,
            "pages": 13
        },
        "abstract": "Commit message generation (CMG) is a challenging task in automated software engineering that aims to generate natural language descriptions of code changes for commits. Previous methods all start from the modified code snippets, outputting commit messages through template-based, retrieval-based, or learning-based models. While these methods can summarize what is modified from the perspective of code, they struggle to provide reasons for the commit. The correlation between commits and issues that could be a critical factor for generating rational commit messages is still unexplored.\r\n\r\nIn this work, we delve into the correlation between commits and issues from the perspective of dataset and methodology. We construct the first dataset anchored on combining correlated commits and issues. The dataset consists of an unlabeled commit-issue parallel part and a labeled part in which each example is provided with human-annotated rational information in the issue. Furthermore, we propose \\textbf{ExGroFi} (Extraction, Grounding, Fine-tuning), a novel paradigm that can introduce the correlation between commits and issues into the training phase of models. To evaluate whether it is effective, we perform comprehensive experiments with various state-of-the-art CMG models. The results show that compared with the original models, the performance of \\textbf{ExGroFi}-enhanced models is significantly improved.",
        "authors": [
            {
                "email": "wanglr@buaa.edu.cn",
                "first": "Liran",
                "last": "Wang",
                "affiliation": "Beihang University",
                "contact": true
            },
            {
                "email": "xunzhu.tang@uni.lu",
                "first": "Xunzhu",
                "last": "Tang",
                "affiliation": "University of Luxembourg",
                "contact": true
            },
            {
                "email": "hyc2026@buaa.edu.cn",
                "first": "Yichen",
                "last": "He",
                "affiliation": "Beihang University",
                "contact": true
            },
            {
                "email": "cyren@buaa.edu.cn",
                "first": "Changyu",
                "last": "Ren",
                "affiliation": "Beihang University",
                "contact": true
            },
            {
                "email": "shishuhua@buaa.edu.cn",
                "first": "Shuhua",
                "last": "Shi",
                "affiliation": "Beihang University",
                "contact": true
            },
            {
                "email": "ycr2345@buaa.edu.cn",
                "first": "Chaoran",
                "last": "Yan",
                "affiliation": "Beihang University",
                "contact": true
            },
            {
                "email": "lizj@buaa.edu.cn",
                "first": "Zhoujun",
                "last": "Li",
                "affiliation": "Beihang University",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering"
        ],
        "pc_conflicts": {
            "kevin.allix@centralesupelec.fr": true,
            "M.Sabetzadeh@uottawa.ca": true,
            "xin.xia@acm.org": true,
            "haodan@pku.edu.cn": true,
            "ma.lei@acm.org": true,
            "lilicoding@ieee.org": true,
            "domenico.bianculli@uni.lu": true,
            "mnayebi@yorku.ca": true,
            "davidlo@smu.edu.sg": true,
            "fabrizio.pastore@uni.lu": true,
            "snejati@uottawa.ca": true,
            "renzo.degiovanni@uni.lu": true,
            "d.shin@sheffield.ac.uk": true,
            "xuwang@buaa.edu.cn": true,
            "ezekiel.soremekun@rhul.ac.uk": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1692027504,
        "modified_at": 1692027504
    },
    {
        "object": "paper",
        "pid": 17,
        "title": "CertPri: Certifiable Prioritization for Deep Neural Networks via Movement Cost in Feature Space",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-1b701f9abf1b363717d0c795f40d8a960a80aba09a6e8b32910a76093d5d3ece",
            "timestamp": 1682783725,
            "size": 2059403,
            "pages": 12
        },
        "abstract": "Deep neural networks (DNNs) have demonstrated their outperformance in various software systems, but also exhibit misbehavior and even result in irreversible disasters. Therefore, it is crucial to identify the misbehavior of DNN-based software and improve DNNs’ quality. The test input prioritization is one of the most appealing ways to guarantee DNNs’ quality, which prioritizes test inputs so that more bug-revealing test inputs can be identified earlier with limited time and manual labeling efforts. However, the existing prioritization methods are still limited from three aspects: certifiability, effectiveness, and generalizability. To overcome the challenges, we propose CertPri, a test input prioritization technique designed based on a movement cost perspective of test inputs in DNNs’ feature space. CertPri differs from previous works in three key aspects: (1) certifiable - it provides a formal robustness guarantee for the movement cost; (2) effective - it leverages formally guaranteed movement costs to identify malicious bug-revealing test inputs; and (3) generic - it can be applied to various tasks, data forms, models, and scenarios. Extensive evaluations across 2 tasks (i.e., classification and regression), 6 data forms, 4 model structures, and 2 scenarios (i.e., white-box and black-box) demonstrate CertPri’s superior performance. For instance, it significantly improves 53.97% prioritization effectiveness on average compared with baselines. Its robustness and generalizability are 1.41-2.00 times and 1.33-3.39 times that of baselines on average, respectively. The code of CertPri is open-sourced at https:\/\/anonymous.4open.science\/r\/CertPri.",
        "authors": [
            {
                "email": "haibinzheng320@gmail.com",
                "first": "Haibin",
                "last": "Zheng",
                "affiliation": "Zhejiang University of Technology",
                "contact": true
            },
            {
                "email": "chenjinyin@zjut.edu.cn",
                "first": "Jinyin",
                "last": "Chen",
                "affiliation": "Zhejiang University of Technology",
                "contact": true
            },
            {
                "email": "2112003035@zjut.edu.cn",
                "first": "Haibo",
                "last": "Jin",
                "affiliation": "Zhejiang University of Techonology",
                "contact": true
            }
        ],
        "supplementary_material": {
            "mimetype": "application\/zip",
            "hash": "sha2-8af32e3481c7f824ee2dd98824695f2a2e3086e2a9cfb6968653e75e84405df1",
            "timestamp": 1683123087,
            "size": 202109206,
            "filename": "20230501-Supplementary Materials.zip"
        },
        "topics": [
            "AI and Software Engineering",
            "Dependability, Safety, and Reliability",
            "Formal Aspects of Software Engineering",
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "junsun@smu.edu.sg": true,
            "xin.xia@acm.org": true,
            "mnayebi@yorku.ca": true,
            "xinghu@zju.edu.cn": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1682783724,
        "modified_at": 1689639259
    },
    {
        "object": "paper",
        "pid": 33,
        "title": "FLUX: Finding Bugs with LLVM IR Based Unit Test Crossovers",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-960da92348f503a4309e8390581d0d207167b5b0d35684f20e74e044b4711ab1",
            "timestamp": 1683256352,
            "size": 362917,
            "pages": 11
        },
        "abstract": "Optimizing compilers are as ubiquitous as they are crucial to software development. However, bugs in compilers are not uncommon. Among the most serious are bugs in compiler optimizations, which can cause unexpected behavior in compiled binaries. Existing approaches for detecting such bugs have focused on end-to-end compiler fuzzing, which limits their ability for targeted exploration of a compiler's optimizations. \r\n\r\nThis paper proposes FLUX (\\textit{F}inding Bugs with \\textit{L}LVM IR Based \\textit{U}nit Test Cross(\\textit{X})overs), a fuzzer that is designed to generate test cases that stress compiler optimizations. Previous compiler fuzzers are overly constrained by having to construct well-formed inputs. FLUX sidesteps this constraint by using human-written unit test suites as a starting point, and then selecting random combinations of them to generate new tests. We hypothesize that tests generated this way will be able to explore new execution paths through compiler optimizations and find new bugs. Our evaluation of FLUX on LLVM indicates that it is able to increase path coverage and explores more coverage than previous work. After a month of fuzzing, FLUX found 24 unique bugs in LLVM's active development branch. Three of them have already been reported and patched by LLVM developers. Two of these are miscompilation bugs that silently produced incorrect code.",
        "authors": [
            {
                "email": "ec.liu@mail.utoronto.ca",
                "first": "Eric",
                "last": "Liu",
                "affiliation": "University of Toronto",
                "contact": true
            },
            {
                "email": "shengjie.xu@mail.utoronto.ca",
                "first": "Shengjie",
                "last": "Xu",
                "affiliation": "University of Toronto",
                "contact": true
            },
            {
                "email": "david.lie@utoronto.ca",
                "first": "David",
                "last": "Lie",
                "affiliation": "University of Toronto",
                "contact": true
            }
        ],
        "topics": [
            "Dependability, Safety, and Reliability",
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "mnayebi@yorku.ca": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1682546110,
        "modified_at": 1683256352,
        "tags": [
            "accept#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 40,
        "title": "DeFiWarder: Protecting DeFi Apps from Token Leaking Vulnerabilities",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-1a2ea1e5ee9f2ff3e5d35444fa6adc49edd25d37537d4456370be4c88dacf0f4",
            "timestamp": 1683368938,
            "size": 460383,
            "pages": 12
        },
        "abstract": "Decentralized Finance (DeFi) apps have rapidly proliferated with the development of blockchain and smart contracts, whose maximum total value locked (TVL) has exceeded 100 billion USD in the past few years. These apps allow users to interact and perform complicated financial activities. However, the vulnerabilities hiding in the smart contracts of DeFi apps have resulted in numerous security incidents, with most of them leading to the funds (tokens) leaking and resulting in severe financial loss. In this paper, we summarize Token Leaking vulnerability of DeFi apps, which enable someone to withdraw funds that far exceed their deposits. Due to the massive amount of funds in DeFi apps, it is crucial to protect DeFi apps from Token Leaking vulnerabilities. Unfortunately, existing tools have limitations in addressing this vulnerability.\r\n\r\nTo address this issue, we propose DeFiWarder, a tool that traces on-chain transactions and protects DeFi apps from Token Leaking vulnerabilities. Specifically, DeFiWarder first records the execution log of smart contracts. It then accurately recovers token transfers within transactions to catch the funds flow between users and DeFi apps, as well as the relationship between users based on role minting. Finally, DeFiWarder utilizes abnormal detection to reveal Token Leaking vulnerabilities and related attack behaviors.\r\nWe conducted experiments to demonstrate the effectiveness and efficiency of DeFiWarder. Specifically, DeFiWarder successfully revealed 27 Token Leaking vulnerabilities from 32 Defi apps. Moreover, its efficiency supports real-time detection of token leaking within on-chain transactions. In addition, we summarize seven major reasons for Token Leaking vulnerability to assist DeFi apps in protecting their funds.",
        "authors": [
            {
                "email": "sujzh3@mail2.sysu.edu.cn",
                "first": "Jianzhong",
                "last": "Su",
                "affiliation": "Sun Yat-sen University & Ant Group",
                "contact": true
            },
            {
                "email": "xwlin.roy@gmail.com",
                "first": "Xingwei",
                "last": "Lin",
                "affiliation": "Ant Group",
                "contact": true
            },
            {
                "email": "fangzhy27@mail2.sysu.edu.cn",
                "first": "Zhiyuan",
                "last": "Fang",
                "affiliation": "Sun Yat-sen University",
                "contact": true
            },
            {
                "email": "zhuzhr7@mail2.sysu.edu.cn",
                "first": "Zhirong",
                "last": "Zhu",
                "affiliation": "Sun Yat-sen University",
                "contact": true
            },
            {
                "email": "chenjch86@mail.sysu.edu.cn",
                "first": "Jiachi",
                "last": "Chen",
                "affiliation": "Sun Yat-sen University",
                "contact": true
            },
            {
                "email": "zhzibin@mail.sysu.edu.cn",
                "first": "Zibin",
                "last": "Zheng",
                "affiliation": "Sun Yat-sen University, Guangzhou, 510006, P.R. China",
                "contact": true
            },
            {
                "email": "huaxing.lw@antgroup.com",
                "first": "Wei",
                "last": "Lv",
                "affiliation": "Ant Group",
                "contact": true
            },
            {
                "email": "jiashui.wjs@antgroup.com",
                "first": "Jiashui",
                "last": "Wang",
                "affiliation": "Zhejiang University & Ant Group",
                "contact": true
            }
        ],
        "topics": [
            "Dependability, Safety, and Reliability",
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "junsun@smu.edu.sg": true,
            "xin.xia@acm.org": true,
            "csxluo@comp.polyu.edu.hk": true,
            "mnayebi@yorku.ca": true,
            "davidlo@smu.edu.sg": true,
            "xyzhang@cs.purdue.edu": true,
            "xinghu@zju.edu.cn": true,
            "liu.chao@cqu.edu.cn": true,
            "yli044@e.ntu.edu.sg": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683368938,
        "modified_at": 1683373822,
        "tags": [
            "accept#0"
        ]
    },
    {
        "object": "paper",
        "pid": 50,
        "title": "Systematically Detecting Packet Validation Vulnerabilities in Embedded Network Stacks",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-aaa43d5db91095f958574e897c8101382006f91746c9c59ec453bea5b05400f6",
            "timestamp": 1683374257,
            "size": 607545,
            "pages": 12
        },
        "abstract": "Embedded Network Stacks (ENS) enable communication with cyber-physical systems. packet validation defects in ENS are high severity cybersecurity vulnerabilities: they are remotely triggerable and can impact the physical world. The most common automated approach to detecting ENS defects is feedback-driven random dynamic analysis (“fuzzing”), a costly and unpredictable technique. While prior research has shed light on the characteristics of defects in many classes of software systems, no study has described the properties of known ENS defects nor identified a systematic technique for exposing them\r\n\r\nThis paper provides the first systematic characterization of vulnerabilities in ENS (61 defects across 6 ENS). ENS defects are concentrated in two layers of the network stack, require reaching\r\ndifferent states in the network protocol, and are triggered by only 1-2 modifications to a single packet. We, therefore, propose a novel systematic testing framework that focuses on the transport and network layers, uses seeds that cover a network protocol, and systematically modifies packet fields. We evaluate this framework on 4 ENS and find it replicates 12 of the 14 reported IP\/TCP\/UDP vulnerabilities. On recent versions of these ENSs, it discovered 7 novel defects during a bounded systematic test that covered all protocol states and made up to 3 modifications per packet. We found defects in 3 of the 4 ENS we tested that had not been found by prior fuzzing research. Our results suggest that fuzzing should be deferred until after systematic testing is employed.",
        "authors": [
            {
                "email": "pamusuo@purdue.edu",
                "first": "Paschal C.",
                "last": "Amusuo",
                "affiliation": "Purdue University",
                "contact": true
            },
            {
                "email": "rcalvome@purdue.edu",
                "first": "Ricardo Andrés Calvo",
                "last": "Méndez",
                "affiliation": "Universidad Nacional de Colombia"
            },
            {
                "email": "2206515211@stu.xjtu.edu.cn",
                "first": "Zhongwei",
                "last": "Xu",
                "affiliation": "Xi'an JiaoTong University"
            },
            {
                "email": "amachiry@purdue.edu",
                "first": "Aravind",
                "last": "Machiry",
                "affiliation": "Purdue University",
                "contact": true
            },
            {
                "email": "davisjam@purdue.edu",
                "first": "James C.",
                "last": "Davis",
                "affiliation": "Purdue University",
                "contact": true
            }
        ],
        "topics": [
            "Testing and Analysis",
            "Tools and Processes"
        ],
        "pc_conflicts": {
            "tianyi@purdue.edu": true,
            "louyiling610@gmail.com": true,
            "mnayebi@yorku.ca": true,
            "xyzhang@cs.purdue.edu": true,
            "renzo.degiovanni@uni.lu": true,
            "Steffen.Herbold@uni-passau.de": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683370102,
        "modified_at": 1683374506,
        "tags": [
            "accept#0"
        ]
    },
    {
        "object": "paper",
        "pid": 58,
        "title": "EALink: An Efficient and Accurate Pre-Trained Framework for Issue-Commit Link Recovery",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-b5d23939ff1446ee216c7f4dd62c1533af87512e3329cfb187f5d13f06f21bec",
            "timestamp": 1683373834,
            "size": 924585,
            "pages": 11
        },
        "abstract": "Issue-commit links, as a type of software traceability links, play a vital role in various software development and maintenance tasks. However, they are typically deficient, as developers often forget or fail to create tags when making commits. Existing studies have deployed deep learning techniques, including pre-trained models, to improve automatic issue-commit link recovery. Despite their promising performance, we argue that previous approaches have four main problems, hindering them from recovering links in large software projects. To overcome these problems, we propose an efficient and accurate pre-trained framework called EALink for issue-commit link recovery. EALink requires fewer model parameters than existing pre-trained methods, bringing efficient training and recovery. Moreover, we design various techniques to improve the recovery accuracy of EALink. We construct a large-scale dataset and conduct extensive experiments to demonstrate the power of EALink. It outperforms existing methods by 408.65% at most. It also exceeds the state-of-the-art pre-trained model by a large margin (15.23%-47.67%). Meanwhile, its training and inference overhead is orders of magnitude lower than existing methods. We provide our anonymized implementation and data at https:\/\/anonymous.4open.science\/r\/EALink-6E61.",
        "authors": [
            {
                "email": "zhangchenyuan@stu.xmu.edu.cn",
                "first": "Chenyuan",
                "last": "Zhang",
                "affiliation": "Xiamen University",
                "contact": true
            },
            {
                "email": "wangylin36@mail.sysu.edu.cn",
                "first": "Yanlin",
                "last": "Wang",
                "affiliation": "Sun Yat-sen University",
                "contact": true
            },
            {
                "email": "zachwei@tencent.com",
                "first": "Zhao",
                "last": "Wei",
                "affiliation": "Tencent"
            },
            {
                "email": "rogerxu@tencent.com",
                "first": "Yong",
                "last": "Xu",
                "affiliation": "Tencent"
            },
            {
                "email": "julietwang@tencent.com",
                "first": "Juhong",
                "last": "Wang",
                "affiliation": "Tencent"
            },
            {
                "email": "hui@xmu.edu.cn",
                "first": "Hui",
                "last": "Li",
                "affiliation": "Xiamen University",
                "contact": true
            },
            {
                "email": "rrji@xmu.edu.cn",
                "first": "Rongrong",
                "last": "Ji",
                "affiliation": "Xiamen University"
            }
        ],
        "supplementary_material": {
            "mimetype": "application\/pdf",
            "hash": "sha2-57d8c3d3316330b97e68017024a45e816dd2792036e1c7e38e7cd92c559b4384",
            "timestamp": 1683373497,
            "size": 30217,
            "filename": "Supplementary material.pdf",
            "pages": 1
        },
        "topics": [
            "AI and Software Engineering"
        ],
        "pc_conflicts": {
            "shihan@microsoft.com": true,
            "hongyujohn@gmail.com": true,
            "mnayebi@yorku.ca": true,
            "wurongxin@xmu.edu.cn": true,
            "xyzhang@cs.purdue.edu": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683374172,
        "modified_at": 1683374498
    },
    {
        "object": "paper",
        "pid": 59,
        "title": "Generative Type Inference for Python",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-643f5856f425539ab63328fdeab7ef5bc2c37bbc06c3017070825f628fd6e7de",
            "timestamp": 1683362258,
            "size": 636127,
            "pages": 12
        },
        "abstract": "Python is a popular dynamic programming language, evidenced by its ranking as the second most commonly used language on GitHub. However, its dynamic type system can lead to potential type errors, leading researchers to explore automatic type inference approaches for Python programs. Existing type inference approaches can be generally grouped into three categories, i.e., rule-based, supervised, and cloze-style approaches. The rule-based type inference approaches can ensure the accuracy of predicted variable types, but they suffer from low coverage problems caused by dynamic features and external calls. Supervised type inference approaches, while feature-agnostic and able to mitigate the low coverage problem, require large, high-quality annotated datasets and are limited to pre-defined types. As zero-shot approaches, the cloze-style approaches reformulate the type inference problem into a fill-in-the-blank problem by leveraging the general knowledge in powerful pre-trained code models. However, their performance is limited since they ignore the domain knowledge from static typing rules which reflect the inference logic. What is more, their predictions are not interpretable, hindering developers' understanding and verification of the results.\r\n\r\nThis paper introduces TypeGen, a few-shot generative type inference approach that incorporates static domain knowledge from static analysis. TypeGen creates chain-of-thought (COT) prompts by translating the type inference steps of static analysis into prompts based on the type dependency graphs (TDGs), enabling language models to learn from how static analysis infers types. By combining COT prompts with code slices and type hints, TypeGen constructs example prompts from human annotations. TypeGen only requires very few annotated examples to teach language models to generate similar COT prompts via in-context learning. Moreover, TypeGen enhances the interpretability of results through the use of the input-explanation-output strategy, which generates both explanations and type predictions in COT prompts. Experiments show that TypeGen outperforms the best baseline Type4Py by 10.0% for argument type prediction and 22.5% in return value type prediction in terms of top-1 Exact Match by using only five examples.  Furthermore, TypeGen achieves substantial improvements of 27% to 84% compared to the zero-shot performance of large language models with parameter sizes ranging from 1.3B to 175B in terms of top-1 Exact Match.",
        "authors": [
            {
                "email": "ypeng@cse.cuhk.edu.hk",
                "first": "Yun",
                "last": "Peng",
                "affiliation": "The Chinese University of Hong Kong",
                "contact": true
            },
            {
                "email": "adf111178@gmail.com",
                "first": "Chaozheng",
                "last": "Wang",
                "affiliation": "The Chinese University of Hong Kong",
                "contact": true
            },
            {
                "email": "wxwang@cse.cuhk.edu.hk",
                "first": "Wenxuan",
                "last": "Wang",
                "affiliation": "The Chinese University of Hong Kong",
                "contact": true
            },
            {
                "email": "gaocuiyun@hit.edu.cn",
                "first": "Cuiyun",
                "last": "Gao",
                "affiliation": "Harbin Institute of Technology",
                "contact": true
            },
            {
                "email": "lyu@cse.cuhk.edu.hk",
                "first": "Michael",
                "last": "Lyu",
                "affiliation": "The Chinese University of Hong Kong",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering"
        ],
        "pc_conflicts": {
            "michael@binaervarianz.de": true,
            "junsun@smu.edu.sg": true,
            "junjiechen@tju.edu.cn": true,
            "lxiao6@stevens.edu": true,
            "lingming@illinois.edu": true,
            "tianyi@purdue.edu": true,
            "xin.xia@acm.org": true,
            "fengyang@nju.edu.cn": true,
            "changxu@nju.edu.cn": true,
            "senchen@tju.edu.cn": true,
            "shuaiw@cse.ust.hk": true,
            "haodan@pku.edu.cn": true,
            "xusheng.xiao@asu.edu": true,
            "xfxie@smu.edu.sg": true,
            "liuhui08@bit.edu.cn": true,
            "zhendong@fudan.edu.cn": true,
            "ding_li@pku.edu.cn": true,
            "gaocuiyun@hit.edu.cn": "author",
            "j.petke@ucl.ac.uk": true,
            "mark.harman@ucl.ac.uk": true,
            "lilicoding@ieee.org": true,
            "csxluo@comp.polyu.edu.hk": true,
            "louyiling610@gmail.com": true,
            "fangchunrong@nju.edu.cn": true,
            "hongyujohn@gmail.com": true,
            "linglingfan@nankai.edu.cn": true,
            "wangying@swc.neu.edu.cn": true,
            "mnayebi@yorku.ca": true,
            "davidlo@smu.edu.sg": true,
            "taoxie@pku.edu.cn": true,
            "tazhang@must.edu.mo": true,
            "liu.chao@cqu.edu.cn": true,
            "alessio.gambi@fh-krems.ac.at": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683349852,
        "modified_at": 1683563828,
        "tags": [
            "accept#0",
            "dpa_candidate#0",
            "dpa_yes#0",
            "FeCoI#0"
        ]
    },
    {
        "object": "paper",
        "pid": 64,
        "title": "Automatic Generation and Reuse of Precise Library Summaries for Object-Sensitive Pointer Analysis",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-0553b3f4469e489853693393771c8eecc3ce502a2e523dc0216c6426a479111b",
            "timestamp": 1682039663,
            "size": 600978,
            "pages": 11
        },
        "abstract": "The extensive use of libraries in modern software  impedes the scalability of pointer analysis. To address this issue, library summarization can be beneficial, but only if the resulting summary-based pointer analysis is faster without sacrificing much precision in the application code. However, currently, no library summarization approaches exist that meet this design objective. This paper presents a novel approach that solves this problem by using $k$-object-sensitive pointer analysis, $k$-*obj*, for Java. The approach involves applying $k$-*obj*, along with a set of summary-based inference rules, to generate a $k$-object-sensitive library summary. By replacing the program's library with this summary and  applying $k$-*obj*, the efficiency of the program can be significantly improved while maintaining nearly the same or better precision in the application code. We validate our approach with an implementation in Soot, which will soon be open-sourced, and an evaluation using representative Java programs.",
        "authors": [
            {
                "email": "jingbo.lu@unswalumni.com",
                "first": "Jingbo",
                "last": "Lu",
                "affiliation": "University of New South Wales",
                "contact": true
            },
            {
                "email": "dongjieh@cse.unsw.edu.au",
                "first": "Dongjie",
                "last": "He",
                "affiliation": "School of Computer Science and Engineering, University of New South Wales Sydney",
                "contact": true
            },
            {
                "email": "liwei@cse.unsw.edu.au",
                "first": "Wei",
                "last": "Li",
                "affiliation": "University of New South Wales",
                "contact": true
            },
            {
                "email": "yaoqing.gao@huawei.com",
                "first": "Yaoqing",
                "last": "Gao",
                "affiliation": "Huawei Toronto Research Center",
                "contact": true
            },
            {
                "email": "j.xue@unsw.edu.au",
                "first": "Jingling",
                "last": "Xue",
                "affiliation": "UNSW Sydney",
                "contact": true
            }
        ],
        "supplementary_material": {
            "mimetype": "application\/pdf",
            "hash": "sha2-6481c094d2e24158747f4f9246e404ff697bb4a6e3eceef0e469ce59cb5859ee",
            "timestamp": 1682676975,
            "size": 398396,
            "filename": "Summary_Supplementary_.pdf",
            "pages": 1
        },
        "topics": [
            "Testing and Analysis",
            "Tools and Processes"
        ],
        "pc_conflicts": {
            "j.xue@unsw.edu.au": "author",
            "dolby@us.ibm.com": true,
            "shaowei.wang@umanitoba.ca": true,
            "xin.xia@acm.org": true,
            "dongjieh@cse.unsw.edu.au": "author",
            "y.sui@unsw.edu.au": true,
            "yli044@e.ntu.edu.sg": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1682676975,
        "modified_at": 1684473331,
        "tags": [
            "accept#0"
        ]
    },
    {
        "object": "paper",
        "pid": 93,
        "title": "Contrastive Learning for API Aspect Analysis",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-8f3599c3c05af8774b3ab1487590b901def03810155ee5c736c954dce82fddf2",
            "timestamp": 1683359379,
            "size": 945738,
            "pages": 11
        },
        "abstract": "As software developers are faced with an ever-increasing number of tool and technologies to choose from, it can be challenging to determine which options are best suited for a particular project. To help developers make more informed decisions, researchers have been exploring ways to automatically analyze developer discussion on forums like Stack Overflow to extract information about the advantages and disadvantages of different APIs, frameworks, and tools. In this paper, we propose a novel approach - CLAA - for API aspect detection in API reviews that utilizes transformer models trained with a supervised contrastive loss objective function. We evaluate CLAA using performance and impact analysis. For performance analysis, we utilized a benchmark dataset on developer discussions collected from Stack Overflow and compare the results to those obtained using state-of-the-art transformer models. Our experiments show that contrastive learning can significantly improve the performance of transformer models in detecting aspects such as Performance, Security, Usability, and Documentation. However, some aspects remain challenging for these models. For impact analysis, we performed empirical and developer study. We apply the CLAA and the best performing baseline model by collecting \"json\" and \"java\" related posts and comments from Stack Overflow. Our experiments show that CLAA is the most accurate than the baseline model on online actual in almost all aspects except for Bug. On a randomly selected and manually labeled 200 online reviews, CLAA achieved 92\\% accuracy while the SOTA baseline achieved 81.5\\%. According to our developer study involving 10 participants, the use of \\textit{Stack Overflow + CLAA} resulted in increased accuracy and confidence during API selection, and the participants found it to be very helpful. Overall, this work provides new insights into how contrastive learning can be used to improve the automatic analysis of developer discussions and aid developers in making more informed decisions about which tools and technologies to use.",
        "authors": [
            {
                "email": "sshibli745@gmail.com",
                "first": "G. M.",
                "last": "Shahariar",
                "affiliation": "Bangladesh University of Engineering and Technology",
                "contact": true
            },
            {
                "email": "tahmidhasan@cse.buet.ac.bd",
                "first": "Tahmid",
                "last": "Hasan",
                "affiliation": "Bangladesh University of Engineering and Technology",
                "contact": true
            },
            {
                "email": "anindya@cse.buet.ac.bd",
                "first": "Anindya",
                "last": "Iqbal",
                "affiliation": "Bangladesh University of Engineering and Technology",
                "contact": true
            },
            {
                "email": "gias.uddin@ucalgary.ca",
                "first": "Gias",
                "last": "Uddin",
                "affiliation": "University of Calgary",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering"
        ],
        "pc_conflicts": {
            "hemmati@yorku.ca": true,
            "foutse.khomh@polymtl.ca": true,
            "mnayebi@yorku.ca": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683359379,
        "modified_at": 1683359379,
        "tags": [
            "accept#0"
        ]
    },
    {
        "object": "paper",
        "pid": 98,
        "title": "SCPatcher: Mining Crowd Security Discussions to Enrich Secure Coding Practices",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-f3b824dea2fc79b862ff8831137c0b9166064764f4c53a6432586f350fecc865",
            "timestamp": 1683818999,
            "size": 1048828,
            "pages": 12
        },
        "abstract": "Secure coding practices (SCPs) have been proposed to guide software developers to write code securely to prevent potential security vulnerabilities. Yet, they are typically one-sentence principles without detailed specifications, e.g., “Properly free allocated memory upon the completion of functions and at all exit points.”, which makes them difficult to follow in practice, especially for software developers who are not yet experienced in secure programming. To address this problem,\r\nthis paper proposes SCPatcher, an automated approach to enrich secure coding practices by mining crowd security discussions on online knowledge-sharing platforms, such as Stack Overflow.\r\nIn particular, for each security post, SCPatcher first extracts the area of coding examples and coding explanations with a fix-prompt tuned Large Language Model (LLM) via Prompt Learning. Then, it hierarchically slices the lengthy code into coding examples, and summarizes the coding explanations with the areas. Finally, SCPatcher matches the CWE and Public SCP, integrating them with extracted coding examples and explanations to form the SCP specifications, which are the wild SCPs with details, proposed by the developers. To evaluate the performance of SCPatcher, we conduct experiments on 3,907 security posts from Stack Overflow. The experimental results show that SCPatcher outperforms all baselines in extracting the coding examples with 2.73% MLine on average, as well as coding explanations with 3.97% F1 on average. Moreover, we apply SCPatcher on 447 new security posts to further evaluate its practicality, and the extracted SCP specifications\r\nenrich the public SCPs with 3,074 lines of code and 1,967 sentences.",
        "authors": [
            {
                "email": "ziyou2019@iscas.ac.cn",
                "first": "Ziyou",
                "last": "Jiang",
                "affiliation": "Institute of Software Chinese Academy of Sciences",
                "contact": true
            },
            {
                "email": "shilin@buaa.edu.cn",
                "first": "Lin",
                "last": "Shi",
                "affiliation": "Beihang University",
                "contact": true
            },
            {
                "email": "guowei.yang@uq.edu.au",
                "first": "Guowei",
                "last": "Yang",
                "affiliation": "The University of Queensland",
                "contact": true
            },
            {
                "email": "wq@iscas.ac.cn",
                "first": "Qing",
                "last": "Wang",
                "affiliation": "Institute of Software Chinese Academy of Sciences",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering",
            "Maintenance and Evolution"
        ],
        "pc_conflicts": {
            "pcorina@cmu.edu": true,
            "junjiechen@tju.edu.cn": true,
            "lingming@illinois.edu": true,
            "xin.xia@acm.org": true,
            "mark.harman@ucl.ac.uk": true,
            "lilicoding@ieee.org": true,
            "a.filieri@imperial.ac.uk": true,
            "mnayebi@yorku.ca": true,
            "g.bai@uq.edu.au": true,
            "guowei.yang@uq.edu.au": "author",
            "xyzhang@cs.purdue.edu": true,
            "wangsong@yorku.ca": true,
            "xuwang@buaa.edu.cn": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683372880,
        "modified_at": 1683818999
    },
    {
        "object": "paper",
        "pid": 125,
        "title": "Who is the Real Hero? Measuring Developer Contribution via Multi-dimensional Data Integration",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-aa9b304d8f26a2deb75ad08f6dc43bf6078763c838b1cfb0f3a81d1b714ea343",
            "timestamp": 1683373708,
            "size": 728145,
            "pages": 11
        },
        "abstract": "Proper incentives are important for motivating developers in open-source communities, which is crucial for maintaining the development of open-source software healthy. To provide such incentives, an accurate and objective developer contribution measurement method is needed. However, existing methods rely heavily on manual peer review, lacking objectivity and transparency. The metrics of some automated works about effort estimation use only syntax-level or even text-level information, such as changed lines of code, which lack robustness. Furthermore, some works about identifying core developers provide only a qualitative understanding without a quantitative score or have some project-specific parameters, which makes them not practical in real-world projects. \r\n\r\nTo this end, we propose CVALUE, a multidimensional information fusion-based approach to measure developer contributions. CVALUE extracts both syntax and semantic information from the source code changes in four dimensions: modification amount, understandability, inter-function and intra-function impact of modification. It fuses the information to produce the contribution score for each of the commits in the projects. Experimental results show that CVALUE outperforms other approaches by 19.59% on 10 real-world projects with manually labeled ground truth. We validated and proved that the performance of CVALUE, which takes 83.39 seconds per commit, is acceptable to be applied in real-world projects. Furthermore, we performed a large-scale experiment on 174 projects and detected 2,282 developers having inflated commits. Of these, 2,030 developers did not make a semantic contribution; and 103 were identified as bots.",
        "authors": [
            {
                "email": "suny0056@e.ntu.edu.sg",
                "first": "Yuqiang",
                "last": "Sun",
                "affiliation": "Nanyang Technological University",
                "contact": true
            },
            {
                "email": "zhengzi.xu@ntu.edu.sg",
                "first": "Zhengzi",
                "last": "Xu",
                "affiliation": "Nanyang Technological University",
                "contact": true
            },
            {
                "email": "chengwei001@e.ntu.edu.sg",
                "first": "Chengwei",
                "last": "Liu",
                "affiliation": "Nanyang Technological University",
                "contact": true
            },
            {
                "email": "YIRAN002@e.ntu.edu.sg",
                "first": "Yiran",
                "last": "Zhang",
                "affiliation": "Nanyang Technological University",
                "contact": true
            },
            {
                "email": "yangliu@ntu.edu.sg",
                "first": "Yang",
                "last": "Liu",
                "affiliation": "Nanyang Technological University",
                "contact": true
            }
        ],
        "topics": [
            "Human Aspects of Software Engineering"
        ],
        "pc_conflicts": {
            "junsun@smu.edu.sg": true,
            "chunyang.chen@monash.edu": true,
            "lxiao6@stevens.edu": true,
            "senchen@tju.edu.cn": true,
            "xfxie@smu.edu.sg": true,
            "gaocuiyun@hit.edu.cn": true,
            "ma.lei@acm.org": true,
            "lilicoding@ieee.org": true,
            "linglingfan@nankai.edu.cn": true,
            "jie.zhang@kcl.ac.uk": true,
            "mnayebi@yorku.ca": true,
            "davidlo@smu.edu.sg": true,
            "xxie@whu.edu.cn": true,
            "y.sui@unsw.edu.au": true,
            "tsu@sei.ecnu.edu.cn": true,
            "xuwang@buaa.edu.cn": true,
            "yli044@e.ntu.edu.sg": true,
            "mengguozhu@iie.ac.cn": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683365342,
        "modified_at": 1683373796
    },
    {
        "object": "paper",
        "pid": 127,
        "title": "HOBAT: Batch Verification for Homogeneous Structural Neural Networks",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-58526f86d0d6a2e3a1194d76942087790e3be9424416774996dc3f8e912e7b19",
            "timestamp": 1683366394,
            "size": 421274,
            "pages": 11
        },
        "abstract": "The rapid development of deep learning has significantly transformed the ecology of the software engineering field. As new data continues to grow and evolve at an explosive rate, the challenge of iteratively updating software built on neural networks has become a critical issue. While the continuous learning paradigm enables networks to incorporate new data and update accordingly without losing previous memories, resulting in a batch of new networks as candidates for software updating, these approaches merely select from these networks by empirically testing their accuracy; they lack formal guarantees for such a batch of networks, especially in the presence of adversarial samples. Existing verification techniques, based on constraint solving, interval propagation, and linear approximation, provide formal guarantees but are designed to verify the properties of individual networks rather than a batch of networks. To address this issue, we analyze the batch verification problem corresponding to several non-traditional machine learning paradigms and further propose a framework named HOBAT (BATch verification for HOmogeneous structural neural networks) to enhance batch verification under reasonable assumptions about the representation of homogeneous structure neural networks, increasing scalability in practical applications. Our method involves abstracting the neurons at the same position in a batch of networks into a single neuron, followed by an iterative refinement process on the abstracted neuron to restore the precision until the desired properties for verification are met. Our method is orthogonal to boundary propagation verification on a single neural network. To assess our methodology, we integrate it with boundary propagation verification and observe significant improvements compared to the vanilla approach. Our experiments demonstrate the enormous potential for verifying large batches of networks in the era of big data.",
        "authors": [
            {
                "email": "lijjjjj@sjtu.edu.cn",
                "first": "Jingyang",
                "last": "Li",
                "affiliation": "Shanghai Jiao Tong University",
                "contact": true
            },
            {
                "email": "li.g@sjtu.edu.cn",
                "first": "Guoqiang",
                "last": "Li",
                "affiliation": "Shanghai Jiao Tong University",
                "contact": true
            }
        ],
        "topics": [
            "Formal Aspects of Software Engineering"
        ],
        "pc_conflicts": {
            "chunyang.chen@monash.edu": true,
            "xin.xia@acm.org": true,
            "mnayebi@yorku.ca": true,
            "zhonghao@sjtu.edu.cn": true,
            "jieshan.chen@data61.csiro.au": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683331721,
        "modified_at": 1683366428,
        "tags": [
            "accept#0"
        ]
    },
    {
        "object": "paper",
        "pid": 129,
        "title": "AutoLog: A Log Sequence Synthesis Framework for Anomaly Detection",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-71f619a319dc6c01b665ec30ff068f0e4d4b6111622ff6a504f76b4d376a004b",
            "timestamp": 1683366421,
            "size": 1116803,
            "pages": 12
        },
        "abstract": "The rapid progress of modern computing systems has led to a growing interest in informative run-time logs. Various log-based anomaly detection techniques have been proposed to ensure software reliability. However, their implementation in the industry has been limited due to the lack of high-quality public log resources as training datasets.\r\n\r\nWhile some log datasets are available for anomaly detection, they suffer from limitations in (1) comprehensiveness of log events; (2) scalability over diverse systems; and (3) flexibility of log utility. To address these limitations, we propose AutoLog, the first automated log generation methodology for anomaly detection. AutoLog uses program analysis to generate run-time log sequences without actually running the system. AutoLog starts with probing comprehensive logging statements associated with the call graphs of an application. Then, it constructs execution graphs for each method after pruning the call graphs to find log-related execution paths in a scalable manner. Finally, AutoLog propagates the anomaly label to each acquired execution path based on human knowledge. It generates flexible log sequences by walking along the log execution paths with controllable parameters. Experiments on 50 popular Java projects show that AutoLog acquires significantly more (\\textit{9x-58x}) log events than existing log datasets from the same system, and generates log messages much faster (\\textit{15x}) with a single machine than existing passive data collection approaches. AutoLog also provides hyper-parameters to adjust the data size, anomaly rate, and component indicator for simulating different real-world scenarios. We further demonstrate AutoLog's practicality by showing that AutoLog enables log-based anomaly detectors to achieve better performance (\\textit{1.93\\%}) compared to existing log datasets. We hope AutoLog can facilitate the benchmarking and adoption of automated log analysis techniques.",
        "authors": [
            {
                "email": "ythuo@cse.cuhk.edu.hk",
                "first": "Yintong",
                "last": "Huo",
                "affiliation": "The Chinese University of Hong Kong",
                "contact": true
            },
            {
                "email": "ycli21@cse.cuhk.edu.hk",
                "first": "Yichen",
                "last": "Li",
                "affiliation": "The Chinese University of Hong Kong",
                "contact": true
            },
            {
                "email": "suyx35@mail.sysu.edu.cn",
                "first": "Yuxin",
                "last": "Su",
                "affiliation": "Sun Yat-sen University",
                "contact": true
            },
            {
                "email": "hepinjia@cuhk.edu.cn",
                "first": "Pinjia",
                "last": "He",
                "affiliation": "Chinese University of Hong Kong, Shenzhen",
                "contact": true
            },
            {
                "email": "xzff@hust.edu.cn",
                "first": "Zifan",
                "last": "Xie",
                "affiliation": "Huazhong University of Science and Technology",
                "contact": true
            },
            {
                "email": "lyu@cse.cuhk.edu.hk",
                "first": "Michael",
                "last": "Lyu",
                "affiliation": "The Chinese University of Hong Kong",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering",
            "Dependability, Safety, and Reliability"
        ],
        "pc_conflicts": {
            "dposhyvanyk@gmail.com": true,
            "grunske@informatik.hu-berlin.de": true,
            "michael@binaervarianz.de": true,
            "malek@uci.edu": true,
            "junsun@smu.edu.sg": true,
            "gunel.jahangirova@kcl.ac.uk": true,
            "tianyi@purdue.edu": true,
            "j.bell@northeastern.edu": true,
            "xin.xia@acm.org": true,
            "senchen@tju.edu.cn": true,
            "liuhui08@bit.edu.cn": true,
            "sfakhoury@microsoft.com": true,
            "gaocuiyun@hit.edu.cn": true,
            "taoyue@gmail.com": true,
            "mark.harman@ucl.ac.uk": true,
            "lilicoding@ieee.org": true,
            "saikatc@microsoft.com": true,
            "louyiling610@gmail.com": true,
            "fangchunrong@nju.edu.cn": true,
            "linglingfan@nankai.edu.cn": true,
            "foutse.khomh@polymtl.ca": true,
            "bacchelli@ifi.uzh.ch": true,
            "leonardo.mariani@unimib.it": true,
            "davidlo@smu.edu.sg": true,
            "taoxie@pku.edu.cn": true,
            "tazhang@must.edu.mo": true,
            "yutian.tang@glasgow.ac.uk": true,
            "fatemeh.fard@ubc.ca": true,
            "xyzhang@cs.purdue.edu": true,
            "y.sui@unsw.edu.au": true,
            "mwenaa@hust.edu.cn": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683362251,
        "modified_at": 1683371786,
        "tags": [
            "accept#0",
            "dpa_candidate#0",
            "dpa_no#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 140,
        "title": "Where to Go Now? Finding Alternatives for Declining Packages in the npm Ecosystem",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-b133fd3f88cb30dcf43bc6bf2d77de9651863263b74bed7ff7368701795fa116",
            "timestamp": 1683127498,
            "size": 296398,
            "pages": 12
        },
        "abstract": "Software ecosystems (e.g., npm, PyPI) are the backbone of modern software developments. \r\nDevelopers add new packages to ecosystems every day to solve new problems or provide alternative solutions, causing obsolete packages to decline in their importance to the community.\r\nPackages in decline are reused less over time and may become less frequently maintained. Thus, developers usually migrate their dependencies to better alternatives. Replacing packages in decline with better alternatives requires time and effort by developers to identify packages that need to be replaced, find the alternatives, asset migration benefits, and finally, perform the migration.\r\n\r\nThis paper proposes an approach that automatically identifies packages that need to be replaced and finds their alternatives supported with real-world examples of open source projects performing the suggested migrations. At its core, our approach relies on the dependency migration patterns performed in the ecosystem to suggest migrations to other developers.\r\nWe evaluated our approach on the npm ecosystem and found that 96% of the suggested alternatives are accurate. Furthermore, by surveying expert JavaScript developers, 67% of them indicate that they will use our suggested alternative packages in their future projects.",
        "authors": [
            {
                "email": "smujahid@mozilla.com",
                "first": "Suhaib",
                "last": "Mujahid",
                "affiliation": "Mozilla Corporation",
                "contact": true
            },
            {
                "email": "costa.diego@uqam.ca",
                "first": "Diego Elias",
                "last": "Costa",
                "affiliation": "Université du Québec à Montréal",
                "contact": true
            },
            {
                "email": "rabe.abdalkareem@omu.edu.ly",
                "first": "Rabe",
                "last": "Abdalkareem",
                "affiliation": "Omar Al-Mukhtar University",
                "contact": true
            },
            {
                "email": "emad.shihab@concordia.ca",
                "first": "Emad",
                "last": "Shihab",
                "affiliation": "Concordia University",
                "contact": true
            }
        ],
        "topics": [
            "Maintenance and Evolution"
        ],
        "pc_conflicts": {
            "shang@encs.concordia.ca": true,
            "hridesh@iastate.edu": true,
            "y.tian@queensu.ca": true,
            "xin.xia@acm.org": true,
            "foutse.khomh@polymtl.ca": true,
            "davidlo@smu.edu.sg": true,
            "zi_ding@encs.concordia.ca": true,
            "maxime.lamothe@polymtl.ca": true,
            "mhamdaqa@polymtl.ca": true,
            "sahraouh@iro.umontreal.ca": true,
            "yxtvse@rit.edu": true,
            "Naouel.Moha@etsmtl.ca": true,
            "philipp.leitner@chalmers.se": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683127498,
        "modified_at": 1684473460
    },
    {
        "object": "paper",
        "pid": 156,
        "title": "Automated Software Entity Matching Between Successive Versions",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-c90f36039b16fe7315712980a88bcb7a5e74986aaa57641dfcb0607f771f93f3",
            "timestamp": 1683374106,
            "size": 836570,
            "pages": 12
        },
        "abstract": "Version control systems are widely used to manage the evolution of software applications. However, such version control systems take code as lines of plain text, and thus they cannot present the evolution of software entities embedded in the source code. To this end, a few approaches have been proposed to match software entities before and after a given commit, known as software entity matching algorithms. However, the accuracy of such algorithms requires further improvement. In this paper, we propose an automated iterative algorithm (called ReMapper) to match software entities between two successive versions. The key insight of ReMapper is that the qualified name, the implementation, and the references of a software entity together can distinguish it from others. It matches software entities iteratively because the mapping depends on the reference-based similarity whereas the reference-based similarity depends on the mapping of entities as well. We evaluated ReMapper on a benchmark consisting of 215 commits from 21 real-world projects. Our evaluation results suggest that ReMapper substantially outperformed the state of the art, reducing the number of mistakes (false positives plus false negatives) substantially by 86.5\\%. We also evaluated to what extent it may improve the automated refactoring discovery (mining) that relies heavily on automated entity matching. Our evaluation results suggest that it substantially improved the state of the art in refactoring discovery, improving recall by 6.8\\% and reducing the number of false positives by 72.6\\%.",
        "authors": [
            {
                "email": "liubo@bit.edu.cn",
                "first": "Bo",
                "last": "Liu",
                "affiliation": "Beijing Institute of Technology",
                "contact": true
            },
            {
                "email": "liuhui08@bit.edu.cn",
                "first": "Hui",
                "last": "Liu",
                "affiliation": "Beijing Institute of Technology",
                "contact": true
            },
            {
                "email": "nan.niu@uc.edu",
                "first": "Nan",
                "last": "Niu",
                "affiliation": "University of Cincinnati",
                "contact": true
            },
            {
                "email": "yuxiazh@bit.edu.cn",
                "first": "Yuxia",
                "last": "Zhang",
                "affiliation": "Beijing Institute of Technology",
                "contact": true
            },
            {
                "email": "liguangjie_er@126.com",
                "first": "Guangjie",
                "last": "Li",
                "affiliation": "National Innovation Institute of Defense Technology",
                "contact": true
            },
            {
                "email": "yanjiejiang@bit.edu.cn",
                "first": "Yanjie",
                "last": "Jiang",
                "affiliation": "Beijing Institute of Technology",
                "contact": true
            }
        ],
        "topics": [
            "Maintenance and Evolution"
        ],
        "pc_conflicts": {
            "nan.niu@uc.edu": "author",
            "liuhui08@bit.edu.cn": "author",
            "mnayebi@yorku.ca": true,
            "zhonghao@sjtu.edu.cn": true,
            "shanshanli@nudt.edu.cn": true,
            "szy_@pku.edu.cn": true,
            "august@utexas.edu": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683183074,
        "modified_at": 1683374106,
        "tags": [
            "accept#0"
        ]
    },
    {
        "object": "paper",
        "pid": 172,
        "title": "ConfTainter: Static Taint Analysis For Configuration Options",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-78d1f5a124ba24b0d2952fd974315b33c938fa45de98de74243ed68963101073",
            "timestamp": 1683372139,
            "size": 519425,
            "pages": 12
        },
        "abstract": "The prevalence and severity of software configuration-induced issues have driven the design and development of a number of detection and diagnosis techniques. Many of these techniques need to perform static taint analysis on configuration-related variables to analyze the data flow, control flow, and execution paths given by configuration options. However, existing taint analysis or static slicer tools are not suitable for configuration analysis due to the complex effects of configuration on program behaviors.\r\n\r\nIn this paper, we conducted an empirical study on the propagation policy of configuration options. We concluded four rules of how configurations affect program behaviors, among which implicit data-flow and control-flow propagation are often ignored by existing tools. We report our experience designing and implementing a taint analysis infrastructure for configurations, ConfTainter. It can support various kinds of configuration analysis, e.g., explicit or implicit analysis for data or control flow. Based on the infrastructure, researchers and developers can easily implement analysis techniques for different configuration-related targets, e.g., misconfiguration detection. We evaluated the effectiveness of ConfTainter on 5 popular open-source systems. The result shows that the accuracy rate of data- and control-flow analysis is 96.1% and 97.7%, and the recall rate is 94.2% and 95.5%, respectively. We also apply ConfTainter to two types of configuration-related tasks: misconfiguration detection and configuration-related bug detection. The result shows that CONFTAINTER is highly applicable for configuration-related tasks with a few lines of code.",
        "authors": [
            {
                "email": "wangteng13@nudt.edu.cn",
                "first": "Teng",
                "last": "Wang",
                "affiliation": "National University of Defense Technology",
                "contact": true
            },
            {
                "email": "hehaochen13@nudt.edu.cn",
                "first": "Haochen",
                "last": "He",
                "affiliation": "National University of Defense Technology",
                "contact": true
            },
            {
                "email": "liuxiaodong@nudt.edu.cn",
                "first": "Xiaodong",
                "last": "Liu",
                "affiliation": "National University of Defense Technology",
                "contact": true
            },
            {
                "email": "shanshanli@nudt.edu.cn",
                "first": "Shanshan",
                "last": "Li",
                "affiliation": "National University of Defense Technology",
                "contact": true
            },
            {
                "email": "jiazhouyang@nudt.edu.cn",
                "first": "Zhouyang",
                "last": "Jia",
                "affiliation": "National University of Defense Technology",
                "contact": true
            },
            {
                "email": "jy1989@mail.tsinghua.edu.cn",
                "first": "Yu",
                "last": "Jiang",
                "affiliation": "Tsinghua University",
                "contact": true
            },
            {
                "email": "liaoqing@hit.edu.cn",
                "first": "Qing",
                "last": "Liao",
                "affiliation": "Harbin Institute of Technology",
                "contact": true
            },
            {
                "email": "liwang2015@nudt.edu.cn",
                "first": "Wang",
                "last": "Li",
                "affiliation": "National University of Defense Technology",
                "contact": true
            }
        ],
        "topics": [
            "Software Analytics"
        ],
        "pc_conflicts": {
            "gaocuiyun@hit.edu.cn": true,
            "mnayebi@yorku.ca": true,
            "shanshanli@nudt.edu.cn": "author"
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683335940,
        "modified_at": 1683374407,
        "tags": [
            "accept#0",
            "experience_paper#0"
        ]
    },
    {
        "object": "paper",
        "pid": 181,
        "title": "Compiler Auto-tuning via Critical Flag Selection",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-2980cbdefa28370aca8e8da2eb38d3ae030b89b7f7a6dd6f51821b3b9344d0e7",
            "timestamp": 1683373559,
            "size": 442897,
            "pages": 11
        },
        "abstract": "Widely used compilers like GCC usually have hundreds of optimizations controlled by optimization flags, which can be enabled or disabled during compilation to improve the runtime performance of a compiled program. Due to the large number of optimization flags and their combination, it is difficult for compiler users to tune compiler optimization flags manually. In the literature, many auto-tuning techniques have been proposed, which find a desired setting on all optimization flags (i.e., an optimization sequence) by designing different search strategies in the entire optimization space. Due to the huge search space, these techniques suffer from the widely-recognized efficiency problem. To reduce the search space, in this paper, we propose a critical-flag selection based approach CFSCA which first finds flags potentially relevant to the target program by analyzing program structure and compiler documentation, and then identifies critical flags through statistical analysis on the program’s predicted runtime performance with various optimization sequences. With the reduced search space, CFSCA selects a desired optimization sequence. To evaluate the performance of the proposed approach CFSCA, we conduct an extensive experimental study on the latest version of the compiler GCC with a widely used benchmark cBench. The experimental results show that CFSCA significantly outperforms the four compared techniques, including the state-of-art technique BOCA.",
        "authors": [
            {
                "email": "zhumingxuan@stu.pku.edu.cn",
                "first": "Mingxuan",
                "last": "Zhu",
                "affiliation": "Peking University",
                "contact": true
            },
            {
                "email": "haodan@pku.edu.cn",
                "first": "Dan",
                "last": "Hao",
                "affiliation": "Peking University",
                "contact": true
            }
        ],
        "topics": [
            "Maintenance and Evolution"
        ],
        "pc_conflicts": {
            "michael@binaervarianz.de": true,
            "junjiechen@tju.edu.cn": true,
            "zp.chen@ucl.ac.uk": true,
            "lingming@illinois.edu": true,
            "shihan@microsoft.com": true,
            "haodan@pku.edu.cn": "collaborator author",
            "xusheng.xiao@asu.edu": true,
            "ding_li@pku.edu.cn": true,
            "mark.harman@ucl.ac.uk": true,
            "louyiling610@gmail.com": true,
            "hongyujohn@gmail.com": true,
            "jie.zhang@kcl.ac.uk": true,
            "mnayebi@yorku.ca": true,
            "taoxie@pku.edu.cn": true,
            "wurongxin@xmu.edu.cn": true,
            "szy_@pku.edu.cn": true,
            "wangbo_cs@bjtu.edu.cn": true,
            "mwenaa@hust.edu.cn": true,
            "wangdi95@pku.edu.cn": true,
            "man.mzhang@gmail.com": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683120611,
        "modified_at": 1683373559,
        "tags": [
            "accept#0"
        ]
    },
    {
        "object": "paper",
        "pid": 192,
        "title": "Personalized First Issue Recommender for Newcomers in Open Source Projects",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-c1c11dc02bba001c2d9cd9f5df75e468ec5de3ed87b46543e6951f8ffc9bb35e",
            "timestamp": 1683374395,
            "size": 845392,
            "pages": 12
        },
        "abstract": "Open source projects often provide ``good first issues\" (GFIs) to attract and retain newcomers. Although several automatic GFI recommenders have been proposed, existing tools are limited to recommending generic GFIs without considering differences between individual newcomers. Cases show that genetic GFIs do not match newcomers' experience, availability, and preferences and result in their many failed attempts, discouraging their onboarding and delaying the issues' resolution. To address the problem, we assume that personalized first issues (PFIs) for newcomers could help reduce the mismatches. To justify the assumption, we first empirically analyze 37 newcomers' first issues resolved across multiple projects. We find that the first issues resolved by the same newcomer share similarities in task type, programming language, and project domain. These findings underscore the need for improving state-of-the-art approaches by proposing a PFI recommender. For that purpose, we identify features that influence newcomers' personalized selection of first issues by analyzing the relationship between possible features and the characteristics of the newcomers' chosen first issues. We find that the features of newcomers' expertise preference, OSS experience, activeness, and sentiment drive their personalized choice of the first issues. Based on these findings, we propose PFIRec, which employs the LamdaMART model to rank candidate issues for a given newcomer by leveraging the identified influential features. We evaluate PFIRec using a dataset of 68,858 issues from 100 GitHub projects. The evaluation results show that PFIRec outperforms existing first-issue recommenders, potentially doubling the probability that the top-recommended issue is suitable for a specific newcomer and reducing one-third of a newcomer's unsuccessful attempts to identify suitable first issues, in the median.",
        "authors": [
            {
                "email": "wenxin.xiao@stu.pku.edu.cn",
                "first": "Wenxin",
                "last": "Xiao",
                "affiliation": "Peking University",
                "contact": true
            },
            {
                "email": "jingyue.li@ntnu.no",
                "first": "Jingyue",
                "last": "Li",
                "affiliation": "Norwegian University of Science and Technology",
                "contact": true
            },
            {
                "email": "heh@pku.edu.cn",
                "first": "Hao",
                "last": "He",
                "affiliation": "Peking University",
                "contact": true
            },
            {
                "email": "1120192277@bit.edu.cn",
                "first": "Ruiqiao",
                "last": "Qiu",
                "affiliation": "Beijing Institute of Technology",
                "contact": true
            },
            {
                "email": "zhmh@pku.edu.cn",
                "first": "Minghui",
                "last": "Zhou",
                "affiliation": "Peking University",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering",
            "Human Aspects of Software Engineering",
            "Maintenance and Evolution"
        ],
        "pc_conflicts": {
            "zp.chen@ucl.ac.uk": true,
            "haodan@pku.edu.cn": true,
            "liuhui08@bit.edu.cn": true,
            "ding_li@pku.edu.cn": true,
            "louyiling610@gmail.com": true,
            "taoxie@pku.edu.cn": true,
            "shanshanli@nudt.edu.cn": true,
            "wangbo_cs@bjtu.edu.cn": true,
            "wangdi95@pku.edu.cn": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683373210,
        "modified_at": 1683374395,
        "tags": [
            "accept#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 193,
        "title": "EndWatch: A Practical Method for Detecting Non-Termination in Real-World Software",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-2dfd4f8d2a690da56c641329570f1c0ce08b5ea8e981a7113470453fe97543fa",
            "timestamp": 1683365623,
            "size": 754548,
            "pages": 11
        },
        "abstract": "Detecting non-termination is crucial for ensuring program correctness and security, such as preventing denial-of-service attacks. While termination analysis has been studied for many years, existing methods have limited scalability and are only effective on small programs. To address this issue, we propose a practical termination checking technique, called EndWatch, for detecting non-termination through testing. Specifically, we introduce two methods to generate non-termination oracles based on checking state revisits, i.e., if the program returns to a previously visited state at the same program location, it does not terminate. The non-termination oracles can be incorporated into testing tools (e.g., AFL used in this paper) to detect non- termination in large programs. For linear loops, we perform symbolic execution on individual loops to infer State Revisit Conditions (SRC) and instrument SRC into target loops. For non-linear loops, we instrument target loops for checking concrete state revisits during execution. We evaluated EndWatch on standard benchmarks with small-sized programs and real-world projects with large-sized programs. The evaluation results show that EndWatch is more effective than the state-of-the-art tools on standard benchmarks (detecting 87% of non-terminating programs while the best baseline detects only 67%), and useful in detecting non-termination in real-world projects (detecting 90% of known non-termination CVEs and 4 unknown bugs).",
        "authors": [
            {
                "email": "zzyy@tju.edu.cn",
                "first": "Yao",
                "last": "Zhang",
                "affiliation": "College of Intelligence and Computing, Tianjin University, China",
                "contact": true
            },
            {
                "email": "xfxie@smu.edu.sg",
                "first": "Xiaofei",
                "last": "Xie",
                "affiliation": "Singapore Management University",
                "contact": true
            },
            {
                "email": "yi_li@ntu.edu.sg",
                "first": "Yi",
                "last": "Li",
                "affiliation": "Nanyang Technological University",
                "contact": true
            },
            {
                "email": "senchen@tju.edu.cn",
                "first": "Sen",
                "last": "Chen",
                "affiliation": "Tianjin University",
                "contact": true
            },
            {
                "email": "cen001@e.ntu.edu.sg",
                "first": "Cen",
                "last": "Zhang",
                "affiliation": "Nanyang Technological University",
                "contact": true
            },
            {
                "email": "xiaohongli@tju.edu.cn",
                "first": "Xiaohong",
                "last": "Li",
                "affiliation": "Tianjin University",
                "contact": true
            }
        ],
        "topics": [
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "junsun@smu.edu.sg": true,
            "junjiechen@tju.edu.cn": true,
            "chunyang.chen@monash.edu": true,
            "y.tian@queensu.ca": true,
            "shaowei.wang@umanitoba.ca": true,
            "senchen@tju.edu.cn": "author",
            "shuaiw@cse.ust.hk": true,
            "xfxie@smu.edu.sg": "author",
            "gaocuiyun@hit.edu.cn": true,
            "ma.lei@acm.org": true,
            "lilicoding@ieee.org": true,
            "linglingfan@nankai.edu.cn": true,
            "mnayebi@yorku.ca": true,
            "davidlo@smu.edu.sg": true,
            "y.sui@unsw.edu.au": true,
            "jiangjiajun@tju.edu.cn": true,
            "tsu@sei.ecnu.edu.cn": true,
            "yli044@e.ntu.edu.sg": true,
            "mengguozhu@iie.ac.cn": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1691861742,
        "modified_at": 1691861742,
        "tags": [
            "dpa_candidate#0",
            "dpa_yes#0"
        ]
    },
    {
        "object": "paper",
        "pid": 195,
        "title": "Demystifying Template-based Invariant Generation for Bit-Vector Programs",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-8785585146f959e3eed26c0c80dade6145849be5331f1ff538bfce3a3769d778",
            "timestamp": 1683376107,
            "size": 342652,
            "pages": 12
        },
        "abstract": "The template-based approach to invariant generation is a parametric and relatively complete methodology for loop invariant inference. The relative completeness ensures the accuracy of the generated invariants up to the form of the template and the inductive condition. However, little progress has been made in advancing the approach to bit-precise reasoning, which involves modeling integers using bit-vector arithmetic. This is unfortunate because bit-precise reasoning is important for faithfully and accurately modeling machine integer semantics and, thus, for sound and precise program verification. \r\n\r\nThis paper presents an experimental study of bit-precise, template-based invariant generation on three fronts: the precision of different invariant templates, the performance of different constraint solvers for solving the constraints; and the effectiveness of the template-based approach compared to existing bit-precise verification techniques. By an extensive experimental evaluation over a wide range of benchmarks, we find that (1) have varying degrees of impact on the precision and efficiency of invariant generation. (2) the template-based approaches can handle benchmarks that other approaches for bit-vectors cannot handle, demonstrating the effectiveness of such approaches. The results also reveal several guidelines for advancing future research on template-based invariant generation.",
        "authors": [
            {
                "email": "pyaoaa@zju.edu.cn",
                "first": "Peisen",
                "last": "Yao",
                "affiliation": "Zhejiang University",
                "contact": true
            },
            {
                "email": "Windocotber@sjtu.edu.cn",
                "first": "Jingyu",
                "last": "Ke",
                "affiliation": "Shanghai Jiao Tong University",
                "contact": true
            },
            {
                "email": "jasonj@zju.edu.cn",
                "first": "Jiahui",
                "last": "Sun",
                "affiliation": "Zhejiang University"
            },
            {
                "email": "fuhf@cs.sjtu.edu.cn",
                "first": "Hongfei",
                "last": "Fu",
                "affiliation": "Shanghai Jiao Tong University",
                "contact": true
            },
            {
                "email": "wurongxin@xmu.edu.cn",
                "first": "Rongxin",
                "last": "Wu",
                "affiliation": "Xiamen University",
                "contact": true
            },
            {
                "email": "kuiren@zju.edu.cn",
                "first": "Kui",
                "last": "Ren",
                "affiliation": "Zhejiang University",
                "contact": true
            }
        ],
        "topics": [
            "Formal Aspects of Software Engineering",
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "junsun@smu.edu.sg": true,
            "junjiechen@tju.edu.cn": true,
            "xin.xia@acm.org": true,
            "changxu@nju.edu.cn": true,
            "shuaiw@cse.ust.hk": true,
            "haodan@pku.edu.cn": true,
            "hongyujohn@gmail.com": true,
            "wangying@swc.neu.edu.cn": true,
            "mnayebi@yorku.ca": true,
            "taoxie@pku.edu.cn": true,
            "zhonghao@sjtu.edu.cn": true,
            "wurongxin@xmu.edu.cn": "author",
            "xinghu@zju.edu.cn": true,
            "mwenaa@hust.edu.cn": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683373935,
        "modified_at": 1683816025,
        "tags": [
            "accept#0",
            "experience_paper#0"
        ]
    },
    {
        "object": "paper",
        "pid": 201,
        "title": "An Image is Worth a Thousand Toxic Words: A Metamorphic Testing Framework for Content Moderation Software",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-933f6c00744d04790c766bcb40dc66f529e2fb3f5579ac4363fe6296eb204389",
            "timestamp": 1683370002,
            "size": 678511,
            "pages": 12
        },
        "abstract": "The exponential growth of social media platforms has brought about a revolution in communication and content dissemination in human society.\r\nNevertheless, these platforms are being increasingly misused to spread toxic content, including hate speech, malicious advertising, and pornography, leading to severe negative consequences such as harm to teenagers' mental health.\r\nDespite tremendous efforts in developing and deploying textual and image content moderation methods, malicious users can evade moderation by embedding texts into images, such as screenshots of the text, usually with some interference.\r\nWe find that modern content moderation software's performance against such malicious inputs remains underexplored.\r\nIn this work, we propose OASIS, a metamorphic testing framework for content moderation software.\r\nOASIS employs 21 transform rules summarized from our pilot study on 5,000 real-world toxic contents collected from 4 popular social media applications, including Twitter, Instagram, Sina Weibo, and Baidu Tieba.\r\nGiven toxic textual contents, OASIS can generate image test cases, which preserve the toxicity yet are likely to bypass moderation.\r\nIn the evaluation, we employ OASIS to test five commercial textual content moderation software from famous companies (i.e., Google Cloud, Microsoft Azure, Baidu Cloud, Alibaba Cloud and Tencent Cloud), as well as a state-of-the-art moderation research model.\r\nThe results show that OASIS achieves up to 100% error finding rates.\r\nMoreover, through retraining the models with the test cases generated by OASIS, the robustness of the moderation model can be improved without performance degradation.\r\nA demo can be found in https:\/\/204.236.128.207\/.",
        "authors": [
            {
                "email": "1155156767@link.cuhk.edu.hk",
                "first": "Wenxuan",
                "last": "Wang",
                "affiliation": "The Chinese University of Hong Kong",
                "contact": true
            },
            {
                "email": "1155173905@link.cuhk.edu.hk",
                "first": "Jingyuan",
                "last": "Huang",
                "affiliation": "The Chinese University of Hong Kong"
            },
            {
                "email": "jthuang@cse.cuhk.edu.hk",
                "first": "Jen-tse",
                "last": "Huang",
                "affiliation": "The Chinese University of Hong Kong",
                "contact": true
            },
            {
                "email": "ccchen@link.cuhk.edu.hk",
                "first": "Chang",
                "last": "Chen",
                "affiliation": "The Chinese University of Hong Kong"
            },
            {
                "email": "jiazhengu@cuhk.edu.hk",
                "first": "Jiazhen",
                "last": "Gu",
                "affiliation": "The Chinese University of Hong Kong",
                "contact": true
            },
            {
                "email": "hepinjia@cuhk.edu.cn",
                "first": "Pinjia",
                "last": "He",
                "affiliation": "The Chinese University of Hong Kong, Shenzhen",
                "contact": true
            },
            {
                "email": "lyu@cse.cuhk.edu.hk",
                "first": "Michael R.",
                "last": "Lyu",
                "affiliation": "The Chinese University of Hong Kong",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering"
        ],
        "pc_conflicts": {
            "junsun@smu.edu.sg": true,
            "junjiechen@tju.edu.cn": true,
            "tianyi@purdue.edu": true,
            "xin.xia@acm.org": true,
            "shuaiw@cse.ust.hk": true,
            "xfxie@smu.edu.sg": true,
            "gaocuiyun@hit.edu.cn": true,
            "ma.lei@acm.org": true,
            "hongyujohn@gmail.com": true,
            "linglingfan@nankai.edu.cn": true,
            "mnayebi@yorku.ca": true,
            "davidlo@smu.edu.sg": true,
            "taoxie@pku.edu.cn": true,
            "y.sui@unsw.edu.au": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683366172,
        "modified_at": 1683371842,
        "tags": [
            "accept#0"
        ]
    },
    {
        "object": "paper",
        "pid": 207,
        "title": "InfeRE: Step-by-Step Regex Generation via Chain of Inference",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-307023d1b6053e3c6aaaa0cdcdc362194b75c30f5d01a236e59996846fa9b6a4",
            "timestamp": 1683374178,
            "size": 1320113,
            "pages": 11
        },
        "abstract": "Automatically generating regular expressions (abbrev. regexes) from natural language description (NL2RE) has been an emerging research area. Prior studies treat regex as a linear sequence of tokens and generate the final expressions autoregressively in a single pass. They did not take into account the step-by-step internal text-matching processes behind the final results. This significantly hinders the efficacy and interpretability of regex generation by neural language models. In this paper, we propose a new paradigm called InfeRE, which decomposes the generation of regexes into chains of step-by-step inference. To enhance the robustness, we introduce a self-consistency decoding mechanism that ensembles multiple outputs sampled from different models. We evaluate InfeRE on two publicly available datasets, NL-RX-Turk and KB13, and compare the results with state-of-the-art approaches and the popular tree-based generation approach TRANX. Experimental results show that InfeRE substantially outperforms previous baselines, yielding 16.3% and 14.7% improvement in DFA@5 accuracy on two datasets, respectively. Particularly, InfeRE outperforms the popular tree-based generation approach by 18.1% and 11.3% on both datasets, respectively, in terms of DFA@5 accuracy.",
        "authors": [
            {
                "email": "zhangshuai2000@sjtu.edu.cn",
                "first": "Shuai",
                "last": "Zhang",
                "affiliation": "School of Software, Shanghai Jiao Tong University",
                "contact": true
            },
            {
                "email": "xiaodong.gu@sjtu.edu.cn",
                "first": "Xiaodong",
                "last": "Gu",
                "affiliation": "Shanghai Jiao Tong University",
                "contact": true
            },
            {
                "email": "bjshen@sjtu.edu.cn",
                "first": "Beijun",
                "last": "Shen",
                "affiliation": "School of Software, Shanghai Jiao Tong University",
                "contact": true
            },
            {
                "email": "chenyt@sjtu.edu.cn",
                "first": "Yuting",
                "last": "Chen",
                "affiliation": "Shanghai Jiao Tong University",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering"
        ],
        "pc_conflicts": {
            "mnayebi@yorku.ca": true,
            "zhonghao@sjtu.edu.cn": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683371314,
        "modified_at": 1683374178,
        "tags": [
            "accept#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 222,
        "title": "Let's Chat to Find the APIs: Connecting Human, LLM and Knowledge Graph through AI Chain",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-c1983a363f2f6ea950d3f55968ffd95fc61dc83fce50edce3a2bdaaf0c5eed3f",
            "timestamp": 1683353858,
            "size": 452464,
            "pages": 12
        },
        "abstract": "API recommendation methods have evolved from literal and semantic keyword matching to query expansion and query clarification. \r\nThe latest query clarification method is knowledge graph (KG)-based, but limitations include out-of-vocabulary (OOV) failures and rigid question templates. \r\nTo address these limitations, we propose a novel knowledge-guided query clarification approach for API recommendation that leverages a large language model (LLM) guided by KG. \r\nWe utilize the LLM as a neural knowledge base to overcome OOV failures, generating fluent and appropriate clarification questions and options. \r\nWe also leverage the structured API knowledge and entity relationships stored in the KG to filter out noise, and transfer the optimal clarification path from KG to the LLM, increasing the efficiency of the clarification process.\r\nOur approach is designed as an AI chain that consists of five steps, each handled by a separate LLM call, to improve accuracy, efficiency, and fluency for query clarification in API recommendation.\r\nWe verify the usefulness of each unit in our AI chain, which all received high scores close to a perfect 5.\r\nWhen compared to the baselines, our approach shows a significant improvement in MRR, with a maximum increase of 63.9\\% higher when the query statement is covered in KG and 37.2\\% when it is not.\r\nAblation experiments reveal that the guidance of knowledge in the KG and the knowledge-guided pathfinding strategy are crucial for our approach's performance, resulting in a 19.0\\% and 22.2\\% increase in MAP, respectively.\r\nOur approach demonstrates a way to bridge the gap between KG and LLM, effectively compensating for the strengths and weaknesses of both.",
        "authors": [
            {
                "email": "qh@whu.edu.cn",
                "first": "Qing",
                "last": "Huang",
                "affiliation": "Jiangxi Normal University",
                "contact": true
            },
            {
                "email": "wanzy@jxnu.edu.cn",
                "first": "Zhenyu",
                "last": "Wan",
                "affiliation": "Jiangxi Normal University",
                "contact": true
            },
            {
                "email": "zhenchang.xing@data61.csiro.au",
                "first": "Zhenchang",
                "last": "Xing",
                "affiliation": "CSIRO's Data61 & Australian National University",
                "contact": true
            },
            {
                "email": "wcj771006@163.com",
                "first": "Changjing",
                "last": "Wang",
                "affiliation": "Jiangxi Normal University",
                "contact": true
            },
            {
                "email": "jieshan.chen@data61.csiro.au",
                "first": "Jieshan",
                "last": "Chen",
                "affiliation": "CSIRO's Data61",
                "contact": true
            },
            {
                "email": "xiwei.xu@data61.csiro.au",
                "first": "Xiwei",
                "last": "Xu",
                "affiliation": "Data61, CSIRO",
                "contact": true
            },
            {
                "email": "qinghua.lu@data61.csiro.au",
                "first": "Qinghua",
                "last": "Lu",
                "affiliation": "Data61, CSIRO",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering",
            "Maintenance and Evolution"
        ],
        "pc_conflicts": {
            "junsun@smu.edu.sg": true,
            "chunyang.chen@monash.edu": true,
            "xin.xia@acm.org": true,
            "glewis@sei.cmu.edu": true,
            "mnayebi@yorku.ca": true,
            "davidlo@smu.edu.sg": true,
            "jieshan.chen@data61.csiro.au": "author",
            "tsu@sei.ecnu.edu.cn": true,
            "ozkaya@sei.cmu.edu": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1682505690,
        "modified_at": 1683355071,
        "tags": [
            "accept#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 224,
        "title": "PHYFU: Fuzzing Modern Physics Simulation Engines",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-d7d3897083eff12f6a0a94a81e86e44202b9df6a77a698f3f24ecebcd4edfee3",
            "timestamp": 1683286268,
            "size": 642141,
            "pages": 12
        },
        "abstract": "A physical simulation engine (PSE) is a software system that simulates physical environments and objects. Modern PSEs feature both forward and backward simulations, where the forward phase predicts the behavior of a simulated system, and the backward phase provides gradients (guidance) for learning-based control tasks, such as a robot arm learning to fetch items. This way, modern PSEs show promising support for learning-based control methods. To date, PSEs have been largely used in various high-profitable, commercial applications, such as games, movies, virtual reality (VR), and robotics. Despite the prosperous development and usage of PSEs by academia and industrial manufacturers such as Google and NVIDIA, PSEs may produce incorrect simulations, which may lead to negative results, from poor user experience in entertainment to accidents in robotics-involved manufacturing and surgical operations.\r\n\r\nThis paper introduces PHYFU, a fuzzing framework designed specifically for PSEs to uncover errors in both forward and backward simulation phases. PHYFU mutates initial states and asserts if the PSE under test behaves consistently with respect to basic Physics Laws (PLs). We further use feedback-driven test input scheduling to guide and accelerate the search for errors. Our study of four PSEs covers mainstream industrial vendors (Google and NVIDIA) as well as academic products. We successfully uncover over 5K error-triggering inputs that generate incorrect simulation results spanning across the whole software stack of PSEs.",
        "authors": [
            {
                "email": "dxiaoad@cse.ust.hk",
                "first": "Dongwei",
                "last": "Xiao",
                "affiliation": "The Hong Kong University of Science and Technology",
                "contact": true
            },
            {
                "email": "zliudc@cse.ust.hk",
                "first": "Zhibo",
                "last": "Liu",
                "affiliation": "The Hong Kong University of Science and Technology",
                "contact": true
            },
            {
                "email": "shuaiw@cse.ust.hk",
                "first": "Shuai",
                "last": "Wang",
                "affiliation": "The Hong Kong University of Science and Technology",
                "contact": true
            }
        ],
        "topics": [
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "pwng@google.com": true,
            "shuaiw@cse.ust.hk": "author",
            "xfxie@smu.edu.sg": true,
            "gaocuiyun@hit.edu.cn": true,
            "ma.lei@acm.org": true,
            "taoyue@gmail.com": true,
            "csxluo@comp.polyu.edu.hk": true,
            "wangying@swc.neu.edu.cn": true,
            "mnayebi@yorku.ca": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683362885,
        "modified_at": 1683362885,
        "tags": [
            "accept#0",
            "dpa_candidate#0",
            "dpa_yes#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 227,
        "title": "Fuzzing for CPS Mutation Testing",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-b05d12cb6f5fa581d57407684ec708e77cf974e4d083033c803d14ea77fa885a",
            "timestamp": 1683275693,
            "size": 1202536,
            "pages": 12
        },
        "abstract": "Mutation testing can help reduce the risks of releasing faulty software. For such reason, it is a desired practice for the development of embedded software running in safety-critical cyber-physical systems (CPS). \r\nUnfortunately, state-of-the-art test data generation techniques for mutation testing of C and C++ software, two typical languages for CPS software, rely on symbolic execution, whose limitations often prevent its application (e.g., cannot test black-box components).\r\n\r\nWe propose a mutation testing approach that leverages fuzz testing, which has proved effective with C and C++ software. Fuzz testing automatically generates diverse test inputs that exercise program branches in a varied number of ways and, therefore, exercise statements in different program states, thus maximizing the likelihood of killing mutants, our objective.\r\n\r\nWe performed an empirical assessment of our approach with software components used in satellite systems currently in orbit. Our empirical evaluation shows that mutation testing based on fuzz testing kills a significantly higher proportion of live mutants than symbolic execution (i.e., up to 47 percentage points higher). Further, when symbolic execution cannot be applied, fuzz testing provides significant benefits (i.e., up to 45% mutants killed). Our study is the first one comparing fuzz testing and symbolic execution for mutation testing; our results provide guidance towards the development of fuzz testing tools dedicated to mutation testing.",
        "authors": [
            {
                "email": "jaekwon.lee@uni.lu",
                "first": "Jaekwon",
                "last": "Lee",
                "affiliation": "University of Luxembourg",
                "contact": true
            },
            {
                "email": "enrico.vigano@uni.lu",
                "first": "Enrico",
                "last": "Vigano",
                "affiliation": "University of Luxembourg",
                "contact": true
            },
            {
                "email": "o.cornejo.o@gmail.com",
                "first": "Oscar",
                "last": "Cornejo",
                "affiliation": "University of Luxembourg",
                "contact": true
            },
            {
                "email": "fabrizio.pastore@uni.lu",
                "first": "Fabrizio",
                "last": "Pastore",
                "affiliation": "University of Luxembourg",
                "contact": true
            },
            {
                "email": "lionel.briand@uni.lu",
                "first": "Lionel",
                "last": "Briand",
                "affiliation": "University of Luxembourg & University of Ottawa",
                "contact": true
            }
        ],
        "topics": [
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "pcorina@cmu.edu": true,
            "kevin.allix@centralesupelec.fr": true,
            "M.Sabetzadeh@uottawa.ca": true,
            "taoyue@gmail.com": true,
            "lilicoding@ieee.org": true,
            "hemmati@yorku.ca": true,
            "domenico.bianculli@uni.lu": true,
            "leonardo.mariani@unimib.it": true,
            "fabrizio.pastore@uni.lu": "author",
            "snejati@uottawa.ca": true,
            "renzo.degiovanni@uni.lu": true,
            "d.shin@sheffield.ac.uk": true,
            "sahraouh@iro.umontreal.ca": true,
            "ezekiel.soremekun@rhul.ac.uk": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1682956375,
        "modified_at": 1683275693,
        "tags": [
            "accept#0"
        ]
    },
    {
        "object": "paper",
        "pid": 230,
        "title": "PTdetector: An Automated JavaScript Front-end Library Detector",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-74fa318e4b53b560ccb5445195ee8addc0772f60e1782d1217bf0c84f44e9813",
            "timestamp": 1683313253,
            "size": 1323837,
            "pages": 11
        },
        "abstract": "Identifying what front-end library runs on a web page is challenging. Although many mature detectors exist on the market, they suffer from false positives and the inability to detect libraries bundled by packers such as Webpack. Most importantly, the detection features they use are collected from developers' knowledge leading to an inefficient manual workflow and a large number of libraries that the existing detectors cannot detect. This paper introduces PTdetecor, which provides the first automated method to generate features and detect libraries on web pages. We propose a novel data structure, the pTree, which we use as a detection feature. The pTree is well-suited for automation and addresses the limitations of existing detectors. We implement PTdetecor as a browser extension and test it on 200 top-traffic websites. Our experiments show that PTdetecor can identify packer-bundled libraries, and its detection results outperform existing tools.",
        "authors": [
            {
                "email": "xliu234@buffalo.edu",
                "first": "Xinyue",
                "last": "Liu",
                "affiliation": "University at Buffalo, SUNY",
                "contact": true
            },
            {
                "email": "lziarek@buffalo.edu",
                "first": "Lukasz",
                "last": "Ziarek",
                "affiliation": "The State University of New York",
                "contact": true
            }
        ],
        "supplementary_material": {
            "mimetype": "application\/zip",
            "hash": "sha2-81c21f51f526ae1d8542f17df6367db522d1aa427362e4c1f84012c66a3be6f9",
            "timestamp": 1683255604,
            "size": 1221937,
            "filename": "data.zip"
        },
        "topics": [
            "Software Analytics",
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "hemmati@yorku.ca": true,
            "mnayebi@yorku.ca": true,
            "wangsong@yorku.ca": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1682553270,
        "modified_at": 1683313253,
        "tags": [
            "accept#0"
        ]
    },
    {
        "object": "paper",
        "pid": 237,
        "title": "SMT Solver Validation Empowered by Large Pre-trained Language Models",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-4b3352e6cd01bc2696566c3471666f190d1f936d1e0e04d6b43d1758a37490b1",
            "timestamp": 1683827795,
            "size": 447241,
            "pages": 12
        },
        "abstract": "SMT solvers are utilized to check the satisfiability of logic formulas and have been applied in various crucial domains, including software verification, test case generation, and program synthesis. However, bugs hidden in SMT solvers can lead to severe consequences, causing erroneous results in these domains. Therefore, ensuring the reliability and robustness of SMT solvers is of critical importance. Despite a number of testing approaches proposed for SMT solvers, generating effective test formulas to comprehensively test SMT solvers remains a challenge. To address this challenge, in this study, we propose to port large pre-trained language models (LLMs) to generate SMT formulas for fuzzing solvers. Specifically, the study presents a novel retrain-finetune pipeline to unleash the potential of language models to generate effective SMT formulas and improve their generation performance through data augmentation. We implemented our approach as a practical fuzzing tool, named DETECT, and then extensively tested the state-of-the-art SMT solvers, namely Z3, cvc5, and Bitwuzla. To date, DETECT has successfully uncovered 65 new bugs for the solvers, of which 43 have been fixed by the developers.",
        "authors": [
            {
                "email": "merlinsun7@gmail.com",
                "first": "Maolin",
                "last": "Sun",
                "affiliation": "National Key Laboratory for Novel Software Technology, Nanjing University",
                "contact": true
            },
            {
                "email": "yangyibiao@nju.edu.cn",
                "first": "Yibiao",
                "last": "Yang",
                "affiliation": "National Key Laboratory for Novel Software Technology, Nanjing University",
                "contact": true
            },
            {
                "email": "njuwy@smail.nju.edu.cn",
                "first": "Yang",
                "last": "Wang",
                "affiliation": "National Key Laboratory for Novel Software Technology, Nanjing University",
                "contact": true
            },
            {
                "email": "mwenaa@hust.edu.cn",
                "first": "Ming",
                "last": "WEN",
                "affiliation": "Huazhong University of Science and Technology",
                "contact": true
            },
            {
                "email": "haoxiangjia@hust.edu.cn",
                "first": "Haoxiang",
                "last": "Jia",
                "affiliation": "Huazhong University of Science and Technology",
                "contact": true
            },
            {
                "email": "zhouyuming@nju.edu.cn",
                "first": "Yuming",
                "last": "Zhou",
                "affiliation": "National Key Laboratory for Novel Software Technology, Nanjing University",
                "contact": true
            }
        ],
        "topics": [
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "junjiechen@tju.edu.cn": true,
            "lingming@illinois.edu": true,
            "fengyang@nju.edu.cn": true,
            "changxu@nju.edu.cn": true,
            "haodan@pku.edu.cn": true,
            "taoyue@gmail.com": true,
            "mark.harman@ucl.ac.uk": true,
            "louyiling610@gmail.com": true,
            "fangchunrong@nju.edu.cn": true,
            "mnayebi@yorku.ca": true,
            "yutian.tang@glasgow.ac.uk": true,
            "wurongxin@xmu.edu.cn": true,
            "xyzhang@cs.purdue.edu": true,
            "juanzhai@umass.edu": true,
            "mwenaa@hust.edu.cn": "author",
            "jyy@nju.edu.cn": true,
            "zqzuo@nju.edu.cn": true,
            "why@nju.edu.cn": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683367151,
        "modified_at": 1683827795,
        "tags": [
            "accept#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 241,
        "title": "CoMSA: A modeling driven sampling approach for configuration performance testing",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-eb85c2f53c2803880203e3b243e62948028224982b597928fb59333bd87fb434",
            "timestamp": 1683341872,
            "size": 331716,
            "pages": 11
        },
        "abstract": "Highly configurable systems enable customers to flexibly configure the systems in diverse deployment environments. The flexibility of configurations also poses challenges for performance testing. On one hand, there exist a massive number of possible configurations; while on the other hand, the time and resources are limited for performance testing, which is already a costly process during software development. Modeling the performance of configurations is one of the solutions to reduce the cost of configuration performance testing. Although prior research proposes various modeling and sampling techniques to build configuration performance models, the sampling approaches used in the model typically do not consider the accuracy of the performance models, leading to potential sub-optimal performance modeling results in practice. In this paper, we present a modeling driven sampling approach (CoMSA) to improve the performance modeling of highly configurable systems. The intuition of CoMSA is to select samples based on their uncertainties to the performance models. In other words, the configurations that have the more uncertain performance prediction results by the performance models are more likely to be selected as further training samples to improve the model. CoMSA is designed by considering both scenarios where 1) the software projects do not have historical performance testing results (cold start) and 2) there exist historical performance testing results (warm start). We evaluate the performance of our approach in four subjects, namely LRZIP, LLVM, x264, and SQLite. Through the evaluation result, we can conclude that our sampling approaches could highly enhance the accuracy of the prediction models and the efficiency of configuration performance testing compared to other baseline sampling approaches.",
        "authors": [
            {
                "email": "X_YUANJI@encs.concordia.ca",
                "first": "Yuanjie",
                "last": "Xia",
                "affiliation": "Concordia University",
                "contact": true
            },
            {
                "email": "zi_ding@encs.concordia.ca",
                "first": "Zishuo",
                "last": "Ding",
                "affiliation": "Concordia University",
                "contact": true
            },
            {
                "email": "shang@encs.concordia.ca",
                "first": "Weiyi",
                "last": "Shang",
                "affiliation": "Concordia University",
                "contact": true
            }
        ],
        "topics": [
            "Maintenance and Evolution",
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "shang@encs.concordia.ca": "collaborator author",
            "y.tian@queensu.ca": true,
            "shaowei.wang@umanitoba.ca": true,
            "xin.xia@acm.org": true,
            "ma.lei@acm.org": true,
            "tazhang@must.edu.mo": true,
            "zi_ding@encs.concordia.ca": "author",
            "yxtvse@rit.edu": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683338808,
        "modified_at": 1683341872,
        "tags": [
            "FeCoI#0",
            "invalid_abstract#0"
        ]
    },
    {
        "object": "paper",
        "pid": 245,
        "title": "The Plastic Surgery Hypothesis in the Era of Large Language Models",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-68bd7535145e7be4654bf9a148af1563a917ad50c74e59883c25b9b15ae400d3",
            "timestamp": 1683339630,
            "size": 984040,
            "pages": 12
        },
        "abstract": "Automated Program Repair (APR) aspires to automatically generate patches for an input buggy program with traditional APR tools typically focus on specific bug types and fixes through the use of templates, heuristics, and formal specifications. However, these techniques are limited in terms of the bug types and patch variety they can produce. As such, researchers have designed various learning-based APR tools with recent work focused on directly using Large Language Models (LLMs) for APR. While LLM-based APR tools are able to achieve state-of-the-art performance on many repair datasets, the LLMs used for direct repair are not fully aware of the project-specific information such as unique variable or method names.\r\n\r\nThe plastic surgery hypothesis is a well-known insight for APR, which states that the code ingredients to fix the bug usually already exist within the same project. Traditional APR tools have largely leveraged the plastic surgery hypothesis by designing manual or heuristic-based approaches to exploit such existing code ingredients. However, as recent APR research starts focusing on LLM-based approaches, the plastic surgery hypothesis has been largely ignored. In this paper, we ask the following question: How useful is the plastic surgery hypothesis in the era of LLMs? Interestingly, LLM-based APR presents a unique opportunity to fully automate the plastic surgery hypothesis via fine-tuning and prompting. To this end, we propose FitRepair, which combines the direct usage of LLMs with two domain-specific fine-tuning strategies and one prompting strategy for more powerful APR. Our experiments on the widely studied Defects4j 1.2 and 2.0 datasets show that FitRepair fixes 89 and 44 bugs (substantially outperforming the best-performing baseline by 15 and 8), respectively, demonstrating a promising future of the plastic surgery hypothesis in the era of LLMs.",
        "authors": [
            {
                "email": "chunqiu2@illinois.edu",
                "first": "Chunqiu Steven",
                "last": "Xia",
                "affiliation": "UIUC",
                "contact": true
            },
            {
                "email": "yifeng6@illinois.edu",
                "first": "Yifeng",
                "last": "Ding",
                "affiliation": "UIUC",
                "contact": true
            },
            {
                "email": "lingming@illinois.edu",
                "first": "Lingming",
                "last": "Zhang",
                "affiliation": "UIUC",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering",
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "rayb@cs.columbia.edu": true,
            "dposhyvanyk@gmail.com": true,
            "michael@binaervarianz.de": true,
            "junjiechen@tju.edu.cn": true,
            "zp.chen@ucl.ac.uk": true,
            "lingming@illinois.edu": "author",
            "j.bell@northeastern.edu": true,
            "haodan@pku.edu.cn": true,
            "xusheng.xiao@asu.edu": true,
            "mark.harman@ucl.ac.uk": true,
            "louyiling610@gmail.com": true,
            "fangchunrong@nju.edu.cn": true,
            "jie.zhang@kcl.ac.uk": true,
            "mnayebi@yorku.ca": true,
            "taoxie@pku.edu.cn": true,
            "guowei.yang@uq.edu.au": true,
            "szy_@pku.edu.cn": true,
            "xiaoyin.wang@utsa.edu": true,
            "august@utexas.edu": true,
            "jiangjiajun@tju.edu.cn": true,
            "mwenaa@hust.edu.cn": true,
            "kpmoran@ucf.edu": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683339630,
        "modified_at": 1683351630,
        "tags": [
            "accept#0"
        ]
    },
    {
        "object": "paper",
        "pid": 248,
        "title": "Pluggable Type Inference for Free",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-11108de2812e8cb2fe47918ce16a60ca4ea8dd7bd1e21566c06f37a39d873f52",
            "timestamp": 1683324798,
            "size": 325662,
            "pages": 12
        },
        "abstract": "A pluggable type system extends a host programming language with type qualifiers.\r\nIt lets programmers write types like \\<unsigned int>, \\<secret\r\nstring>, and \\<nonnull object>.\r\nTypechecking with pluggable types detects and prevents more errors than\r\nthe host type system.\r\nHowever, the need for programmers to write type qualifiers is\r\nthe biggest obstacle to use of pluggable types in practice.\r\nType inference can solve this problem.\r\nTraditional approaches to type inference are type-system-specific:\r\nfor each new pluggable type system, the type inference algorithm\r\nmust be extended to\r\nbuild and then solve a system\r\nof constraints corresponding to the rules of the underlying type system.\r\n\r\nWe propose a novel type inference algorithm\r\nthat can infer type qualifiers for \\emph{any} pluggable\r\ntype system with little to no new type-system-specific code---that is, ``for free''.\r\nThe key insight is that extant practical pluggable type systems are\r\nflow-sensitive and therefore already implement local type inference.\r\nUsing this insight, we can derive a global inference algorithm by re-using existing implementations\r\nof local inference.\r\nOur algorithm runs iteratively in rounds.\r\nEach round uses the results of local type inference to produce summaries (specifications)\r\nfor procedures and fields. These summaries enable improved inference throughout\r\nthe program in subsequent rounds.  The algorithm terminates when the inferred summaries reach a fixed point.\r\n\r\nIn practice, many pluggable type systems are built on frameworks. By implementing our\r\nalgorithm \\emph{once}, at the framework level, it can be reused by \\emph{any} typechecker\r\nbuilt using that framework. Using that insight,\r\nwe have implemented our algorithm\r\nin an open-source framework that supports both type checking and type inference.\r\nIn experiments with 11 distinct\r\npluggable type systems and 12 projects, our algorithm\r\nreduced, by 45\\%\r\non average, the number of warnings that developers must resolve\r\nby writing annotations.",
        "authors": [
            {
                "email": "martin.kellogg@njit.edu",
                "first": "Martin",
                "last": "Kellogg",
                "affiliation": "New Jersey Institute of Technology",
                "contact": true
            },
            {
                "email": "dd482@njit.edu",
                "first": "Daniel",
                "last": "Daskiewicz",
                "affiliation": "New Jersey Institute of Technology",
                "contact": true
            },
            {
                "email": "ln3@njit.edu",
                "first": "Loi Ngo Duc",
                "last": "Nguyen",
                "affiliation": "New Jersey Institute of Technology"
            },
            {
                "email": "ma234@njit.edu",
                "first": "Muyeed",
                "last": "Ahmed",
                "affiliation": "New Jersey Institute of Technology",
                "contact": true
            },
            {
                "email": "mernst@cs.washington.edu",
                "first": "Michael D.",
                "last": "Ernst",
                "affiliation": "UW CSE",
                "contact": true
            }
        ],
        "topics": [
            "Dependability, Safety, and Reliability",
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "hridesh@iastate.edu": true,
            "xin.xia@acm.org": true,
            "alessandra.gorla@imdea.org": true,
            "rma@fe.up.pt": true,
            "mnayebi@yorku.ca": true,
            "davidlo@smu.edu.sg": true,
            "taoxie@pku.edu.cn": true,
            "jordan.henkel@microsoft.com": true,
            "august@utexas.edu": true,
            "rdyer@unl.edu": true,
            "amarlop@us.es": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683324798,
        "modified_at": 1683331786,
        "tags": [
            "accept#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 259,
        "title": "Neural SZZ Algorithm",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-d4e2a64afa918b78c78760173e6c3565ac94e5e50a958df2b6168cfa626d9d40",
            "timestamp": 1683371331,
            "size": 487677,
            "pages": 12
        },
        "abstract": "The SZZ algorithm has been widely used for identifying bug-inducing commits. However, it suffers from low precision, as not all deletion lines in the bug-fixing commit are related to  bug fix. Previous studies have attempted to address this issue by using static methods to filter out noise, e.g., comments and refactoring operations in the bug-fixing commit. \r\nHowever, these methods have two limitations. First, it is challenging to include all refactoring and non-essential change patterns in a tool, leading to the potential exclusion of relevant lines and the inclusion of irrelevant lines. Second, applying these tools might not always improve performance, as seen in the dataset provided by Wen et al.\r\n\r\nIn this paper, to address the aforementioned challenges, we propose NeurlSZZ, a deep learning approach for detecting the root cause deletion lines in a bug-fixing commit and using them as input for the SZZ algorithm. NeurlSZZ first constructs a heterogeneous graph attention network model that captures the semantic relationships between each deletion line and the other deletion and addition lines. To pinpoint the root cause of a bug, NeurlSZZ uses a learning-to-rank technique to rank all deletion lines in the commit. To evaluate the effectiveness of NeurlSZZ, we utilize three datasets containing high-quality bug-fixing and bug-inducing commits. The experiment results show that NeurlSZZ outperforms various baseline methods, e.g., traditional machine learning-based approaches and  Bi-LSTM in identifying the root cause of bugs. Moreover, by utilizing the top-ranked deletion lines and applying the SZZ algorithm, NeurlSZZ demonstrates better precision and F1-score compared to previous SZZ algorithms.",
        "authors": [
            {
                "email": "tlx@zju.edu.cn",
                "first": "Lingxiao",
                "last": "Tang",
                "affiliation": "zhejiang university",
                "contact": true
            },
            {
                "email": "lingfengbao@zju.edu.cn",
                "first": "Lingfeng",
                "last": "Bao",
                "affiliation": "Zhejiang University",
                "contact": true
            },
            {
                "email": "xin.xia@acm.org",
                "first": "Xin",
                "last": "Xia",
                "affiliation": "Zhejiang University",
                "contact": true
            },
            {
                "email": "hzd@zju.edu.cn",
                "first": "Zhongdong",
                "last": "Huang",
                "affiliation": "Zhejiang University"
            }
        ],
        "topics": [
            "AI and Software Engineering",
            "Maintenance and Evolution"
        ],
        "pc_conflicts": {
            "shang@encs.concordia.ca": true,
            "pcorina@cmu.edu": true,
            "junsun@smu.edu.sg": true,
            "chunyang.chen@monash.edu": true,
            "xin.xia@acm.org": "collaborator author",
            "shihan@microsoft.com": true,
            "gaocuiyun@hit.edu.cn": true,
            "ma.lei@acm.org": true,
            "lilicoding@ieee.org": true,
            "csxluo@comp.polyu.edu.hk": true,
            "saikatc@microsoft.com": true,
            "mnayebi@yorku.ca": true,
            "davidlo@smu.edu.sg": true,
            "taoxie@pku.edu.cn": true,
            "tazhang@must.edu.mo": true,
            "fatemeh.fard@ubc.ca": true,
            "jieshan.chen@data61.csiro.au": true,
            "jordan.henkel@microsoft.com": true,
            "xinghu@zju.edu.cn": true,
            "jiangjiajun@tju.edu.cn": true,
            "liu.chao@cqu.edu.cn": true,
            "minghuama@microsoft.com": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683336583,
        "modified_at": 1683526710,
        "tags": [
            "accept#0",
            "ChrisCoI#0",
            "dpa_candidate#0",
            "dpa_no#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 262,
        "title": "Information Retrieval-based Fault Localization for Concurrent Programs",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-8b87dba2c6da07cf5fffdb55c15d41df2b50f4131ca02e849a2374a58750dc7a",
            "timestamp": 1683340579,
            "size": 613639,
            "pages": 12
        },
        "abstract": "Information retrieval-based fault localization (IRFL) techniques have been proposed as a solution to identify the files that are likely to contain faults that are root causes of failures reported by users. These techniques have been extensively studied to accurately rank source files, however, none of the existing approaches have focused on the specific case of concurrent programs. This is a critical issue since concurrency bugs are notoriously difficult to identify. To address this problem, this paper presents a novel approach called BLCoiR, which aims to reformulate bug report queries to more accurately localize source files related to concurrency bugs. The key idea of BLCoiR is based on a novel knowledge graph (KG), which represents the domain entities extracted from the concurrency bug reports and their semantic relations. The KG is then transformed into the IR query to perform fault localization. BLCoiR leverages natural language processing (NLP) and concept modeling techniques to construct the knowledge graph. Specifically, NLP techniques are used to extract relevant entities from the bug reports, such as the word entities related to concurrency constructs. These entities are then linked together based on their semantic relationships, forming the KG. We have conducted an empirical study on 692 concurrency bug reports from 44 real-world applications. The results show that BLCoiR outperforms existing IRFL techniques in terms of accuracy and efficiency in localizing concurrency bugs. BLCoiR demonstrates effectiveness of using a knowledge graph to model the domain entities and their relationships, providing a promising direction for future research in this area.",
        "authors": [
            {
                "email": "shaosh@mail.uc.edu",
                "first": "Shuai",
                "last": "Shao",
                "affiliation": "University of Cincinnati",
                "contact": true
            },
            {
                "email": "yutt@ucmail.uc.edu",
                "first": "Tingting",
                "last": "Yu",
                "affiliation": "University Of Cincinnati",
                "contact": true
            }
        ],
        "topics": [
            "Maintenance and Evolution"
        ],
        "pc_conflicts": {
            "michael@binaervarianz.de": true,
            "nan.niu@uc.edu": true,
            "lxiao6@stevens.edu": true,
            "davidlo@smu.edu.sg": true,
            "xiaoyin.wang@utsa.edu": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683341175,
        "modified_at": 1683341175,
        "tags": [
            "accept#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 263,
        "title": "Merge Conflict Resolution: Classification or Generation?",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-500f61c8eeb05a53b1adad1d4fa705f700014e0a88e26500549a7fd77fa38f04",
            "timestamp": 1683373811,
            "size": 569660,
            "pages": 11
        },
        "abstract": "Collaborative development is critical to improve the productivity.  Multiple contributors work simultaneously on the same project and might make changes to the same code locations. This can cause conflicts and require manual intervention from developers to resolve them. To alleviate the human efforts of manual conflict resolution, researchers have proposed various automatic techniques. More recently, deep learning models have been adopted to solve this problem and achieved state-of-the-art performance. However, these techniques leverage classification to combine the existing elements of input. The classification-based models cannot generate new tokens or produce flexible combinations, and have a wrong hypothesis that fine-grained conflicts of one single coarse-grained conflict are independent.\r\n\r\nIn this work, we propose to generate the resolutions of merge conflicts from a totally new perspective, that is, generation, and we present a conflict resolution technique, MergeGen. First, we design a structural and fine-grained conflict-aware representation for the merge conflicts. Then, we propose to leverage an encoder-decoder-based generative model to process the designed conflict representation and generate the resolutions auto-regressively. We further perform a comprehensive study to evaluate the effectiveness of MergeGen. The quantitative results show that MergeGen outperforms the state-of-the-art (SOTA) techniques from both precision and accuracy. Our evaluation on multiple programming languages verifies the good generalization ability of MergeGen. In addition, the ablation study shows that the major component of our technique makes a positive contribution to the performance of MergeGen, and the granularity analysis reveals the high tolerance of MergeGen to coarse-grained conflicts. Moreover, the analysis on generating new tokens further proves the advance of generative models.",
        "authors": [
            {
                "email": "dongjinhao@stu.pku.edu.cn",
                "first": "Jinhao",
                "last": "Dong",
                "affiliation": "Peking University",
                "contact": true
            },
            {
                "email": "Zhuqh@pku.edu.cn",
                "first": "Qihao",
                "last": "Zhu",
                "affiliation": "Peking University",
                "contact": true
            },
            {
                "email": "szy_@pku.edu.cn",
                "first": "Zeyu",
                "last": "Sun",
                "affiliation": "Zhongguancun Laboratory",
                "contact": true
            },
            {
                "email": "yilinglou@fudan.edu.cn",
                "first": "Yiling",
                "last": "Lou",
                "affiliation": "Fudan University",
                "contact": true
            },
            {
                "email": "haodan@pku.edu.cn",
                "first": "Dan",
                "last": "Hao",
                "affiliation": "Peking University",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering"
        ],
        "pc_conflicts": {
            "michael@binaervarianz.de": true,
            "junsun@smu.edu.sg": true,
            "junjiechen@tju.edu.cn": true,
            "zp.chen@ucl.ac.uk": true,
            "lingming@illinois.edu": true,
            "tianyi@purdue.edu": true,
            "shihan@microsoft.com": true,
            "haodan@pku.edu.cn": "collaborator author",
            "xusheng.xiao@asu.edu": true,
            "liuhui08@bit.edu.cn": true,
            "zhendong@fudan.edu.cn": true,
            "ding_li@pku.edu.cn": true,
            "sfakhoury@microsoft.com": true,
            "mark.harman@ucl.ac.uk": true,
            "saikatc@microsoft.com": true,
            "louyiling610@gmail.com": true,
            "hongyujohn@gmail.com": true,
            "jie.zhang@kcl.ac.uk": true,
            "taoxie@pku.edu.cn": true,
            "jordan.henkel@microsoft.com": true,
            "wurongxin@xmu.edu.cn": true,
            "xyzhang@cs.purdue.edu": true,
            "szy_@pku.edu.cn": "author",
            "jiangjiajun@tju.edu.cn": true,
            "wangbo_cs@bjtu.edu.cn": true,
            "mwenaa@hust.edu.cn": true,
            "wangdi95@pku.edu.cn": true,
            "man.mzhang@gmail.com": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683371121,
        "modified_at": 1683373811,
        "tags": [
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 270,
        "title": "OrdinalFix: Fixing Compilation Errors via Shortest-Path CFL Reachability with Attribute Checking",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-3c96764c3bd3031a0c3a3e89a687d27a82d30148e5c75ad5cea46af77bb28281",
            "timestamp": 1683287493,
            "size": 509165,
            "pages": 11
        },
        "abstract": "The development of correct and efficient software can be hindered by compilation errors, which must be fixed to ensure the code's syntactic correctness and program language constraints. Neural network-based approaches have been used to tackle this problem, but they lack guarantees of output correctness and can require an unlimited number of modifications. Fixing compilation errors within a given number of modifications is a challenging task. We demonstrate that finding the minimum number of modifications to fix a compilation error is NP-hard. To address compilation error fixing problem, we propose OrdinalFix, a complete algorithm based on shortest-path CFL (context-free language) reachability with attribute checking that is guaranteed to output a program with the minimum number of modifications required. Specifically, OrdinalFix searches possible fixes from the smallest to the largest number of modifications. By incorporating merged attribute checking to enhance efficiency, the time complexity of OrdinalFix is acceptable for application. We evaluate OrdinalFix on two datasets and demonstrate its ability to fix compilation errors within reasonable time limit. Comparing with existing approaches, OrdinalFix achieves a success rate of 83.5%, surpassing all existing approaches (71.7%).",
        "authors": [
            {
                "email": "zhang_wen_jie@pku.edu.cn",
                "first": "Wenjie",
                "last": "Zhang",
                "affiliation": "Peking University",
                "contact": true
            },
            {
                "email": "guancheng.wang@pku.edu.cn",
                "first": "Guancheng",
                "last": "Wang",
                "affiliation": "Peking University",
                "contact": true
            },
            {
                "email": "junjiechen@tju.edu.cn",
                "first": "Junjie",
                "last": "Chen",
                "affiliation": "College of Intelligence and Computing, Tianjin University",
                "contact": true
            },
            {
                "email": "xiongyf@pku.edu.cn",
                "first": "Yingfei",
                "last": "Xiong",
                "affiliation": "Peking University",
                "contact": true
            },
            {
                "email": "lyong@mail.buct.edu.cn",
                "first": "Yong",
                "last": "Liu",
                "affiliation": "Beijing University of Chemical Technology",
                "contact": true
            },
            {
                "email": "zhanglucs@pku.edu.cn",
                "first": "Lu",
                "last": "Zhang",
                "affiliation": "Peking University",
                "contact": true
            }
        ],
        "supplementary_material": {
            "mimetype": "application\/x-compressed",
            "hash": "sha2-2cd86e6bb4cf19b5a3f2dd7ca8c4dd4f4bc929630c3d0dc40284a182049c7d23",
            "timestamp": 1683293640,
            "size": 2131516,
            "filename": "ordinalfix-source-code-dataset.tgz"
        },
        "topics": [
            "Maintenance and Evolution"
        ],
        "pc_conflicts": {
            "michael@binaervarianz.de": true,
            "nan.niu@uc.edu": true,
            "junsun@smu.edu.sg": true,
            "junjiechen@tju.edu.cn": "author",
            "contact@stefanstanciulescu.com": true,
            "zp.chen@ucl.ac.uk": true,
            "lingming@illinois.edu": true,
            "a.tahir@massey.ac.nz": true,
            "xin.xia@acm.org": true,
            "shihan@microsoft.com": true,
            "senchen@tju.edu.cn": true,
            "haodan@pku.edu.cn": true,
            "xusheng.xiao@asu.edu": true,
            "liuhui08@bit.edu.cn": true,
            "ding_li@pku.edu.cn": true,
            "mark.harman@ucl.ac.uk": true,
            "louyiling610@gmail.com": true,
            "hongyujohn@gmail.com": true,
            "jie.zhang@kcl.ac.uk": true,
            "taoxie@pku.edu.cn": true,
            "zhonghao@sjtu.edu.cn": true,
            "guowei.yang@uq.edu.au": true,
            "wurongxin@xmu.edu.cn": true,
            "szy_@pku.edu.cn": true,
            "xiaoyin.wang@utsa.edu": true,
            "jiangjiajun@tju.edu.cn": true,
            "wangbo_cs@bjtu.edu.cn": true,
            "mwenaa@hust.edu.cn": true,
            "wangdi95@pku.edu.cn": true,
            "minghuama@microsoft.com": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683287493,
        "modified_at": 1683287493,
        "tags": [
            "accept#0"
        ]
    },
    {
        "object": "paper",
        "pid": 272,
        "title": "Mitigating Persistence of Open-Source Vulnerabilities in Maven Ecosystem",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-060637b1ec9de741e9e3979f99864425a6a35d7bc10b4a77df0260181d085b03",
            "timestamp": 1683370446,
            "size": 1198091,
            "pages": 11
        },
        "abstract": "Vulnerabilities from third-party libraries (TPLs) have been unveiled to threaten the Maven ecosystem in the long term. Despite patches being released promptly after vulnerabilities are disclosed, the libraries and applications in the community still use the vulnerable versions, which makes the vulnerabilities persistent in the Maven ecosystem (e.g., the notorious Log4Shell still greatly influences the Maven ecosystem nowadays from 2021). Both academic and industrial researchers have proposed user-oriented standards and solutions to address vulnerabilities, while such solutions fail to tackle the ecosystem-wide persistent vulnerabilities because it requires a collective effort from the community to timely adopt patches without introducing breaking issues. \r\n\r\nTo seek an ecosystem-wide solution, we first carried out an empirical study to examine the prevalence of persistent vulnerabilities in the Maven ecosystem. Then, we identified affected libraries for alerts by implementing an algorithm monitoring downstream dependents of vulnerabilities based on an up-to-date dependency graph. Based on them, we further quantitatively revealed that the patches blocked by upstream libraries caused the persistence of vulnerabilities. After reviewing the drawbacks of existing countermeasures, towards addressing them, we proposed Ranger for range r estoration to automatically restore the compatible and secure version ranges of dependencies for downstream dependents. The automatic restoration requires no manual effort from the community, and the code-centric compatibility assurance ensures smooth upgrades to patched versions. Moreover, Ranger along with the ecosystem monitoring can timely alert developers of blocking libraries and suggest flexible version ranges for them to rapidly unblock patched versions. By evaluation, Ranger could restore 75.64% of ranges which automatically remediated 90.32% of vulnerable downstream projects.",
        "authors": [
            {
                "email": "zh0004ye@e.ntu.edu.sg",
                "first": "Lyuye",
                "last": "Zhang",
                "affiliation": "Nanyang Technological University",
                "contact": true
            },
            {
                "email": "chengwei001@e.ntu.edu.sg",
                "first": "Chengwei",
                "last": "Liu",
                "affiliation": "Nanyang Technological University",
                "contact": true
            },
            {
                "email": "senchen@tju.edu.cn",
                "first": "Sen",
                "last": "Chen",
                "affiliation": "Tianjin University",
                "contact": true
            },
            {
                "email": "zhengzi.xu@ntu.edu.sg",
                "first": "Zhengzi",
                "last": "Xu",
                "affiliation": "Nanyang Technological University",
                "contact": true
            },
            {
                "email": "linglingfan@nankai.edu.cn",
                "first": "Lingling",
                "last": "Fan",
                "affiliation": "Nankai University",
                "contact": true
            },
            {
                "email": "lida001@e.ntu.edu.sg",
                "first": "Lida",
                "last": "Zhao",
                "affiliation": "Nanyang Technological University",
                "contact": true
            },
            {
                "email": "yiran002@e.ntu.edu.sg",
                "first": "Yiran",
                "last": "Zhang",
                "affiliation": "Nanyang Technological University",
                "contact": true
            },
            {
                "email": "yangliu@ntu.edu.sg",
                "first": "Yang",
                "last": "Liu",
                "affiliation": "Nanyang Technological University",
                "contact": true
            }
        ],
        "topics": [
            "Maintenance and Evolution"
        ],
        "pc_conflicts": {
            "junsun@smu.edu.sg": true,
            "junjiechen@tju.edu.cn": true,
            "chunyang.chen@monash.edu": true,
            "lxiao6@stevens.edu": true,
            "senchen@tju.edu.cn": "author",
            "xfxie@smu.edu.sg": true,
            "gaocuiyun@hit.edu.cn": true,
            "ma.lei@acm.org": true,
            "lilicoding@ieee.org": true,
            "linglingfan@nankai.edu.cn": "author",
            "wangying@swc.neu.edu.cn": true,
            "jie.zhang@kcl.ac.uk": true,
            "davidlo@smu.edu.sg": true,
            "xxie@whu.edu.cn": true,
            "y.sui@unsw.edu.au": true,
            "jiangjiajun@tju.edu.cn": true,
            "tsu@sei.ecnu.edu.cn": true,
            "xuwang@buaa.edu.cn": true,
            "yli044@e.ntu.edu.sg": true,
            "mengguozhu@iie.ac.cn": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683370446,
        "modified_at": 1683373835
    },
    {
        "object": "paper",
        "pid": 277,
        "title": "Are They All Good? Studying Practitioners' Expectations on the Readability of Log Messages",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-864666142b099d8a0fad48087eede0db7191ac472ff24e6427963df280928bea",
            "timestamp": 1683286259,
            "size": 328630,
            "pages": 12
        },
        "abstract": "Developers write logging statements to generate logs that provide run-time information for various tasks. The readability of log messages in the logging statements (i.e., the descriptive text) is rather crucial to the value of the generated logs. Immature log messages may slow down or even obstruct the process of log analysis. Despite the importance of log messages, there is still a lack of standards on what constitutes good readability in log messages and how to write them. In this paper, we conduct a series of interviews with 17 industrial practitioners to investigate their expectations on the readability of log messages. Through the interviews, we derive three aspects related to the readability of log messages, including Structure, Information, and Wording, along with several specific practices to improve each aspect. We validate our findings through a series of online questionnaire surveys and receive positive feedback from the participants.\r\nWe then manually investigate the readability of log messages in large-scale open source systems and find that a large portion (38.1%) of the log messages have inadequate readability. Motivated by such observation, we further explore the potential of automatically classifying the readability of log messages using deep learning and machine learning models. \r\nWe find that both deep learning and machine learning models can effectively classify the readability of log messages with a balanced accuracy above 80.0% on average.\r\nOur study provides comprehensive guidelines for composing log messages to further improve practitioners' logging practices.",
        "authors": [
            {
                "email": "l_zhenha@encs.concordia.ca",
                "first": "Zhenhao",
                "last": "Li",
                "affiliation": "Concordia University",
                "contact": true
            },
            {
                "email": "anr_chen@encs.concordia.ca",
                "first": "An Ran",
                "last": "Chen",
                "affiliation": "Concordia University",
                "contact": true
            },
            {
                "email": "xinghu@zju.edu.cn",
                "first": "Xing",
                "last": "Hu",
                "affiliation": "Zhejiang University",
                "contact": true
            },
            {
                "email": "xin.xia@acm.org",
                "first": "Xin",
                "last": "Xia",
                "affiliation": "Zhejiang University",
                "contact": true
            },
            {
                "email": "peterc@encs.concordia.ca",
                "first": "Tse-Hsun (Peter)",
                "last": "Chen",
                "affiliation": "Concordia University",
                "contact": true
            },
            {
                "email": "shang@encs.concordia.ca",
                "first": "Weiyi",
                "last": "Shang",
                "affiliation": "Concordia University",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering",
            "Human Aspects of Software Engineering",
            "Maintenance and Evolution"
        ],
        "pc_conflicts": {
            "shang@encs.concordia.ca": "collaborator author",
            "pcorina@cmu.edu": true,
            "junsun@smu.edu.sg": true,
            "junjiechen@tju.edu.cn": true,
            "chunyang.chen@monash.edu": true,
            "y.tian@queensu.ca": true,
            "shaowei.wang@umanitoba.ca": true,
            "xin.xia@acm.org": "author",
            "shihan@microsoft.com": true,
            "gaocuiyun@hit.edu.cn": true,
            "ma.lei@acm.org": true,
            "lilicoding@ieee.org": true,
            "csxluo@comp.polyu.edu.hk": true,
            "saikatc@microsoft.com": true,
            "hemmati@yorku.ca": true,
            "davidlo@smu.edu.sg": true,
            "taoxie@pku.edu.cn": true,
            "tazhang@must.edu.mo": true,
            "fatemeh.fard@ubc.ca": true,
            "jieshan.chen@data61.csiro.au": true,
            "jordan.henkel@microsoft.com": true,
            "zi_ding@encs.concordia.ca": true,
            "xinghu@zju.edu.cn": "author",
            "jiangjiajun@tju.edu.cn": true,
            "liu.chao@cqu.edu.cn": true,
            "yxtvse@rit.edu": true,
            "minghuama@microsoft.com": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683337160,
        "modified_at": 1683526748,
        "tags": [
            "ChrisCoI#0"
        ]
    },
    {
        "object": "paper",
        "pid": 279,
        "title": "CodeGen4Libs: A Two-Stage Approach for Library-Oriented Code Generation",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-013e3a04b49a14752b7d5d0e8d71652996cb6797f6676c0a07290c8f2f9bc719",
            "timestamp": 1683371717,
            "size": 1719785,
            "pages": 11
        },
        "abstract": "Automated code generation has been extensively studied in recent literature. In this work, we first survey 66 participants to motivate a more pragmatic code generation scenario, i.e., \\textit{library-oriented code generation}, where the generated code should implement the functionally of the natural language query with the given library. We then revisit existing learning-based code generation techniques and find they have limited effectiveness in such a library-oriented code generation scenario. \r\n\r\nTo address this limitation, we propose a novel library-oriented code generation technique, CodeGen4Libs, which incorporates two stages: import generation and code generation. The import generation stage generates import statements for the natural language query with the given third-party libraries, while the code generation stage generates concrete code based on the generated imports and the query. To evaluate the effectiveness of our approach, we conducted extensive experiments on a dataset of 403,780 data items. Our results demonstrate that \\app{} outperforms baseline models in both import generation and code generation stages, achieving improvements of up to 97.4\\% on EM (Exact Match), 54.5\\% on BLEU, and 53.5\\% on Hit@All. Overall, our proposed CodeGen4Libs approach shows promising results in generating high-quality code with specific third-party libraries, which can improve the efficiency and effectiveness of software development.",
        "authors": [
            {
                "email": "liumingwei@fudan.edu.cn",
                "first": "Mingwei",
                "last": "Liu",
                "affiliation": "Fudan University",
                "contact": true
            },
            {
                "email": "21212010044@m.fudan.edu.cn",
                "first": "Tianyong",
                "last": "Yang",
                "affiliation": "Fudan University",
                "contact": true
            },
            {
                "email": "yilinglou@fudan.edu.cn",
                "first": "Yiling",
                "last": "Lou",
                "affiliation": "Fudan University",
                "contact": true
            },
            {
                "email": "21210240012@m.fudan.edu.cn",
                "first": "Xueying",
                "last": "Du",
                "affiliation": "Fudan University",
                "contact": true
            },
            {
                "email": "22210240051@m.fudan.edu.cn",
                "first": "Ying",
                "last": "Wang",
                "affiliation": "Fudan University",
                "contact": true
            },
            {
                "email": "pengxin@fudan.edu.cn",
                "first": "Xin",
                "last": "Peng",
                "affiliation": "Fudan University",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering"
        ],
        "pc_conflicts": {
            "junsun@smu.edu.sg": true,
            "zp.chen@ucl.ac.uk": true,
            "lxiao6@stevens.edu": true,
            "lingming@illinois.edu": true,
            "tianyi@purdue.edu": true,
            "xin.xia@acm.org": true,
            "changxu@nju.edu.cn": true,
            "haodan@pku.edu.cn": true,
            "zhendong@fudan.edu.cn": true,
            "ding_li@pku.edu.cn": true,
            "louyiling610@gmail.com": true,
            "wangying@swc.neu.edu.cn": true,
            "taoxie@pku.edu.cn": true,
            "wurongxin@xmu.edu.cn": true,
            "xyzhang@cs.purdue.edu": true,
            "szy_@pku.edu.cn": true,
            "jiangjiajun@tju.edu.cn": true,
            "tsu@sei.ecnu.edu.cn": true,
            "mwenaa@hust.edu.cn": true,
            "wangdi95@pku.edu.cn": true,
            "mengguozhu@iie.ac.cn": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683371717,
        "modified_at": 1683373339
    },
    {
        "object": "paper",
        "pid": 290,
        "title": "PERFCE: Performance Debugging on Databases with Chaos Engineering-Enhanced Causality Analysis",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-08719587e6614ec9a7712d36284ec171d36bdb2c68a0b9349187951c6f97e25e",
            "timestamp": 1683274235,
            "size": 1423483,
            "pages": 12
        },
        "abstract": "Debugging performance anomalies in databases is challenging. Causal inference techniques enable qualitative and quantitative root cause analysis of performance downgrades. Nev- ertheless, causality analysis is challenging in practice, particularly due to limited observability. Recently, chaos engineering (CE) has been applied to test complex software systems. CE frameworks mutate chaos variables to inject catastrophic events (e.g., network slowdowns) to stress-test these software systems. The systems under chaos stress are then tested (e.g., via differential testing) to check if they retain normal functionality, such as returning correct SQL query outputs even under stress.\r\n\r\nTo date, CE is mainly employed to aid software testing. This paper identifies the novel usage of CE in diagnosing performance anomalies in databases. Our framework, PERFCE, has two phases — offline and online. The offline phase learns statistical models of a database using both passive observations and proactive chaos experiments. The online phase diagnoses the root cause of performance anomalies from both qualitative and quantitative aspects on-the-fly. In evaluation, PERFCE outperformed previous works on synthetic datasets and is highly accurate and moderately expensive when analyzing real-world (distributed) databases like MySQL and TiDB.",
        "authors": [
            {
                "email": "zjiae@cse.ust.hk",
                "first": "Zhenlan",
                "last": "Ji",
                "affiliation": "HKUST",
                "contact": true
            },
            {
                "email": "pmaab@cse.ust.hk",
                "first": "Pingchuan",
                "last": "Ma",
                "affiliation": "HKUST",
                "contact": true
            },
            {
                "email": "shuaiw@cse.ust.hk",
                "first": "Shuai",
                "last": "Wang",
                "affiliation": "HKUST",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering",
            "Maintenance and Evolution",
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "pwng@google.com": true,
            "fengyang@nju.edu.cn": true,
            "shihan@microsoft.com": true,
            "changxu@nju.edu.cn": true,
            "shuaiw@cse.ust.hk": "collaborator author",
            "xfxie@smu.edu.sg": true,
            "gaocuiyun@hit.edu.cn": true,
            "ma.lei@acm.org": true,
            "taoyue@gmail.com": true,
            "csxluo@comp.polyu.edu.hk": true,
            "saikatc@microsoft.com": true,
            "fangchunrong@nju.edu.cn": true,
            "wangying@swc.neu.edu.cn": true,
            "jordan.henkel@microsoft.com": true,
            "jyy@nju.edu.cn": true,
            "zqzuo@nju.edu.cn": true,
            "why@nju.edu.cn": true,
            "minghuama@microsoft.com": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683273466,
        "modified_at": 1683526786
    },
    {
        "object": "paper",
        "pid": 294,
        "title": "MLIRSmith: Random Program Generation for Fuzzing MLIR Compiler Infrastructure",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-6732bbd34dfc4383e12a301ce1344d1f72566a2b7ba13910427edb767f0ea626",
            "timestamp": 1683377636,
            "size": 530570,
            "pages": 11
        },
        "abstract": "MLIR (Multi-Level Intermediate Representation) compiler infrastructure has gained popularity in recent years to support the construction of many compilers.\r\nInstead of designing a new IR with a single abstraction for each domain, MLIR compiler infrastructure provides systematic passes to support a wide range of functionalities for benefiting multiple domains together and introduces dialects to support different levels of abstraction in MLIR. Due to its fundamental role in compiler community, ensuring its quality is very critical.\r\nIn this work, we propose MLIRSmith, the first fuzzing technique to MLIR compiler infrastructure.\r\nMLIRSmith employs a two-phase strategy to generate valid and diverse MLIR programs, which first constructs diverse program templates guided by extended MLIR syntax rules and then generates valid MLIR programs through template instantiation guided by our designed context-sensitive grammar. After applying MLIRSmith to the latest revision of MLIR compiler infrastructure, we detected 53 previously unknown bugs, among which 49\/38 have been confirmed\/fixed by developers. We also transform the high-level programs generated by NNSmith (a high-level program generator for deep learning compilers) to MLIR programs for indirectly fuzzing MLIR compiler infrastructure. During the same testing time, MLIRSmith largely outperforms such an indirect technique by detecting 328.57% more bugs and covering 194.67%\/225.87% more lines\/branches in MLIR compiler infrastructure.",
        "authors": [
            {
                "email": "haoyuwang@tju.edu.cn",
                "first": "Haoyu",
                "last": "Wang",
                "affiliation": "College of Intelligence and Computing, Tianjin University",
                "contact": true
            },
            {
                "email": "junjiechen@tju.edu.cn",
                "first": "Junjie",
                "last": "Chen",
                "affiliation": "College of Intelligence and Computing, Tianjin University",
                "contact": true
            },
            {
                "email": "xiechuyue@tju.edu.cn",
                "first": "Chuyue",
                "last": "Xie",
                "affiliation": "College of Intelligence and Computing, Tianjin University",
                "contact": true
            },
            {
                "email": "shuang.liu@tju.edu.cn",
                "first": "Shuang",
                "last": "Liu",
                "affiliation": "College of Intelligence and Computing, Tianjin University",
                "contact": true
            },
            {
                "email": "wangzan@tju.edu.cn",
                "first": "Zan",
                "last": "Wang",
                "affiliation": "College of Intelligence and Computing, Tianjin University",
                "contact": true
            },
            {
                "email": "qingchao@tju.edu.cn",
                "first": "Qingchao",
                "last": "Shen",
                "affiliation": "College of Intelligence and Computing, Tianjin University; School of New Media and Communication, Tianjin University",
                "contact": true
            },
            {
                "email": "zhaoyingquan@tju.edu.cn",
                "first": "Yingquan",
                "last": "Zhao",
                "affiliation": "College of Intelligence and Computing, Tianjin University",
                "contact": true
            }
        ],
        "topics": [
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "junsun@smu.edu.sg": true,
            "junjiechen@tju.edu.cn": "author",
            "zp.chen@ucl.ac.uk": true,
            "lingming@illinois.edu": true,
            "senchen@tju.edu.cn": true,
            "haodan@pku.edu.cn": true,
            "xusheng.xiao@asu.edu": true,
            "lilicoding@ieee.org": true,
            "hongyujohn@gmail.com": true,
            "jie.zhang@kcl.ac.uk": true,
            "mnayebi@yorku.ca": true,
            "guowei.yang@uq.edu.au": true,
            "wurongxin@xmu.edu.cn": true,
            "y.sui@unsw.edu.au": true,
            "jiangjiajun@tju.edu.cn": true,
            "mwenaa@hust.edu.cn": true,
            "mengguozhu@iie.ac.cn": true,
            "minghuama@microsoft.com": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683374076,
        "modified_at": 1683377636,
        "tags": [
            "accept#0"
        ]
    },
    {
        "object": "paper",
        "pid": 301,
        "title": "Generating Variable Explanations via Zero-shot Prompt Learning",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-e47bfc08c49e2ba7a0de524c5b21f7cfb83ec74164e0221e40cff79433312a5c",
            "timestamp": 1683367857,
            "size": 585096,
            "pages": 12
        },
        "abstract": "As basic elements in program, variables convey essential information that is critical for program comprehension and maintenance. However, understanding the meanings of variables in program is not always easy for developers, since poor-quality variable names are prevalent while such variable are less informative for program comprehension. Therefore, in this paper, we target at generating concise natural language explanations for variables to facilitate program comprehension. In particular, there are two challenges in variable explanation generation, including the lack of training data and the association with complex code contexts around the variable. To address these issues, we propose a novel approach ZeroVar, which leverages code pre-trained models and zero-shot prompt learning to generate explanations for the variable based on its code context. ZeroVar contains two stages: (i) a pre-training stage that continually pre-trains a base model (i.e., CodeT5) to recover the randomly-masked parameter descriptions in method docstrings; and (ii) a zero-shot prompt learning stage that leverages the pre-trained model to generate explanations for a given variable via the prompt constructed with the variable and its belonging method context.\r\nWe then extensively evaluate the quality and usefulness of the variable explanations generated by ZeroVar. We construct an evaluation dataset of 773 variables and their reference explanations. Our results show that ZeroVar can generate higherquality explanations than baselines, not only on automated metrics such as BLEU and ROUGE, but also on human metrics such as correctness, completeness, and conciseness. Moreover, we further assess the usefulness of ZeroVar-generated explanations on two downstream tasks related to variable naming quality, i.e., abbreviation expansion and spelling correction. For abbreviation expansion, the generated variable explanations can help improve the present rate (+13.1%), precision (+3.6%), and recall (+10.0%)\r\nof the state-of-the-art abbreviation explanation approach. For spelling correction, by using the generated explanations we can achieve higher hit@1 (+162.9%) and hit@3 (+49.6%) than the\r\nrecent variable representation learning approach.",
        "authors": [
            {
                "email": "wangchong20@fudan.edu.cn",
                "first": "Chong",
                "last": "Wang",
                "affiliation": "Fudan University",
                "contact": true
            },
            {
                "email": "yilinglou@fudan.edu.cn",
                "first": "Yiling",
                "last": "Lou",
                "affiliation": "Fudan University",
                "contact": true
            },
            {
                "email": "22210240218@m.fudan.edu.cn",
                "first": "Junwei",
                "last": "Liu",
                "affiliation": "Fudan University",
                "contact": true
            },
            {
                "email": "pengxin@fudan.edu.cn",
                "first": "Xin",
                "last": "Peng",
                "affiliation": "Fudan University",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering",
            "Maintenance and Evolution"
        ],
        "pc_conflicts": {
            "junsun@smu.edu.sg": true,
            "zp.chen@ucl.ac.uk": true,
            "lxiao6@stevens.edu": true,
            "lingming@illinois.edu": true,
            "tianyi@purdue.edu": true,
            "xin.xia@acm.org": true,
            "haodan@pku.edu.cn": true,
            "liuhui08@bit.edu.cn": true,
            "zhendong@fudan.edu.cn": true,
            "ding_li@pku.edu.cn": true,
            "louyiling610@gmail.com": true,
            "mnayebi@yorku.ca": true,
            "cmc@nd.edu": true,
            "taoxie@pku.edu.cn": true,
            "xyzhang@cs.purdue.edu": true,
            "szy_@pku.edu.cn": true,
            "jiangjiajun@tju.edu.cn": true,
            "tsu@sei.ecnu.edu.cn": true,
            "mwenaa@hust.edu.cn": true,
            "wangdi95@pku.edu.cn": true,
            "mengguozhu@iie.ac.cn": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683367857,
        "modified_at": 1683367857,
        "tags": [
            "accept#0"
        ]
    },
    {
        "object": "paper",
        "pid": 307,
        "title": "Revisiting and Improving Retrieval-Augmented Deep Assertion Generation",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-b726625fbeec2bed0e76b847d8252b819f9ee1c99fd794213bd49d086c772218",
            "timestamp": 1683360506,
            "size": 746561,
            "pages": 12
        },
        "abstract": "Unit testing validates the correctness of the unit under test and has become an essential activity in software development process. A unit test consists of a test prefix that drives the unit under test into a particular state, and a test oracle (e.g., assertion), which specifies the behavior in that state. To reduce manual efforts in conducting unit testing, Yu et al. proposed an integrated approach (*integration* for short), combining information retrieval (IR) with a deep learning-based approach, to generate assertions for a unit test. Despite promising, there is still a knowledge gap as to why or where *integration* works or does not work. In this paper, we describe an in-depth analysis of the effectiveness of *integration*. Our analysis shows that: 1) The overall performance of *integration* is mainly due to its success in retrieving assertions. 2) *integration* struggles to understand the semantic differences between the retrieved focal-test (*focal-test* includes a test prefix and a unit under test) and the input focal-test, resulting in many tokens being incorrectly modified; 3) *integration* is limited to specific types of edit operations (i.e., replacement) and cannot handle token addition or deletion. To improve the effectiveness of assertion generation, this paper proposes a novel retrieve-and-edit approach named *EditAS*. Specifically, *EditAS* first retrieves a similar focal-test from a pre-defined corpus and treats its assertion as a prototype. Then, *EditAS* reuses the information in the prototype and edits the prototype automatically. *EditAS* is more generalizable than *integration* because it can 1) comprehensively understand the semantic differences between input and similar focal-tests; 2) apply appropriate assertion edit patterns with greater flexibility; and 3) generate more diverse edit actions than just replacement operations. We conduct experiments on two large-scale datasets and experimental results demonstrate that *EditAS* outperforms the state-of-the-art approaches, with an average improvement of 10.00%-87.48% and 3.30%-42.65% in accuracy and BLEU score, respectively.",
        "authors": [
            {
                "email": "weifeng.sun@cqu.edu.cn",
                "first": "Weifeng",
                "last": "Sun",
                "affiliation": "Chongqing University",
                "contact": true
            },
            {
                "email": "hongyan.li@cqu.edu.cn",
                "first": "Hongyan",
                "last": "Li",
                "affiliation": "Chongqing University",
                "contact": true
            },
            {
                "email": "mengy@cqu.edu.cn",
                "first": "Meng",
                "last": "Yan",
                "affiliation": "Chongqing University",
                "contact": true
            },
            {
                "email": "yanlei@cqu.edu.cn",
                "first": "Yan",
                "last": "Lei",
                "affiliation": "School of Big Data & Software Engineering, Chongqing University",
                "contact": true
            },
            {
                "email": "hyzhang@cqu.edu.cn",
                "first": "Hongyu",
                "last": "Zhang",
                "affiliation": "Chongqing University",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering",
            "Software Analytics"
        ],
        "pc_conflicts": {
            "dposhyvanyk@gmail.com": true,
            "michael@binaervarianz.de": true,
            "junjiechen@tju.edu.cn": true,
            "xin.xia@acm.org": true,
            "shihan@microsoft.com": true,
            "haodan@pku.edu.cn": true,
            "lilicoding@ieee.org": true,
            "louyiling610@gmail.com": true,
            "hongyujohn@gmail.com": "author",
            "jie.zhang@kcl.ac.uk": true,
            "mnayebi@yorku.ca": true,
            "davidlo@smu.edu.sg": true,
            "taoxie@pku.edu.cn": true,
            "yutian.tang@glasgow.ac.uk": true,
            "y.sui@unsw.edu.au": true,
            "jiangjiajun@tju.edu.cn": true,
            "liu.chao@cqu.edu.cn": true,
            "xuwang@buaa.edu.cn": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683361526,
        "modified_at": 1683361526,
        "tags": [
            "accept#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 315,
        "title": "An Empirical Study of Malicious Code In PyPI Ecosystem",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-9c54e2ef8be36521b23091e51745e2b57047ab8894b3c0f5d38c9eeda0476341",
            "timestamp": 1683373507,
            "size": 935463,
            "pages": 11
        },
        "abstract": "PyPI provides a convenient and accessible package management platform to developers, enabling them to quickly implement specific functions and improve work efficiency. However, the rapid development of the PyPI ecosystem has led to a severe problem of malicious package propagation. Malicious developers disguise malicious packages as normal, posing a significant security risk to end-users. To this end, we conducted an empirical study to understand the characteristics and current state of the malicious code lifecycle in the PyPI ecosystem. We first built an automated data collection framework and collated a multi-source malicious code dataset containing 4,669 malicious package files. We preliminarily classified these malicious codes into five categories based on malicious behaviour characteristics. Our research found that over 50% of malicious code exhibits multiple malicious behaviours, with information stealing and command execution being particularly prevalent. In addition, we observed several novel attack vectors and anti-detection techniques. Our analysis revealed that 74.81% of all malicious packages successfully entered end-user projects through source code installation, thereby increasing security risks. A real-world investigation showed that many reported malicious packages persist in PyPI mirror servers globally, with over 72% remaining for an extended period after being discovered. Finally, we sketched a portrait of the malicious code lifecycle in the PyPI ecosystem, effectively reflecting the characteristics of malicious code at different stages. We also present some suggested mitigations to improve the security of the Python open-source ecosystem.",
        "authors": [
            {
                "email": "honywenair@gmail.com",
                "first": "Wenbo",
                "last": "Guo",
                "affiliation": "School of Cyber Science and Engineering, Sichuan University",
                "contact": true
            },
            {
                "email": "zhengzi.xu@ntu.edu.sg",
                "first": "Zhengzi",
                "last": "Xu",
                "affiliation": "School of Computer Science and Engineering, Nanyang Technological University",
                "contact": true
            },
            {
                "email": "chengwei001@e.ntu.edu.sg",
                "first": "Chengwei",
                "last": "Liu",
                "affiliation": "School of Computer Science and Engineering, Nanyang Technological University",
                "contact": true
            },
            {
                "email": "opcodesec@gmail.com",
                "first": "Cheng",
                "last": "Huang",
                "affiliation": "School of Cyber Science and Engineering, Sichuan University",
                "contact": true
            },
            {
                "email": "yongfangscu@gmail.com",
                "first": "Yong",
                "last": "Fang",
                "affiliation": "School of Cyber Science and Engineering, Sichuan University",
                "contact": true
            },
            {
                "email": "yangliu@ntu.edu.sg",
                "first": "Yang",
                "last": "Liu",
                "affiliation": "School of Computer Science and Engineering, Nanyang Technological University",
                "contact": true
            }
        ],
        "topics": [
            "Maintenance and Evolution",
            "Software Analytics"
        ],
        "pc_conflicts": {
            "junsun@smu.edu.sg": true,
            "lxiao6@stevens.edu": true,
            "senchen@tju.edu.cn": true,
            "gaocuiyun@hit.edu.cn": true,
            "ma.lei@acm.org": true,
            "lilicoding@ieee.org": true,
            "jie.zhang@kcl.ac.uk": true,
            "mnayebi@yorku.ca": true,
            "davidlo@smu.edu.sg": true,
            "xxie@whu.edu.cn": true,
            "y.sui@unsw.edu.au": true,
            "tsu@sei.ecnu.edu.cn": true,
            "xuwang@buaa.edu.cn": true,
            "yli044@e.ntu.edu.sg": true,
            "mengguozhu@iie.ac.cn": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683372518,
        "modified_at": 1683373821,
        "tags": [
            "accept#0"
        ]
    },
    {
        "object": "paper",
        "pid": 340,
        "title": "Scene-Driven Exploration and GUI Modeling for Android Apps",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-2251bd1d0a0548cbced81350bf7ac9e0af34271a9d193e52c861fb90ba02f6c3",
            "timestamp": 1683368244,
            "size": 4368337,
            "pages": 11
        },
        "abstract": "Due to the competitive environment, mobile apps are usually produced under pressure with lots of complicated functionality and UI pages. Therefore, it is challenging for various roles to design, understand, test, and maintain these apps. The extracted transition graphs for apps such as ATG, WTG, and STG have a low transition coverage and coarse-grained granularity, which limits the existing methods of graphical user interface (GUI) modeling by UI exploration. To solve these problems, in this paper, we propose SceneDroid, a scene-driven exploration approach to extracting the GUI scenes dynamically by integrating a series of novel techniques including smart exploration, state fuzzing, and indirect launching strategies. We present the GUI scenes as a scene transition graph (SceneTG) to model the GUI of apps with high transition coverage and fine-grained granularity. Compared with the existing GUI modeling tools, SceneDroid has improved by 168.74% in the coverage of transition pairs and 162.42% in scene extraction. Apart from the effectiveness evaluation of SceneDroid, we also illustrate the future potential of SceneDroid as a fundamental capability to support app development, reverse engineering, and GUI regression testing.",
        "authors": [
            {
                "email": "2120220657@mail.nankai.edu.cn",
                "first": "Xiangyu",
                "last": "Zhang",
                "affiliation": "Nankai University",
                "contact": true
            },
            {
                "email": "linglingfan@nankai.edu.cn",
                "first": "Lingling",
                "last": "Fan",
                "affiliation": "Nankai University",
                "contact": true
            },
            {
                "email": "senchen@tju.edu.cn",
                "first": "Sen",
                "last": "Chen",
                "affiliation": "Tianjin University",
                "contact": true
            },
            {
                "email": "suyucheng.syc@alibaba-inc.com",
                "first": "Yucheng",
                "last": "Su",
                "affiliation": "Alibaba Group",
                "contact": true
            },
            {
                "email": "liby2119@mails.jlu.edu.cn",
                "first": "Boyuan",
                "last": "Li",
                "affiliation": "Nankai University",
                "contact": true
            }
        ],
        "topics": [
            "Software Analytics"
        ],
        "pc_conflicts": {
            "dolby@us.ibm.com": true,
            "junsun@smu.edu.sg": true,
            "junjiechen@tju.edu.cn": true,
            "chunyang.chen@monash.edu": true,
            "senchen@tju.edu.cn": "author",
            "xfxie@smu.edu.sg": true,
            "lilicoding@ieee.org": true,
            "linglingfan@nankai.edu.cn": "author",
            "guowei.yang@uq.edu.au": true,
            "xyzhang@cs.purdue.edu": true,
            "jiangjiajun@tju.edu.cn": true,
            "mengguozhu@iie.ac.cn": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683368244,
        "modified_at": 1683368375,
        "tags": [
            "accept#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 361,
        "title": "Enhancing Malware Detection for Android Apps: Detecting Fine-granularity Malicious Components",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-81e26a5692b81f3fd305ac7a59960a092295e844aff3b1524b5939da5db03d41",
            "timestamp": 1683374385,
            "size": 848974,
            "pages": 12
        },
        "abstract": "Existing Android malware detection systems primarily concentrate on detecting malware apps, leaving a gap in the research concerning the detection of malicious components in apps. In this work, we propose a novel approach to detect fine-granularity malicious components for Android apps and build a prototype (AMCDroid). For a given app, AMCDroid first models app behavior to a homogenous graph based on the call graph and code statements of the app. Then, the graph is converted to a statement tree sequence for malware detection through the AST-based Neural Network with Feature Mapping (ASTNNF) model. Finally, if the app is detected as malware, AMCDroid applies fine-granularity malicious component detection (MCD) algorithm which is based on many-objective genetic algorithm to the homogenous graph for detecting malicious component in the app adaptively. We evaluate \\textit{AMCDroid} on 95,134 samples. Compared with the other two state-of-the-art methods in malware detection, AMCDroid gets the highest performance on the test set with 0.9699 F1-Score, and shows better robustness in facing obfuscation. Moreover, AMCDroid is capable of detecting fine-granularity malicious components of (obfuscated) malware apps. Especially, its average F1-Score exceeds another state-of-the-art method by 50%.",
        "authors": [
            {
                "email": "liuzhj2022@shanghaitech.edu.cn",
                "first": "Zhijie",
                "last": "Liu",
                "affiliation": "School of Information Science and Technology, ShanghaiTech University",
                "contact": true
            },
            {
                "email": "zhanglf@shanghaitech.edu.cn",
                "first": "Liang Feng",
                "last": "Zhang",
                "affiliation": "School of Information Science and Technology, ShanghaiTech University",
                "contact": true
            },
            {
                "email": "csytang@ieee.org",
                "first": "Yutian",
                "last": "Tang",
                "affiliation": "University of Glasgow",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering",
            "Dependability, Safety, and Reliability"
        ],
        "cover_letter": {
            "mimetype": "application\/pdf",
            "hash": "sha2-f9cfbc700fef9cdcd069cff75e856fb8da9cabd1f587d24b99a4908874d69b2f",
            "timestamp": 1690967226,
            "size": 106051,
            "filename": "Cover_Letter___ASE___AMCDroid.pdf",
            "pages": 1
        },
        "pc_conflicts": {
            "zp.chen@ucl.ac.uk": true,
            "csxluo@comp.polyu.edu.hk": true,
            "mnayebi@yorku.ca": true,
            "HandanGul.Calikli@glasgow.ac.uk": true,
            "tazhang@must.edu.mo": true,
            "yutian.tang@glasgow.ac.uk": "author",
            "y.sui@unsw.edu.au": true,
            "timothy.storer@glasgow.ac.uk": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1692027487,
        "modified_at": 1692092683,
        "tags": [
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 368,
        "title": "Fork Entropy: Assessing the Diversity of Open Source Software Projects' Forks",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-a33e48fa7cf237ec793fd6d6c54c9f88dc1409ad9147d8a13f26ad289d8bb96d",
            "timestamp": 1683335588,
            "size": 510010,
            "pages": 12
        },
        "abstract": "In this paper, we focus on the population of forks created in open source software (OSS) development and examine the diversity of an OSS project's forks. We propose a new metric called fork entropy to measure the diversity of fork populations around OSS projects using Rao's quadratic entropy. By measuring the diversity of forks in terms of modifications made to project files, the proposed fork entropy metric provides a new way to evaluate the variability of forks in a project. This paper contributes to the field in several ways. First, we introduce a new metric, fork entropy, to quantify and measure the diversity of forks in OSS projects. Second, we show how fork entropy is correlated with external productivity, acceptance rate of external pull-requests, and the number of reported bugs in OSS projects. This demonstrates that fork entropy is an effective indicator for understanding the development of OSS projects under the pull-based model. Third, we enrich the set of metrics about forks beyond simple number of forks. We also expand the current scope of diversity discussed in OSS development, which mainly focuses on the contributors, to further include the artifacts they create, i.e., forks. Despite that we focus on external contributors' forks and fork efficiency in this work, the proposed fork entropy can also be applied to OSS projects that adopt the pull-based model for all members including core members. In summary, this paper highlights the importance of fork diversity in OSS development and presents a novel metric to evaluate fork populations in OSS projects, providing valuable insights for project maintainers and contributors to understand and improve their fork practices.",
        "authors": [
            {
                "email": "wl@nju.edu.cn",
                "first": "Liang",
                "last": "Wang",
                "affiliation": "State Key Laboratory for Novel Software Technology, Nanjing University",
                "contact": true
            },
            {
                "email": "zwZheng@smail.nju.edu.cn",
                "first": "Zhiwen",
                "last": "Zheng",
                "affiliation": "State Key Laboratory for Novel Software Technology, Nanjing University",
                "contact": true
            },
            {
                "email": "xchenwuhhu@gmail.com",
                "first": "Xiangchen",
                "last": "Wu",
                "affiliation": "State Key Laboratory for Novel Software Technology, Nanjing University",
                "contact": true
            },
            {
                "email": "DZ21330024@smail.nju.edu.cn",
                "first": "Baihui",
                "last": "Sang",
                "affiliation": "State Key Laboratory for Novel Software Technology, Nanjing University",
                "contact": true
            },
            {
                "email": "jieruizhang@smail.nju.edu.cn",
                "first": "Jierui",
                "last": "Zhang",
                "affiliation": "State Key Laboratory for Novel Software Technology, Nanjing University",
                "contact": true
            },
            {
                "email": "txp@nju.edu.cn",
                "first": "Xianping",
                "last": "Tao",
                "affiliation": "State Key Laboratory for Novel Software Technology, Nanjing University",
                "contact": true
            }
        ],
        "topics": [
            "Software Analytics"
        ],
        "pc_conflicts": {
            "fengyang@nju.edu.cn": true,
            "changxu@nju.edu.cn": true,
            "taoyue@gmail.com": true,
            "fangchunrong@nju.edu.cn": true,
            "juanzhai@umass.edu": true,
            "jyy@nju.edu.cn": true,
            "zqzuo@nju.edu.cn": true,
            "why@nju.edu.cn": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683203073,
        "modified_at": 1683335588
    },
    {
        "object": "paper",
        "pid": 383,
        "title": "CAT-LM: Training Language Models on Aligned Code And Tests",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-8702e673bd3ac2982231ab221b33ef26faa143d97eb2bb40cd4655d140e9ca9a",
            "timestamp": 1683344566,
            "size": 882717,
            "pages": 12
        },
        "abstract": "Testing is an integral part of the software development process. Yet, writing tests is time-consuming and therefore often neglected. Classical test generation tools such as EvoSuite generate behavioral test suites by optimizing for coverage, but tend to produce tests that are hard to understand. Language models trained on code can generate code that is highly similar to that written by humans, but current models are trained to generate each file separately, as is standard practice in natural language processing, and thus fail to consider the code-under-test context when producing a test file. In this work, we propose the Aligned Code And Tests Language Model (CAT-LM), a GPT-style language model with 2.7 Billion parameters, trained on a corpus of Python and Java projects. We utilize a novel pretraining signal that explicitly considers the mapping between code and test files when available. We also drastically increase the maximum sequence length of inputs to 8,192 tokens, 4x more than typical code generation models, to ensure that the code context is available to the model when generating test code.\r\nWe analyze its usefulness for realistic applications, showing that sampling with filtering (e.g., by compilability, coverage) allows it to efficiently produce tests that achieve coverage similar to ones written by developers while resembling their writing style. By utilizing the code context, CAT-LM generates more valid tests than even much larger language models trained with more data (CodeGen 16B) and substantially outperforms a recent test-specific model (TeCo) at test completion. Overall, our work highlights the importance of incorporating software-specific insights when training language models for code and paves the way to more powerful automated test generation.",
        "authors": [
            {
                "email": "nikithar@andrew.cmu.edu",
                "first": "Nikitha",
                "last": "Rao",
                "affiliation": "Carnegie Mellon University",
                "contact": true
            },
            {
                "email": "kdjain@andrew.cmu.edu",
                "first": "Kush",
                "last": "Jain",
                "affiliation": "Carnegie Mellon University",
                "contact": true
            },
            {
                "email": "ualon@cs.cmu.edu",
                "first": "Uri",
                "last": "Alon",
                "affiliation": "Carnegie Mellon University",
                "contact": true
            },
            {
                "email": "clegoues@cs.cmu.edu",
                "first": "Claire",
                "last": "Le Goues",
                "affiliation": "Carnegie Mellon University",
                "contact": true
            },
            {
                "email": "vhellendoorn@cmu.edu",
                "first": "Vincent J.",
                "last": "Hellendoorn",
                "affiliation": "Carnegie Mellon University",
                "contact": true
            }
        ],
        "supplementary_material": {
            "mimetype": "application\/pdf",
            "hash": "sha2-61572a2d1c15908e50a62dce149a541c8c5967d10c996ce00524473bcf5f67f6",
            "timestamp": 1683345040,
            "size": 190429,
            "filename": "Supplementary_material__ASE_2023.pdf",
            "pages": 7
        },
        "topics": [
            "AI and Software Engineering",
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "rayb@cs.columbia.edu": true,
            "pwng@google.com": true,
            "grunske@informatik.hu-berlin.de": true,
            "michael@binaervarianz.de": true,
            "pcorina@cmu.edu": true,
            "contact@stefanstanciulescu.com": true,
            "y.tian@queensu.ca": true,
            "arie.vandeursen@tudelft.nl": true,
            "eunsukk@andrew.cmu.edu": true,
            "alastair.donaldson@imperial.ac.uk": true,
            "bacchelli@ifi.uzh.ch": true,
            "rma@fe.up.pt": true,
            "glewis@sei.cmu.edu": true,
            "mnayebi@yorku.ca": true,
            "davidlo@smu.edu.sg": true,
            "s.proksch@tudelft.nl": true,
            "sumon@case.edu": true,
            "ozkaya@sei.cmu.edu": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683344566,
        "modified_at": 1683346051,
        "tags": [
            "accept#0",
            "ChrisCoI#0",
            "dpa_candidate#0",
            "dpa_no#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 406,
        "title": "Nuances are the Key: Unlocking ChatGPT to Find Failure-Inducing Tests with Differential Prompting",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-9dfe7ecab3b41d3ce326f6890ea049609d9d01ffb508a52528a1bf777c283f8a",
            "timestamp": 1683376273,
            "size": 926515,
            "pages": 11
        },
        "abstract": "Automated detection of software failures is an important but challenging software engineering task. It involves finding in a vast search space the failure-inducing tests that contain an input triggering the software fault and an oracle asserting the incorrect execution. We are motivated to study how far this outstanding challenge can be solved by recent advances in large language models (LLMs) such as ChatGPT. However, our study reveals that ChatGPT has a relatively low success rate (28.8%) in finding correct failure-inducing test cases for buggy programs. A possible conjecture is that finding failure-inducing test cases requires analyzing the subtle differences (nuances) between the tokens for a program’s correct version and those for its buggy version. When these two versions have similar sets of tokens and attentions, ChatGPT is weak in distinguishing their differences.\r\nWe find that ChatGPT can successfully generate failure-inducing test cases when it is guided to focus on the nuances. Our solution is inspired by an interesting observation that ChatGPT could infer the intended functionality of buggy code if it is similar to the correct version. Driven by the inspiration, we develop a novel technique, called Differential Prompting, to effectively find failure-inducing test cases with the help of the compilable code synthesized by the inferred intention. Prompts are constructed based on the nuances between the given version and the synthesized code. We evaluate Differential Prompting on Quixbugs (a popular benchmark of buggy programs) and recent programs published at Codeforces (a popular programming contest portal, which is also an official benchmark of ChatGPT). We compare Differential Prompting with two baselines constructed using conventional ChatGPT prompting and PYNGUIN (the state-of-the-art unit test generation tool for Python programs). Our evaluation results show that for programs of Quixbugs, Differential Prompting can achieve a success rate of 75.0% in finding failure-inducing test cases, outperforming the best baseline by 2.6X. For programs of Codeforces, Differential Prompting’s success rate is 66.7%, outperforming the best baseline by 4.0X.",
        "authors": [
            {
                "email": "toli@connect.ust.hk",
                "first": "Tsz-on",
                "last": "Li",
                "affiliation": "Department of Computer Science and Engineering, The Hong Kong University of Science and Technology",
                "contact": true
            },
            {
                "email": "iamwenxiz@163.com",
                "first": "Wenxi",
                "last": "Zong",
                "affiliation": "Northeastern University",
                "contact": true
            },
            {
                "email": "yibowangcz@outlook.com",
                "first": "Yibo",
                "last": "Wang",
                "affiliation": "Northeastern University",
                "contact": true
            },
            {
                "email": "haoye.tian@uni.lu",
                "first": "Haoye",
                "last": "Tian",
                "affiliation": "University of Luxembourg",
                "contact": true
            },
            {
                "email": "wangying@swc.neu.edu.cn",
                "first": "Ying",
                "last": "Wang",
                "affiliation": "Northeastern University",
                "contact": true
            },
            {
                "email": "scc@cse.ust.hk",
                "first": "Shing-Chi",
                "last": "Cheung",
                "affiliation": "Department of Computer Science and Engineering, The Hong Kong University of Science and Technology",
                "contact": true
            },
            {
                "email": "j.kramer@imperial.ac.uk",
                "first": "Jeff",
                "last": "Kramer",
                "affiliation": "Imperial College London",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering",
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "junjiechen@tju.edu.cn": true,
            "kevin.allix@centralesupelec.fr": true,
            "M.Sabetzadeh@uottawa.ca": true,
            "j.bell@northeastern.edu": true,
            "xin.xia@acm.org": true,
            "shihan@microsoft.com": true,
            "changxu@nju.edu.cn": true,
            "shuaiw@cse.ust.hk": true,
            "haodan@pku.edu.cn": true,
            "gaocuiyun@hit.edu.cn": true,
            "ma.lei@acm.org": true,
            "lilicoding@ieee.org": true,
            "csxluo@comp.polyu.edu.hk": true,
            "fangchunrong@nju.edu.cn": true,
            "a.filieri@imperial.ac.uk": true,
            "hongyujohn@gmail.com": true,
            "domenico.bianculli@uni.lu": true,
            "alastair.donaldson@imperial.ac.uk": true,
            "wangying@swc.neu.edu.cn": "collaborator author",
            "mnayebi@yorku.ca": true,
            "taoxie@pku.edu.cn": true,
            "wurongxin@xmu.edu.cn": true,
            "fabrizio.pastore@uni.lu": true,
            "snejati@uottawa.ca": true,
            "renzo.degiovanni@uni.lu": true,
            "d.shin@sheffield.ac.uk": true,
            "mwenaa@hust.edu.cn": true,
            "dalal.alrajeh@ic.ac.uk": true,
            "yli044@e.ntu.edu.sg": true,
            "ezekiel.soremekun@rhul.ac.uk": true,
            "v.nowack@imperial.ac.uk": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683368952,
        "modified_at": 1683376273,
        "tags": [
            "accept#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 421,
        "title": "VRGuide: Efficient Testing of Virtual Reality Scenes via Dynamic Cut Coverage",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-20902217c68e8f58df2da199376c8e2bf5813eb80d707df6ed5dabb85e8d33b3",
            "timestamp": 1683175777,
            "size": 784026,
            "pages": 12
        },
        "abstract": "Virtual Reality (VR) is an emerging technique that have been applied to more and more areas such as gaming, remote conference, and education. Since VR user interface has very different character compared with traditional graphic user interface (GUI), VR applications also require new testing techniques for quality assurance. Recently, some frameworks (e.g., VRTest) have been proposed to automate VR user interface testing by automatically controlling the player camera. However, their testing strategies are not able to address VR-specific testing challenges such as object occlusion and movement. In this paper, we propose a novel testing technique called VRGuide to explore VR scenes more efficiently. In particular, VRGuide adapts a computer geometry technique called Cut Extension to optimize the camera routes for covering all interact-able objects. \r\nWe compared the testing strategy with VRTest on eight top VR software projects with scenes. The results show that VRGuide is able to achieve higher test coverage upon testing timeout in two of the projects, and achieving saturation coverage with averagely 31% less testing time than VRTest on the remaining six projects. Furthermore, VRGuide detected and reported three unknown bugs from the projects, only one of which is also detected by VRTest.",
        "authors": [
            {
                "email": "xiaoyin.wang@utsa.edu",
                "first": "Xiaoyin",
                "last": "Wang",
                "affiliation": "University of Texas at San Antonio",
                "contact": true
            },
            {
                "email": "md.tahmidulislam.rafi@utsa.edu",
                "first": "Tahmid",
                "last": "Rafi",
                "affiliation": "University of Texas at San Antonio",
                "contact": true
            },
            {
                "email": "nm8247@vt.edu",
                "first": "Na",
                "last": "Meng",
                "affiliation": "Virginia Tech",
                "contact": true
            }
        ],
        "topics": [
            "Testing and Analysis",
            "Tools and Processes"
        ],
        "pc_conflicts": {
            "lxiao6@stevens.edu": true,
            "lingming@illinois.edu": true,
            "tianyi@purdue.edu": true,
            "xin.xia@acm.org": true,
            "xusheng.xiao@asu.edu": true,
            "liuhui08@bit.edu.cn": true,
            "wangying@swc.neu.edu.cn": true,
            "mnayebi@yorku.ca": true,
            "davidlo@smu.edu.sg": true,
            "taoxie@pku.edu.cn": true,
            "zhonghao@sjtu.edu.cn": true,
            "xiaoyin.wang@utsa.edu": "author"
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683175777,
        "modified_at": 1683175777,
        "tags": [
            "accept#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 426,
        "title": "Eiffel: Inferring Input Ranges of Significant Floating-point Errors via Polynomial Extrapolation",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-fe7e325cac59c18a695ae907e9b59bd00ce1ba1a0c0db2c341546df7ec195410",
            "timestamp": 1683357427,
            "size": 5277916,
            "pages": 12
        },
        "abstract": "Existing search heuristics used to find input values that result in significant floating-point (FP) errors or small ranges that cover them are accompanied by severe constraints, complicating their implementation and restricting their general applicability. This paper introduces an error analysis tool called Eiffel to infer error-inducing input ranges instead of searching them. Given an FP expression with its domain $\\mathcal{D}$, Eiffel first constructs an error data set by sampling values across a smaller domain $\\mathcal{R}$ and assembles these data into clusters. If more than two clusters are formed, Eiffel derives polynomial curves that best fit the bound coordinates of the error-inducing ranges in $\\mathcal{R}$, extrapolating them to infer all target ranges of $\\mathcal{D}$ and reporting the maximal error. Otherwise, Eiffel simply returns the largest error across $\\mathcal{R}$. Experimental results show that Eiffel exhibits a broader applicability than Atomu and S$^3$FP by successfully detecting the errors of all 70 considered benchmarks while the two baselines only report errors for part of them. By taking as input the inferred ranges of Eiffel, Herbie obtains an average accuracy improvement of 3.35 bits and up to 53.3 bits.",
        "authors": [
            {
                "email": "zhangzuoyan523@163.com",
                "first": "Zuoyan",
                "last": "Zhang",
                "affiliation": "Information Engineering University"
            },
            {
                "email": "beibei_0812@126.com",
                "first": "Bei",
                "last": "Zhou",
                "affiliation": "Information Engineering University"
            },
            {
                "email": "haojiangweitimo@foxmail.com",
                "first": "Jiangwei",
                "last": "Hao",
                "affiliation": "Information Engineering University"
            },
            {
                "email": "hpcyhr@163.com",
                "first": "Hongru",
                "last": "Yang",
                "affiliation": "Information Engineering University"
            },
            {
                "email": "saki1340@163.com",
                "first": "Mengqi",
                "last": "Cui",
                "affiliation": "Information Engineering University",
                "contact": true
            },
            {
                "email": "zyc_1013@163.com",
                "first": "Yuchang",
                "last": "Zhou",
                "affiliation": "Information Engineering University"
            },
            {
                "email": "sheensong@163.com",
                "first": "Guanghui",
                "last": "Song",
                "affiliation": "Information Engineering University"
            },
            {
                "email": "feili2022@hotmail.com",
                "first": "Fei",
                "last": "Li",
                "affiliation": "Information Engineering University"
            },
            {
                "email": "atao728208@126.com",
                "first": "Jinchen",
                "last": "Xu",
                "affiliation": "Information Engineering University"
            },
            {
                "email": "yaozhujiajie@gmail.com",
                "first": "Jie",
                "last": "Zhao",
                "affiliation": "Information Engineering University",
                "contact": true
            }
        ],
        "topics": [
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "mnayebi@yorku.ca": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1691749804,
        "modified_at": 1691749804,
        "tags": [
            "accept#0"
        ]
    },
    {
        "object": "paper",
        "pid": 439,
        "title": "Understanding and Remediating Open-Source License Incompatibilities in the PyPI Ecosystem",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-2557c0e1ea1af8717ae1734f3abd654f494581b0c4842cf9deba2e1924b8f652",
            "timestamp": 1683367812,
            "size": 502897,
            "pages": 12
        },
        "abstract": "The reuse and distribution of open-source software must be in compliance with its accompanying open-source license. In modern packaging ecosystems, maintaining such compliance is challenging because a package may have a complex multi-layered dependency graph with many packages, any of which may have an incompatible license. Although prior research finds that license incompatibilities are prevalent, empirical evidence is still scarce in some modern packaging ecosystems (e.g., PyPI). It also remains unclear how developers remediate the license incompatibilities in the dependency graphs of their packages (including direct and transitive dependencies), let alone any automated approaches.\r\n\r\nTo bridge this gap, we conduct a large-scale empirical study of license incompatibilities and their remediation practices in the PyPI ecosystem. We find that 7.27% of the PyPI package releases have license incompatibilities and 61.3% of them are caused by transitive dependencies, causing challenges in their remediation; for remediation, developers can apply one of the five strategies: migration, removal, pinning versions, changing their own licenses, and negotiation. Inspired by our findings, we propose SILENSE, an SMT-solver-based approach to recommend license incompatibility remediations with minimal costs in package dependency graph. Our evaluation shows that SILENSE can match the proposed remediations in 19 real-world cases except for migrations not covered by an existing knowledge base.",
        "authors": [
            {
                "email": "xuww@stu.pku.edu.cn",
                "first": "Weiwei",
                "last": "Xu",
                "affiliation": "Peking University",
                "contact": true
            },
            {
                "email": "heh@pku.edu.cn",
                "first": "Hao",
                "last": "He",
                "affiliation": "Peking University",
                "contact": true
            },
            {
                "email": "gaokai19@pku.edu.cn",
                "first": "Kai",
                "last": "Gao",
                "affiliation": "Peking University",
                "contact": true
            },
            {
                "email": "zhmh@pku.edu.cn",
                "first": "Minghui",
                "last": "Zhou",
                "affiliation": "Peking University",
                "contact": true
            }
        ],
        "topics": [
            "Maintenance and Evolution",
            "Software Analytics"
        ],
        "pc_conflicts": {
            "zp.chen@ucl.ac.uk": true,
            "haodan@pku.edu.cn": true,
            "ding_li@pku.edu.cn": true,
            "xavier.devroey@unamur.be": true,
            "louyiling610@gmail.com": true,
            "mnayebi@yorku.ca": true,
            "taoxie@pku.edu.cn": true,
            "shanshanli@nudt.edu.cn": true,
            "wangbo_cs@bjtu.edu.cn": true,
            "wangdi95@pku.edu.cn": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683352476,
        "modified_at": 1683368161
    },
    {
        "object": "paper",
        "pid": 443,
        "title": "WADIFF: A Differential Testing Framework for WebAssembly Runtimes",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-92ec6504f2296e231e79a3c58207a991a743f96d792853a17cd8d0402282d467",
            "timestamp": 1683374104,
            "size": 536559,
            "pages": 11
        },
        "abstract": "WebAssembly (Wasm) runtime provides a virtual machine that can execute the WebAssembly modules and is widely used in different areas (e.g., browsers, edge computing, blockchain). Thus, the precision and reliability of the WebAssembly runtime are important and deserve our attention. To ensure the correctness and detect potential bugs in WebAssembly runtimes, we propose WADIFF, a differential testing framework, which consists of a sufficient test case generator and a deterministic differential testing engine. To evaluate the effectiveness of WADIFF, we apply it on seven popular WebAssembly runtimes and found 411 inconsistent instructions due to bugs and different implementation details in runtimes. Furthermore, we identify 21 bugs from 7 WebAssembly runtimes, and 7 of them are confirmed by their developers.",
        "authors": [
            {
                "email": "csszhou1@comp.polyu.edu.hk",
                "first": "Shiyao",
                "last": "Zhou",
                "affiliation": "The Hong Kong Polytechnic University",
                "contact": true
            },
            {
                "email": "csmjiang@comp.polyu.edu.hk",
                "first": "Muhui",
                "last": "Jiang",
                "affiliation": "The Hong Kong Polytechnic University",
                "contact": true
            },
            {
                "email": "cswchen@comp.polyu.edu.hk",
                "first": "Weimin",
                "last": "CHEN",
                "affiliation": "The Hong Kong Polytechnic University (PolyU)",
                "contact": true
            },
            {
                "email": "cshaoz@comp.polyu.edu.hk",
                "first": "Hao",
                "last": "Zhou",
                "affiliation": "Department of Computing, The Hong Kong Polytechnic University, Hong Kong, China",
                "contact": true
            },
            {
                "email": "haoyuwang@hust.edu.cn",
                "first": "Haoyu",
                "last": "Wang",
                "affiliation": "Huazhong University of Science and Technology",
                "contact": true
            },
            {
                "email": "csxluo@comp.polyu.edu.hk",
                "first": "Xiapu",
                "last": "Luo",
                "affiliation": "The Hong Kong Polytechnic University",
                "contact": true
            }
        ],
        "topics": [
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "zp.chen@ucl.ac.uk": true,
            "xin.xia@acm.org": true,
            "senchen@tju.edu.cn": true,
            "xusheng.xiao@asu.edu": true,
            "lilicoding@ieee.org": true,
            "csxluo@comp.polyu.edu.hk": "author",
            "linglingfan@nankai.edu.cn": true,
            "mnayebi@yorku.ca": true,
            "davidlo@smu.edu.sg": true,
            "tazhang@must.edu.mo": true,
            "yutian.tang@glasgow.ac.uk": true,
            "bagheri@unl.edu": true,
            "y.sui@unsw.edu.au": true,
            "mwenaa@hust.edu.cn": true,
            "hndai@ieee.org": true,
            "yli044@e.ntu.edu.sg": true,
            "mengguozhu@iie.ac.cn": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683362073,
        "modified_at": 1683374104,
        "tags": [
            "accept#0"
        ]
    },
    {
        "object": "paper",
        "pid": 449,
        "title": "The Devil is in the Tails: How Long-Tailed Code Distributions Impact Large Language Models",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-1687a0a66b03f1e34e9bd9b6e0dbeeecf4ad8155b49c8b0cbb30251c615886e6",
            "timestamp": 1683286373,
            "size": 1354119,
            "pages": 12
        },
        "abstract": "Learning-based techniques have gained considerable popularity in various software engineering (SE) tasks. However, most existing works focus on designing better learning-based models and pay less attention to the properties of datasets. Learning-based models heavily rely on data, and the data's properties (e.g., data distribution) could significantly affect their behavior. We conducted an exploratory study on the distribution of SE data and found that such data usually follows a skewed distribution (i.e., long-tailed distribution) where a small number of classes have an extensive collection of samples, while a large number of classes have very few samples. We investigate three distinct SE tasks and analyze the impacts of long-tailed distribution on the performance of learning-based models. Our experimental results reveal that the long-tailed distribution has a substantial impact on the effectiveness of learning-based SE models. Specifically, the models perform between 30.0\\% and 254.0\\% worse on data samples associated with infrequent labels compared to data samples of frequent labels. \r\nOur study provides a better understanding of the effects of long-tailed distributions on SE tools and insights for the future development of SE automation.",
        "authors": [
            {
                "email": "xinzhou.2020@phdcs.smu.edu.sg",
                "first": "Xin",
                "last": "Zhou",
                "affiliation": "School of Computing and Information Systems, Singapore Management University",
                "contact": true
            },
            {
                "email": "kisubkim@smu.edu.sg",
                "first": "Kisub",
                "last": "Kim",
                "affiliation": "School of Computing and Information Systems, Singapore Management University",
                "contact": true
            },
            {
                "email": "bowenxu.2017@phdcs.smu.edu.sg",
                "first": "Bowen",
                "last": "XU",
                "affiliation": "School of Computing and Information Systems, Singapore Management University",
                "contact": true
            },
            {
                "email": "jkliu@smu.edu.sg",
                "first": "Jiakun",
                "last": "Liu",
                "affiliation": "School of Computing and Information Systems, Singapore Management University",
                "contact": true
            },
            {
                "email": "donggyun.han@rhul.ac.uk",
                "first": "DongGyun",
                "last": "Han",
                "affiliation": "Royal Holloway, University of London",
                "contact": true
            },
            {
                "email": "davidlo@smu.edu.sg",
                "first": "David",
                "last": "Lo",
                "affiliation": "School of Computing and Information Systems, Singapore Management University",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering"
        ],
        "pc_conflicts": {
            "grunske@informatik.hu-berlin.de": true,
            "pcorina@cmu.edu": true,
            "junsun@smu.edu.sg": true,
            "y.tian@queensu.ca": true,
            "shaowei.wang@umanitoba.ca": true,
            "kevin.allix@centralesupelec.fr": true,
            "xin.xia@acm.org": true,
            "changxu@nju.edu.cn": true,
            "xfxie@smu.edu.sg": true,
            "raula-k@is.naist.jp": true,
            "zhendong@fudan.edu.cn": true,
            "gaocuiyun@hit.edu.cn": true,
            "mark.harman@ucl.ac.uk": true,
            "lilicoding@ieee.org": true,
            "csxluo@comp.polyu.edu.hk": true,
            "a.filieri@imperial.ac.uk": true,
            "timofey.bryksin@jetbrains.com": true,
            "daniela.micucci@unimib.it": true,
            "foutse.khomh@polymtl.ca": true,
            "jie.zhang@kcl.ac.uk": true,
            "hoa@uow.edu.au": true,
            "rma@fe.up.pt": true,
            "davidlo@smu.edu.sg": "collaborator author",
            "tazhang@must.edu.mo": true,
            "thomas.bach03@sap.com": true,
            "fatemeh.fard@ubc.ca": true,
            "iftekha@uci.edu": true,
            "xinghu@zju.edu.cn": true,
            "jiangjiajun@tju.edu.cn": true,
            "liu.chao@cqu.edu.cn": true,
            "sahraouh@iro.umontreal.ca": true,
            "ezekiel.soremekun@rhul.ac.uk": true,
            "martinschaef@gmail.com": true,
            "gaucho@amazon.com": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683285484,
        "modified_at": 1691861879,
        "tags": [
            "accept#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 463,
        "title": "Detection of Java Basic Thread Misuses Based on Static Event Analysis",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-ef42383e333458387ab90375039d96e1f72b097892e8458a3bb48c296bc8baa7",
            "timestamp": 1683372842,
            "size": 598514,
            "pages": 12
        },
        "abstract": "The fundamental asynchronous thread (java.lang.Thread} in Java can be easily misused, due to the lack of deep understanding for garbage collection and thread interruption mechanism. \r\nFor example, a careless implementation of asynchronous thread  may cause no response to the interrupt mechanism in time, resulting in unexpected thread-related behaviors, especially resource leak\/waste. \r\n\r\nCurrently, few works aim at these misuses and related works adopt either the dynamic approach without effective inputs or  the static path-sensitive approach with high time consumption due to the path explosion, causing false negatives. \r\nWe have found that the behavior of threads and  the interaction between threads and its referencing objects can be abstracted to a sequence of their events.\r\nIn this paper, we propose an event analysis approach to detect the defects in Java programs and Android apps with three misuse patterns based on the thread features.\r\nIt focuses on the existence or the order of the events to reduce the false negatives.\r\nWe extract the misuse related events, containing the thread events and the destroy events of the object referenced by the thread.\r\nThen we analyze the events with loop identification, happens-before relationship construction and alias determination, and design efficient algorithms  with polynomial time complexity.\r\nFinally, we implement an automatic tool named Leopard and evaluate it on 9 popular large Java programs and 147 real world Android apps.\r\nExperiments show that it is efficient when comparing with the existing approach (misuse: 723 vs 47, time: 60s vs 30min). \r\nThe manual check indicates that Leopard is more efficient and effective than existing work.\r\nBesides, 64 issues reported by us have been confirmed and 19 of them have been fixed by developers.",
        "authors": [
            {
                "email": "cuibq@ios.ac.cn",
                "first": "Baoquan",
                "last": "Cui",
                "affiliation": "State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing, China",
                "contact": true
            },
            {
                "first": "Miaomiao",
                "last": "Wang",
                "affiliation": "Technology Center of Software Engineering, Institute of Software, Chinese Academy of Sciences, Beijing, China"
            },
            {
                "email": "zhangchi@ios.ac.cn",
                "first": "Chi",
                "last": "Zhang",
                "affiliation": "State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing, China",
                "contact": true
            },
            {
                "email": "yanjw@ios.ac.cn",
                "first": "Jiwei",
                "last": "Yan",
                "affiliation": "Technology Center of Software Engineering, Institute of Software, Chinese Academy of Sciences, Beijing, China",
                "contact": true
            },
            {
                "email": "yanjun@ios.ac.cn",
                "first": "Jun",
                "last": "Yan",
                "affiliation": "Technology Center of Software Engineering, Institute of Software, Chinese Academy of Sciences, Beijing, China",
                "contact": true
            },
            {
                "email": "zj@ios.ac.cn",
                "first": "Jian",
                "last": "Zhang",
                "affiliation": "State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing, China",
                "contact": true
            }
        ],
        "topics": [
            "Dependability, Safety, and Reliability",
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "rayb@cs.columbia.edu": true,
            "dposhyvanyk@gmail.com": true,
            "michael@binaervarianz.de": true,
            "dolby@us.ibm.com": true,
            "junsun@smu.edu.sg": true,
            "gunel.jahangirova@kcl.ac.uk": true,
            "arie.vandeursen@tudelft.nl": true,
            "lingming@illinois.edu": true,
            "tuba@ece.ufl.edu": true,
            "j.bell@northeastern.edu": true,
            "shuaiw@cse.ust.hk": true,
            "liuhui08@bit.edu.cn": true,
            "elenasherman@boisestate.edu": true,
            "domenico.bianculli@uni.lu": true,
            "jie.zhang@kcl.ac.uk": true,
            "rma@fe.up.pt": true,
            "mnayebi@yorku.ca": true,
            "leonardo.mariani@unimib.it": true,
            "davidlo@smu.edu.sg": true,
            "xuwang@buaa.edu.cn": true,
            "jyy@nju.edu.cn": true,
            "kpmoran@ucf.edu": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683372400,
        "modified_at": 1683372842,
        "tags": [
            "accept#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 473,
        "title": "Two Birds with One Stone: Multi-Derivation for Fast Context-Free Language Reachability Analysis",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-9ef16a4629a4bc29ebc4da7224949f4266b98cf630b57a42661498884761adb3",
            "timestamp": 1690707365,
            "size": 357044,
            "pages": 13
        },
        "abstract": "Context-free language (CFL) reachability is a fundamental framework for formulating program analyses. CFL-reachability analysis works on top of an edge-labeled graph by deriving reachability relations and adding them as labeled edges to the graph. Existing CFL-reachability algorithms typically adopt a single-reachability relation derivation (SRD) strategy, i.e., one reachability relation is derived at a time. Unfortunately, this strategy can lead to redundancy,  hindering the efficiency of the analysis. \r\n\r\nTo address this problem, this paper proposes PEARL, a multi-derivation approach that reduces derivation redundancy for transitive relations that frequently arise when solving reachability relations, significantly improving the efficiency of CFL-reachability analysis. Our key insight is that multiple edges involving transitivity can be simultaneously derived via batch propagation of reachability relations on the transitivity-aware subgraphs that are induced from the original edge-labeled graph. We evaluate the performance of PEARL on two clients, i.e., context-sensitive value-flow analysis and field-sensitive alias analysis for C\/C++. By eliminating a large amount of redundancy, PEARL achieves average speedups of 82.73x for value-flow analysis and 155.26x for alias analysis over the standard CFL-reachability algorithm.\r\nThe comparison with POCR, a state-of-the-art CFL-reachability solver, shows that PEARL runs 10.1x (up to 29.2x) and 2.37x (up to 4.22x) faster on average respectively for value-flow analysis and alias analysis with less consumed memory.",
        "authors": [
            {
                "email": "shichenghang21s@ict.ac.cn",
                "first": "Chenghang",
                "last": "Shi",
                "affiliation": "SKLP, Institute of Computing Technology, CAS",
                "contact": true
            },
            {
                "email": "lihaofeng@ict.ac.cn",
                "first": "Haofeng",
                "last": "Li",
                "affiliation": "SKLP, Institute of Computing Technology, CAS",
                "contact": true
            },
            {
                "email": "y.sui@unsw.edu.au",
                "first": "Yulei",
                "last": "Sui",
                "affiliation": "University of New South Wales",
                "contact": true
            },
            {
                "email": "lujie@ict.ac.cn",
                "first": "Jie",
                "last": "Lu",
                "affiliation": "SKLP, Institute of Computing Technology, CAS",
                "contact": true
            },
            {
                "email": "lianli@ict.ac.cn",
                "first": "Lian",
                "last": "Li",
                "affiliation": "SKLP, Institute of Computing Technology, CAS",
                "contact": true
            },
            {
                "email": "j.xue@unsw.edu.au",
                "first": "Jingling",
                "last": "Xue",
                "affiliation": "University of New South Wales",
                "contact": true
            }
        ],
        "supplementary_material": {
            "mimetype": "application\/zip",
            "hash": "sha2-fec6281bc1b7d7c80d4008afac48044eded0f300829415e6b5a7d14b0f40ff6d",
            "timestamp": 1690707365,
            "size": 255388784,
            "filename": "artifact.zip"
        },
        "topics": [
            "Testing and Analysis"
        ],
        "cover_letter": {
            "mimetype": "application\/pdf",
            "hash": "sha2-8357ded60293b71106af91b5dd5a06e5b3afc69abe2fdd54ff8ed7eee560046a",
            "timestamp": 1690707369,
            "size": 19811,
            "filename": "cover-letter.pdf",
            "pages": 1
        },
        "pc_conflicts": {
            "j.xue@unsw.edu.au": "collaborator author",
            "xfxie@smu.edu.sg": true,
            "lilicoding@ieee.org": true,
            "csxluo@comp.polyu.edu.hk": true,
            "hongyujohn@gmail.com": true,
            "yutian.tang@glasgow.ac.uk": true,
            "dongjieh@cse.unsw.edu.au": true,
            "y.sui@unsw.edu.au": "author",
            "lianli@ict.ac.cn": "author",
            "yli044@e.ntu.edu.sg": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1692003312,
        "modified_at": 1692003312,
        "tags": [
            "accept#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 479,
        "title": "Aster: Automatic Speech Recognition System Accessibility Testing for Stutterers",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-1c0d78337b1fb0a9a0887e31e2036848a648fbb7709e65d1727d82f817bf6eab",
            "timestamp": 1683372781,
            "size": 430516,
            "pages": 12
        },
        "abstract": "The popularity of automatic speech recognition (ASR)\r\nsystems nowadays leads to an increasing need for improving\r\ntheir accessibility. Handling stuttering speech is an important\r\nfeature for accessible ASR systems. To improve the accessibility\r\nof ASR systems for stutterers, we need to expose and analyze\r\nthe failures of ASR systems on stuttering speech. The speech\r\ndatasets recorded from stutterers are not diverse enough to expose\r\nmost of the failures. Furthermore, these datasets lack ground\r\ntruth information about the non-stuttered text, rendering them\r\nunsuitable as comprehensive test suites. Therefore, a methodology\r\nfor generating stuttering speech as test inputs to test and analyze\r\nthe performance of ASR systems is needed. However, generating\r\nvalid test inputs in this scenario is challenging. The reason is that\r\nalthough the generated test inputs should mimic how stutterers\r\nspeak, they should also be diverse enough to trigger more failures.\r\nTo address the challenge, we propose ASTER, a technique for\r\nautomatically testing the accessibility of ASR systems. ASTER\r\ncan generate valid test cases by injecting five different types of\r\nstuttering. The generated test cases can both simulate realistic\r\nstuttering speech and expose failures in ASR systems. Moreover,\r\nASTER can further enhance the quality of the test cases with a\r\nmulti-objective optimization-based seed updating algorithm. We\r\nimplemented ASTER as a framework and evaluated it on four\r\nopen-source ASR models and three commercial ASR systems. We\r\nconduct a comprehensive evaluation of ASTER and find that it\r\nsignificantly increases the word error rate, match error rate, and\r\nword information loss in the evaluated ASR systems. Additionally,\r\nour user study demonstrates that the generated stuttering audio\r\nis indistinguishable from real-world stuttering audio clips.",
        "authors": [
            {
                "email": "yi009@e.ntu.edu.sg",
                "first": "Yi",
                "last": "Liu",
                "affiliation": "Nanyang Technological University",
                "contact": true
            },
            {
                "email": "yuekang.li@ntu.edu.sg",
                "first": "Yuekang",
                "last": "Li",
                "affiliation": "University of New South Wales",
                "contact": true
            },
            {
                "email": "gdeng003@e.ntu.edu.sg",
                "first": "Gelei",
                "last": "Deng",
                "affiliation": "Nanyang Technological University",
                "contact": true
            },
            {
                "email": "juefei.xu@gmail.com",
                "first": "Felix",
                "last": "Juefei-Xu",
                "affiliation": "Meta AI",
                "contact": true
            },
            {
                "email": "yaodu@usc.edu",
                "first": "Yao",
                "last": "Du",
                "affiliation": "University of Southern California"
            },
            {
                "email": "cen001@e.ntu.edu.sg",
                "first": "Cen",
                "last": "Zhang",
                "affiliation": "Nanyang Technological University",
                "contact": true
            },
            {
                "email": "chengwei001@e.ntu.edu.sg",
                "first": "Chengwei",
                "last": "Liu",
                "affiliation": "Nanyang Technological University",
                "contact": true
            },
            {
                "email": "liyeting@iie.ac.cn",
                "first": "Yeting",
                "last": "Li",
                "affiliation": "Institute of Information Engineering, Chinese Academy of Sciences;University of Chinese Academy of Sciences",
                "contact": true
            },
            {
                "email": "ma.lei@acm.org",
                "first": "Lei",
                "last": "Ma",
                "affiliation": "The University of Tokyo & University of Alberta",
                "contact": true
            },
            {
                "email": "yangliu@ntu.edu.sg",
                "first": "Yang",
                "last": "Liu",
                "affiliation": "Nanyang Technological University",
                "contact": true
            }
        ],
        "topics": [
            "Human Aspects of Software Engineering"
        ],
        "pc_conflicts": {
            "rayb@cs.columbia.edu": true,
            "pwng@google.com": true,
            "j.xue@unsw.edu.au": true,
            "michael@binaervarianz.de": true,
            "shang@encs.concordia.ca": true,
            "dolby@us.ibm.com": true,
            "junsun@smu.edu.sg": true,
            "junjiechen@tju.edu.cn": true,
            "chunyang.chen@monash.edu": true,
            "zp.chen@ucl.ac.uk": true,
            "lxiao6@stevens.edu": true,
            "lingming@illinois.edu": true,
            "tianyi@purdue.edu": true,
            "kevin.allix@centralesupelec.fr": true,
            "j.bell@northeastern.edu": true,
            "xin.xia@acm.org": true,
            "fengyang@nju.edu.cn": true,
            "shihan@microsoft.com": true,
            "changxu@nju.edu.cn": true,
            "senchen@tju.edu.cn": true,
            "shuaiw@cse.ust.hk": true,
            "xfxie@smu.edu.sg": true,
            "zhendong@fudan.edu.cn": true,
            "ding_li@pku.edu.cn": true,
            "gaocuiyun@hit.edu.cn": true,
            "ma.lei@acm.org": "collaborator author",
            "mark.harman@ucl.ac.uk": true,
            "lilicoding@ieee.org": true,
            "csxluo@comp.polyu.edu.hk": true,
            "louyiling610@gmail.com": true,
            "csaba.nagy@usi.ch": true,
            "a.filieri@imperial.ac.uk": true,
            "eunsukk@andrew.cmu.edu": true,
            "skim131@meta.com": true,
            "hongyujohn@gmail.com": true,
            "linglingfan@nankai.edu.cn": true,
            "jie.zhang@kcl.ac.uk": true,
            "mnayebi@yorku.ca": true,
            "davidlo@smu.edu.sg": true,
            "taoxie@pku.edu.cn": true,
            "thomas.bach03@sap.com": true,
            "bob.darkprince@gmail.com": true,
            "yutian.tang@glasgow.ac.uk": true,
            "dongjieh@cse.unsw.edu.au": true,
            "jordan.henkel@microsoft.com": true,
            "xxie@whu.edu.cn": true,
            "y.sui@unsw.edu.au": true,
            "tsu@sei.ecnu.edu.cn": true,
            "xuwang@buaa.edu.cn": true,
            "yli044@e.ntu.edu.sg": "author",
            "mengguozhu@iie.ac.cn": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683362666,
        "modified_at": 1683564163
    },
    {
        "object": "paper",
        "pid": 487,
        "title": "QuraTest: Integrating Quantum Specific Features in Quantum Program Testing",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-64b14baf6b9bc3a2e2eb7771497608b23aed4bec54a61253173f73afdf883457",
            "timestamp": 1683373601,
            "size": 2225320,
            "pages": 12
        },
        "abstract": "The recent fast development of quantum computers breaks several computation limitations that are difficult for conventional computers. At the same time, with the development of quantum computation, the bugs in quantum programs also start to raise concerns. Up to the present, although many approaches and tools have been proposed to test quantum programs, the fundamental features of quantum programs, i.e., magnitude, phase, and entanglement, have been largely overlooked so far, leading to low fault detection capability and reduced testing effectiveness. \r\nTo address this problem, we propose QuraTest, equipped with three test case generators, i.e., UCNOT, IQFT, and Random, where two of them are newly proposed. The proposed generators can generate a diverse set of test inputs by considering the quantum features of quantum programs. \r\nIn the experiments, we evaluate QuraTest from three aspects: generated test case diversity, output coverage of the program under test, and fault detection capability. For evaluations, we further propose three metrics for test case diversity. The results demonstrate that IQFT can generate the most diverse test cases regarding magnitude, phase, and entanglement, with 66% cell coverage. Comparatively, the Random approach only has 10% cell coverage. Regarding the evaluations of the output coverage, IQFT can achieve the highest output coverage in 70.2% (33 out of 47) of all quantum programs. In terms of fault detection, UCNOT outperforms the other two approaches. Specifically, the test cases generated by UCNOT have the best mutation score in 88.4% (23 out of 26) programs.",
        "authors": [
            {
                "email": "yejjmg@gmail.com",
                "first": "Jiaming",
                "last": "Ye",
                "affiliation": "Kyushu University",
                "contact": true
            },
            {
                "email": "xia.shangzhou.218@s.kyushu-u.ac.jp",
                "first": "Shangzhou",
                "last": "Xia",
                "affiliation": "Kyushu University",
                "contact": true
            },
            {
                "email": "fuyuanzhang@163.com",
                "first": "Fuyuan",
                "last": "Zhang",
                "affiliation": "Kyushu University",
                "contact": true
            },
            {
                "email": "arcaini@nii.ac.jp",
                "first": "Paolo",
                "last": "Arcaini",
                "affiliation": "National Institute of Informatics",
                "contact": true
            },
            {
                "email": "ma.lei@acm.org",
                "first": "Lei",
                "last": "Ma",
                "affiliation": "The University of Tokyo & University of Alberta",
                "contact": true
            },
            {
                "email": "zhao@ait.kyushu-u.ac.jp",
                "first": "Jianjun",
                "last": "Zhao",
                "affiliation": "Kyushu University",
                "contact": true
            },
            {
                "email": "f-ishikawa@nii.ac.jp",
                "first": "Fuyuki",
                "last": "Ishikawa",
                "affiliation": "National Institute of Informatics",
                "contact": true
            }
        ],
        "topics": [
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "shang@encs.concordia.ca": true,
            "junsun@smu.edu.sg": true,
            "chunyang.chen@monash.edu": true,
            "tianyi@purdue.edu": true,
            "xin.xia@acm.org": true,
            "shuaiw@cse.ust.hk": true,
            "xfxie@smu.edu.sg": true,
            "ma.lei@acm.org": "collaborator author",
            "xavier.devroey@unamur.be": true,
            "taoyue@gmail.com": true,
            "lilicoding@ieee.org": true,
            "fangchunrong@nju.edu.cn": true,
            "jie.zhang@kcl.ac.uk": true,
            "taoxie@pku.edu.cn": true,
            "zhonghao@sjtu.edu.cn": true,
            "seongmin.lee@mpi-sp.org": true,
            "arcaini@nii.ac.jp": "author",
            "tsu@sei.ecnu.edu.cn": true,
            "mengguozhu@iie.ac.cn": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683369732,
        "modified_at": 1683373601,
        "tags": [
            "accept#0"
        ]
    },
    {
        "object": "paper",
        "pid": 492,
        "title": "Merge-Replay: Efficient IFDS-Based Taint Analysis by Consolidating Equivalent Value Flows",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-b0b111c8c2ea8ceb460738162af3e30e93cc0d3cd4b7a2180036f3f6eb234b34",
            "timestamp": 1683373845,
            "size": 1285472,
            "pages": 11
        },
        "abstract": "IFDS-based taint analysis utilizes two mutually iterative passes, a forward pass for detecting taints and a backward pass for detecting aliases, to ensure both flow and context sensitivity, resulting in high precision. To maintain flow sensitivity, the IFDS-based taint analysis decorates data abstractions with activation statements to identify when they become taints. However, this mechanism can introduce equivalent yet redundant value flows when different activation statements are associated with the same data abstraction, which can make the analysis computationally and memory-intensive unnecessarily.\r\n\r\nWe introduce a novel approach, MergeDroid, to improve the efficiency of IFDS-based taint analysis by consolidating equivalent value flows. The idea is to merge activation statements associated with the same data abstraction from different data facts that are reachable at a given program point during the backward pass. This creates a representative symbolic activation statement that applies to all equivalent data facts, reducing them to a single symbolic data fact. During the forward pass, when the symbolic data fact is propagated back to the same program point (where it was created earlier), the analysis switches to the original data facts with their original activation statements. This merge-and-replay process eliminates redundant value flow propagation and improves performance. We also enhance the precision of the analysis by utilizing context-sensitive information from activation statements. Our evaluation on 40 Android apps reveals that MergeDroid delivers a substantial improvement in IFDS-based taint analysis performance. On average, MergeDroid accelerates the analysis by 9.0× and scales 6 more apps. Moreover, MergeDroid reduces false positives by significantly decreasing the number of reported leak warnings by 19.2%.",
        "authors": [
            {
                "email": "yujiang.gui@unsw.edu.au",
                "first": "Yujiang",
                "last": "Gui",
                "affiliation": "University of New South Wales",
                "contact": true
            },
            {
                "email": "dongjieh@cse.unsw.edu.au",
                "first": "Dongjie",
                "last": "He",
                "affiliation": "University of New South Wales",
                "contact": true
            },
            {
                "email": "jingling@cse.unsw.edu.au",
                "first": "Jingling",
                "last": "Xue",
                "affiliation": "University of New South Wales",
                "contact": true
            }
        ],
        "topics": [
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "j.xue@unsw.edu.au": true,
            "dongjieh@cse.unsw.edu.au": "author",
            "y.sui@unsw.edu.au": true,
            "lianli@ict.ac.cn": true,
            "yli044@e.ntu.edu.sg": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683366459,
        "modified_at": 1683373845,
        "tags": [
            "a#0",
            "accept#0",
            "dpa_candidate#0",
            "dpa_yes#0"
        ]
    },
    {
        "object": "paper",
        "pid": 493,
        "title": "Code Difference Guided Adversarial Example Generation for Deep Code Models",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-46c98bfb844a128c872dbf98119b2ed026085bc180efa1c2593d4f707a02ead8",
            "timestamp": 1683376245,
            "size": 567866,
            "pages": 12
        },
        "abstract": "Adversarial examples are important to test and enhance the robustness of deep code models. As source code is discrete and has to strictly stick to complex grammar and semantics constraints, the adversarial example generation techniques in other domains are hardly applicable. Moreover, the adversarial example generation techniques specific to deep code models still suffer from unsatisfactory effectiveness due to the enormous ingredient search space. In this work, we propose a novel adversarial example generation technique (i.e., CODA) for testing deep code models. Its key idea is to use code differences between the target input (i.e., a given code snippet as the model input) and reference inputs (i.e., the inputs that have small code differences but different prediction results with the target input) to guide the generation of adversarial examples. It considers both structure differences and identifier differences to preserve the original semantics. Hence, the ingredient search space can be largely reduced as the one constituted by the two kinds of code differences, and thus the testing process can be improved by designing and guiding corresponding equivalent structure transformations and identifier renaming transformations. Our experiments on 15 deep code models demonstrate the effectiveness and efficiency of CODA, the naturalness of its generated examples, and its capability of enhancing model robustness after adversarial fine-tuning. For example, CODA reveals 88.05% and 72.51% more faults in models than the state-of-the-art techniques (i.e., CARROT and ALERT) on average, respectively.",
        "authors": [
            {
                "email": "tianzhao@tju.edu.cn",
                "first": "Zhao",
                "last": "Tian",
                "affiliation": "College of Intelligence and Computing, Tianjin University",
                "contact": true
            },
            {
                "email": "junjiechen@tju.edu.cn",
                "first": "Junjie",
                "last": "Chen",
                "affiliation": "College of Intelligence and Computing, Tianjin University",
                "contact": true
            },
            {
                "email": "zhijin@pku.edu.cn",
                "first": "Zhi",
                "last": "Jin",
                "affiliation": "Key Lab of High Confidence Software Technologies, Peking University",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering",
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "junsun@smu.edu.sg": true,
            "junjiechen@tju.edu.cn": "author",
            "zp.chen@ucl.ac.uk": true,
            "lingming@illinois.edu": true,
            "xin.xia@acm.org": true,
            "senchen@tju.edu.cn": true,
            "haodan@pku.edu.cn": true,
            "xfxie@smu.edu.sg": true,
            "ding_li@pku.edu.cn": true,
            "louyiling610@gmail.com": true,
            "fangchunrong@nju.edu.cn": true,
            "hongyujohn@gmail.com": true,
            "mnayebi@yorku.ca": true,
            "davidlo@smu.edu.sg": true,
            "taoxie@pku.edu.cn": true,
            "guowei.yang@uq.edu.au": true,
            "wurongxin@xmu.edu.cn": true,
            "jiangjiajun@tju.edu.cn": true,
            "wangbo_cs@bjtu.edu.cn": true,
            "mwenaa@hust.edu.cn": true,
            "jyy@nju.edu.cn": true,
            "wangdi95@pku.edu.cn": true,
            "minghuama@microsoft.com": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683374367,
        "modified_at": 1683376245,
        "tags": [
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 517,
        "title": "Learning to Locate and Describe Vulnerabilities",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-13ef7ed8b0006ecb6128f26b98774abfef6af7cc70929f020454dd94f3c95f34",
            "timestamp": 1683359107,
            "size": 584223,
            "pages": 12
        },
        "abstract": "Automatically discovering software vulnerability is a long-standing pursuit for software developers and security analysts. Although there have been an enormous number of vulnerability detection tools based on static analysis or deep learning, they either suffer from a high false positive rate or only predicts whether a function is vulnerable without further debugging information.  \r\nTherefore, recent work turns the attention to find fine-grained vulnerabilities, i.e., vulnerable statements. However, existing work for vulnerability localization is limited in capturing long-range and integral dependency information due to the bottleneck of Graph Neural Networks (GNNs). Moreover, little research has been done to help developers reason about detected vulnerabilities, leaving vulnerability diagnosis a challenging task. In this paper, we propose VulTeller, a deep learning-based approach that can automatically locate vulnerable statements in a function and more importantly, can generate its descriptions. Our approach focuses on extracting precise control and data dependencies in the code by modeling the control flow paths and taint analysis. To be specific, we design a novel neural model that encodes the control flows and data flows reside in the control flow paths, and decodes them via node classification and an attentional decoder for the two tasks respectively.\r\nWe conduct extensive experiments with real-world vulnerabilities to evaluate the proposed approach. The evaluation results, including quantitative measurement and human evaluation, demonstrate that our approach is highly effective and outperforms state-of-the-art approaches. Our work for the first time formulates the vulnerability description generation problem, and makes one step further towards automated vulnerability diagnosis.",
        "authors": [
            {
                "email": "jian_zhang@ntu.edu.sg",
                "first": "Jian",
                "last": "Zhang",
                "affiliation": "Nanyang Technological University",
                "contact": true
            },
            {
                "email": "shangqingliu666@gmail.com",
                "first": "Shangqing",
                "last": "Liu",
                "affiliation": "Nanyang Technological University",
                "contact": true
            },
            {
                "email": "xuwang@buaa.edu.cn",
                "first": "Xu",
                "last": "Wang",
                "affiliation": "Beihang University, China",
                "contact": true
            },
            {
                "email": "tianlin001@e.ntu.edu.sg",
                "first": "Tianlin",
                "last": "Li",
                "affiliation": "Nanyang Technological University",
                "contact": true
            },
            {
                "email": "yangliu@ntu.edu.sg",
                "first": "Yang",
                "last": "Liu",
                "affiliation": "Nanyang Technological University",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering"
        ],
        "pc_conflicts": {
            "junsun@smu.edu.sg": true,
            "lxiao6@stevens.edu": true,
            "senchen@tju.edu.cn": true,
            "gaocuiyun@hit.edu.cn": true,
            "ma.lei@acm.org": true,
            "lilicoding@ieee.org": true,
            "hongyujohn@gmail.com": true,
            "linglingfan@nankai.edu.cn": true,
            "jie.zhang@kcl.ac.uk": true,
            "xxie@whu.edu.cn": true,
            "y.sui@unsw.edu.au": true,
            "tsu@sei.ecnu.edu.cn": true,
            "xuwang@buaa.edu.cn": "author",
            "yli044@e.ntu.edu.sg": true,
            "mengguozhu@iie.ac.cn": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683359107,
        "modified_at": 1683359186
    },
    {
        "object": "paper",
        "pid": 530,
        "title": "Robin: A Novel Method to Produce Robust Interpreters for Deep Learning-Based Code Classifiers",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-02de716ae54443b8869682a2bc37b198009f8b8306abeebb19bda5b0d44d5291",
            "timestamp": 1683364010,
            "size": 548841,
            "pages": 12
        },
        "abstract": "Deep learning has been widely used in source code classification tasks, such as code classification according to their functionalities, code authorship attribution, and vulnerability detection. Unfortunately, the black-box nature of deep learning makes it hard to interpret why a classifier (i.e., classification model) makes a particular prediction on a given example. This lack of interpretability (or explainability) might have hindered their adoption by practitioners because it is not clear when they should or should not trust a classifier’s prediction. This lack of interpretability has motivated a number of studies in recent years. However, the known methods are neither robust nor able to cope with out-of-distribution examples. In this paper, we propose a novel method to produce robust interpreters for a given deep learning-based code classifier; the method is dubbed Robin. The key idea behind Robin is a novel hybrid structure combining an interpreter and two approximators, while leveraging the ideas of adversarial training and data augmentation. Experimental results show that on average the interpreter produced by Robin achieves a 6.11% higher fidelity evaluated on the classifier, 67.22% higher fidelity evaluated on the approximator, and 15.87x higher robustness than that of the three existing interpreters we evaluated. Moreover, the interpreter is 47.31% less affected by out-of-distribution examples than that of LEMNA.",
        "authors": [
            {
                "email": "zh_li@hust.edu.cn",
                "first": "Zhen",
                "last": "Li",
                "affiliation": "Huazhong University of Science and Technology",
                "contact": true
            },
            {
                "email": "ruqianzhang@hust.edu.cn",
                "first": "Ruqian",
                "last": "Zhang",
                "affiliation": "Huazhong University of Science and Technology",
                "contact": true
            },
            {
                "email": "deqingzou@hust.edu.cn",
                "first": "Deqing",
                "last": "Zou",
                "affiliation": "Huazhong University of Science and Technology",
                "contact": true
            },
            {
                "email": "wangn@hust.edu.cn",
                "first": "Ning",
                "last": "Wang",
                "affiliation": "Huazhong University of Science and Technology",
                "contact": true
            },
            {
                "email": "liyating20210228@163.com",
                "first": "Yating",
                "last": "Li",
                "affiliation": "Huazhong University of Science and Technology",
                "contact": true
            },
            {
                "email": "sxu@uccs.edu",
                "first": "Shouhuai",
                "last": "Xu",
                "affiliation": "University of Colorado Colorado Springs",
                "contact": true
            },
            {
                "email": "chen.chen@crcv.ucf.edu",
                "first": "Chen",
                "last": "Chen",
                "affiliation": "University of Central Florida",
                "contact": true
            },
            {
                "email": "hjin@hust.edu.cn",
                "first": "Hai",
                "last": "Jin",
                "affiliation": "Huazhong University of Science and Technology",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering",
            "Dependability, Safety, and Reliability"
        ],
        "pc_conflicts": {
            "kjustice@uccs.edu": true,
            "mnayebi@yorku.ca": true,
            "mwenaa@hust.edu.cn": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683243120,
        "modified_at": 1692061917,
        "tags": [
            "accept#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 534,
        "title": "Revealing Performance Issues in Server-side WebAssembly Runtimes via Differential Testing",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-e8dd16c98d44e31c902b7355e2de50b7cc2100c602403b65aad9a7c99458dedb",
            "timestamp": 1683357297,
            "size": 5309173,
            "pages": 12
        },
        "abstract": "WebAssembly (Wasm) is a bytecode format originally serving as a compilation target for Web applications. It has recently been used increasingly on the server side, \\textit{e.g.}, providing a safer, faster, and more portable alternative to Linux containers. With the popularity of server-side Wasm applications, it is essential to study performance issues (\\textit{i.e.}, abnormal latency) in Wasm runtimes, as they may cause a significant impact on server-side applications. However, there is still a lack of attention to performance issues in server-side Wasm runtimes. In this paper, we design a novel differential testing approach \\textit{WarpDiff} to identify performance issues in server-side Wasm runtimes. The key insight is that in normal cases, the execution time of the same test case on different Wasm runtimes should follow an \\textit{oracle ratio}. We identify abnormal cases where the execution time ratio significantly deviates from the \\textit{oracle ratio} and subsequently locate the Wasm runtimes that cause the performance issues. We apply \\textit{WarpDiff} to test five popular server-side Wasm runtimes using 123 test cases from the LLVM test suite, and demonstrate the top 10 abnormal cases we identified. We further conduct an in-depth analysis of these abnormal cases and summarize seven performance issues, all of which have been confirmed by the developers. We hope our work can inspire future investigation on improving Wasm runtime implementation and thus promoting the development of server-side Wasm applications.",
        "authors": [
            {
                "email": "syjiang21@cse.cuhk.edu.hk",
                "first": "Shuyao",
                "last": "Jiang",
                "affiliation": "The Chinese University of Hong Kong",
                "contact": true
            },
            {
                "first": "Ruiying",
                "last": "Zeng",
                "affiliation": "Fudan University"
            },
            {
                "first": "Zihao",
                "last": "Rao",
                "affiliation": "Fudan University"
            },
            {
                "first": "Jiazhen",
                "last": "Gu",
                "affiliation": "The Chinese University of Hong Kong"
            },
            {
                "email": "zyf@fudan.edu.cn",
                "first": "Yangfan",
                "last": "Zhou",
                "affiliation": "Fudan University",
                "contact": true
            },
            {
                "email": "lyu@cse.cuhk.edu.hk",
                "first": "Michael",
                "last": "Lyu",
                "affiliation": "The Chinese University of Hong Kong",
                "contact": true
            }
        ],
        "topics": [
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "junsun@smu.edu.sg": true,
            "tianyi@purdue.edu": true,
            "xin.xia@acm.org": true,
            "zhendong@fudan.edu.cn": true,
            "gaocuiyun@hit.edu.cn": true,
            "louyiling610@gmail.com": true,
            "linglingfan@nankai.edu.cn": true,
            "mnayebi@yorku.ca": true,
            "davidlo@smu.edu.sg": true,
            "taoxie@pku.edu.cn": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683352326,
        "modified_at": 1683357297,
        "tags": [
            "accept#0"
        ]
    },
    {
        "object": "paper",
        "pid": 543,
        "title": "A Needle is an Outlier in a Haystack: Hunting Malicious PyPI Packages with Code Clustering",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-5a470f8337ae049b9cae8988a425d06f99ed7ae6c81ca1d4af5a041f31a1d824",
            "timestamp": 1683374229,
            "size": 580697,
            "pages": 12
        },
        "abstract": "As the most popular Python software repository, PyPI has become an indispensable part of the Python ecosystem. Regrettably, the open nature of PyPI exposes end-users to substantial security risks stemming from malicious packages. Consequently, the timely and effective identification of malware within the vast number of newly-uploaded PyPI packages has emerged as a pressing concern. Existing detection methods are dependent on difficult-to-obtain explicit knowledge, such as taint sources, sinks, and malicious code patterns, rendering them susceptible to overlooking emergent malicious packages.\r\n\r\nIn this paper, we present a lightweight and effective method MPHunter to detect malicious packages without requiring any explicit prior knowledge. MPHunter is founded upon two fundamental and insightful observations: first, that malicious packages are considerably rarer than benign ones, and second, that the functionality of installation scripts for malicious packages diverges significantly from those of benign packages, with the latter frequently forming clusters. Consequently, MPHunter utilizes clustering techniques to group the installation scripts of PyPI packages, identifying outliers and ranking them according to their outlierness and the distance between them and known malicious instances, thus highlighting potential evil packages.\r\n\r\nWith MPHunter, we successfully identified 60 previously unknown malicious packages from a pool of 31,329 newly-uploaded packages over a two-month period. All of them have been confirmed by the PyPI official. Moreover, a manual analysis shows that MPHunter recognizes all potentially malicious installation scripts with a recall of 100% across all analyzed packages. We assert that MPHunter offers a valuable and advantageous supplement to existing detection techniques, augmenting the arsenal of software supply chain security analysis.",
        "authors": [
            {
                "email": "wentao_liang_g@163.com",
                "first": "Wentao",
                "last": "Liang",
                "affiliation": "Institute of Software, Chinese Academy of Sciences",
                "contact": true
            },
            {
                "email": "lingxiang@iscas.ac.cn",
                "first": "Xiang",
                "last": "Ling",
                "affiliation": "Institute of Software, Chinese Academy of Sciences",
                "contact": true
            },
            {
                "email": "jingzheng08@iscas.ac.cn",
                "first": "Jingzheng",
                "last": "Wu",
                "affiliation": "Institute of Software, Chinese Academy of Sciences",
                "contact": true
            },
            {
                "email": "tianyue@iscas.ac.cn",
                "first": "Tianyue",
                "last": "Luo",
                "affiliation": "Institute of Software, Chinese Academy of Sciences",
                "contact": true
            },
            {
                "email": "yanjun@iscas.ac.cn",
                "first": "Yanjun",
                "last": "Wu",
                "affiliation": "Institute of Software, Chinese Academy of Sciences",
                "contact": true
            }
        ],
        "topics": [
            "Dependability, Safety, and Reliability",
            "Software Analytics"
        ],
        "pc_conflicts": {
            "mnayebi@yorku.ca": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683371059,
        "modified_at": 1683374229,
        "tags": [
            "accept#0"
        ]
    },
    {
        "object": "paper",
        "pid": 551,
        "title": "Understanding and Enhancing Issue Prioritization in GitHub",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-02e29606a34af22fb06edf1dd2e278706dfdfa38027ec420b90005f596318bd5",
            "timestamp": 1683360322,
            "size": 1341663,
            "pages": 11
        },
        "abstract": "GitHub has become a prominent platform for open source software development, facilitating collaboration and communication among a diverse group of contributors. Efficient issue tracking is a crucial aspect of managing projects on GitHub, and labels serve as one of the primary mechanisms for issue prioritization. However, in large projects, prioritizing issues remains a challenge, and the efficacy of using labels for prioritization is not well understood. To address this knowledge gap, we conduct a comprehensive empirical study that investigates the role of labels in GitHub issue prioritization, examines the influence of various issue features on prioritization, and assesses the performance of different ranking algorithms based on these impactful features. Our study, conducted on a dataset comprising data from over 1.5 million issues across diverse GitHub projects, provides valuable insights for issue handling in open source platforms and offers guidance for future research in this domain. Specifically, the study reveals the limited effectiveness of labels in issue prioritization, highlights the significance of certain issue features in the prioritization process, and compares the performance of various ranking algorithms for issue prioritization to support issue handlers.",
        "authors": [
            {
                "email": "yingying@nuaa.edu.cn",
                "first": "Yingying",
                "last": "He",
                "affiliation": "Nanjing University of Aeronautics and Astronautics",
                "contact": true
            },
            {
                "email": "ywh@nuaa.edu.cn",
                "first": "Wenhua",
                "last": "Yang",
                "affiliation": "Nanjing University of Aeronautics and Astronautics",
                "contact": true
            },
            {
                "email": "mxp@nju.edu.cn",
                "first": "Minxue",
                "last": "Pan",
                "affiliation": "Nanjing University",
                "contact": true
            },
            {
                "email": "yaxirhuxxain@nuaa.edu.cn",
                "first": "Yasir",
                "last": "Hussain",
                "affiliation": "Nanjing University of Aeronautics and Astronautics",
                "contact": true
            },
            {
                "email": "zhouyu@nuaa.edu.cn",
                "first": "Yu",
                "last": "Zhou",
                "affiliation": "Nanjing University of Aeronautics and Astronautics",
                "contact": true
            }
        ],
        "topics": [
            "Human Aspects of Software Engineering",
            "Maintenance and Evolution"
        ],
        "pc_conflicts": {
            "junjiechen@tju.edu.cn": true,
            "chunyang.chen@monash.edu": true,
            "y.tian@queensu.ca": true,
            "zp.chen@ucl.ac.uk": true,
            "shaowei.wang@umanitoba.ca": true,
            "tianyi@purdue.edu": true,
            "xin.xia@acm.org": true,
            "fengyang@nju.edu.cn": true,
            "changxu@nju.edu.cn": true,
            "senchen@tju.edu.cn": true,
            "haodan@pku.edu.cn": true,
            "xusheng.xiao@asu.edu": true,
            "xfxie@smu.edu.sg": true,
            "liuhui08@bit.edu.cn": true,
            "zhendong@fudan.edu.cn": true,
            "ding_li@pku.edu.cn": true,
            "gaocuiyun@hit.edu.cn": true,
            "ma.lei@acm.org": true,
            "taoyue@gmail.com": true,
            "lilicoding@ieee.org": true,
            "csxluo@comp.polyu.edu.hk": true,
            "louyiling610@gmail.com": true,
            "fangchunrong@nju.edu.cn": true,
            "linglingfan@nankai.edu.cn": true,
            "wangying@swc.neu.edu.cn": true,
            "jie.zhang@kcl.ac.uk": true,
            "taoxie@pku.edu.cn": true,
            "tazhang@must.edu.mo": true,
            "g.bai@uq.edu.au": true,
            "yutian.tang@glasgow.ac.uk": true,
            "juanzhai@umass.edu": true,
            "y.sui@unsw.edu.au": true,
            "jyy@nju.edu.cn": true,
            "zqzuo@nju.edu.cn": true,
            "why@nju.edu.cn": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683360322,
        "modified_at": 1683360322,
        "tags": [
            "invalid_abstract#0"
        ]
    },
    {
        "object": "paper",
        "pid": 568,
        "title": "DCLink: Bridging Data Constraint Changes and Implementations in FinTech Systems",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-1cc7bf5e9b2b648b7ff1f2af6042ed616fd4495c7b736bf28d9edfc81003c939",
            "timestamp": 1683367213,
            "size": 836591,
            "pages": 12
        },
        "abstract": "A FinTech system is a cluster of FinTech applications that intensively interact with databases containing a large quantity of user data. To ensure data consistency, it is a common practice to specify data constraints to validate data at runtime. However, data constraints often evolve according to the changes in business requirements. Meanwhile, the developers can hardly keep up with the latest requirements during the development cycle. Such an information barrier increases the communication burden and prevents FinTech applications from being updated in time, impeding the development cycle significantly.\r\n\r\nIn this paper, we present a comprehensive empirical study on data constraints in FinTech systems, investigating how they evolve and affect the development process. Our results show that developers find it hard to update their code timely because no mapping from data constraint changes to code is provided. Inspired by the findings from code updates respecting data constraint changes, we propose DCLink, a traceability link analysis for linking each data constraint change to target methods demanding the code update in the FinTech application. We extensively evaluate DCLink upon real-world change cases in a global FinTech company. The results show that DCLink can effectively and efficiently localize the target methods.",
        "authors": [
            {
                "email": "wtangae@cse.ust.hk",
                "first": "Wensheng",
                "last": "Tang",
                "affiliation": "The Hong Kong University of Science and Technology",
                "contact": true
            },
            {
                "email": "cwangch@cse.ust.hk",
                "first": "Chengpeng",
                "last": "Wang",
                "affiliation": "The Hong Kong University of Science and Technology",
                "contact": true
            },
            {
                "email": "pyaoaa@zju.edu.cn",
                "first": "Peisen",
                "last": "Yao",
                "affiliation": "Zhejiang University",
                "contact": true
            },
            {
                "email": "wurongxin@xmu.edu.cn",
                "first": "Rongxin",
                "last": "Wu",
                "affiliation": "School of Informatics, Xiamen University",
                "contact": true
            },
            {
                "email": "fuxianjin.fxj@antgroup.com",
                "first": "Xianjin",
                "last": "Fu",
                "affiliation": "Ant Group",
                "contact": true
            },
            {
                "email": "fangang.fg@antgroup.com",
                "first": "Gang",
                "last": "Fan",
                "affiliation": "Ant Group",
                "contact": true
            },
            {
                "email": "charlesz@cse.ust.hk",
                "first": "Charles",
                "last": "Zhang",
                "affiliation": "The Hong Kong University of Science and Technology",
                "contact": true
            }
        ],
        "topics": [
            "Requirements and Design",
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "dolby@us.ibm.com": true,
            "junsun@smu.edu.sg": true,
            "junjiechen@tju.edu.cn": true,
            "xin.xia@acm.org": true,
            "changxu@nju.edu.cn": true,
            "shuaiw@cse.ust.hk": true,
            "haodan@pku.edu.cn": true,
            "wangying@swc.neu.edu.cn": true,
            "taoxie@pku.edu.cn": true,
            "wurongxin@xmu.edu.cn": "author",
            "xinghu@zju.edu.cn": true,
            "mwenaa@hust.edu.cn": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683366185,
        "modified_at": 1683816009,
        "tags": [
            "accept#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 571,
        "title": "On the Evaluation of Neural Code Translation: Taxonomy and Benchmark",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-d701a02f2408272586a7c438f229cd9112d2fdf5c0515ae3bb05c8bfa31e0d40",
            "timestamp": 1683373725,
            "size": 767105,
            "pages": 12
        },
        "abstract": "In recent years, neural code translation has gained increasing attention. While most of the research focuses on improving model architectures and training processes, we notice that the evaluation process and benchmark for code translation models are severely limited: they primarily treat source code as natural languages and provide a holistic accuracy score while disregarding the full spectrum of model capabilities across different translation types and complexity. In this paper, we present a comprehensive investigation of four state-of-the-art models and analyze in-depth the advantages and limitations of three existing benchmarks. Based on the experience we summarized, we develop a taxonomy that categorizes code translation tasks into four primary types according to their complexity and knowledge dependence: token level (type 1), syntactic level (type 2), library level (type 3), and algorithm level (type 4). We then conduct a thorough analysis of how existing approaches perform across these four categories. Our findings indicate that while state-of-the-art code translation models excel in type 1 and type 2 translations, they struggle with knowledge-dependent ones such as type 3 and type 4. Existing benchmarks are biased towards trivial translations, such as keyword mapping. To overcome these limitations, we construct G-TransEval, an enhanced benchmark by manually curating type 3 and type 4 translation pairs and unit test cases. Results on our new benchmark suggest that G-TransEval can exhibit more comprehensive and finer-grained capability of  code translation models, leading to more insightful findings and suggestions for future research.",
        "authors": [
            {
                "email": "jiaomingsheng@sjtu.edu.cn",
                "first": "Mingsheng",
                "last": "Jiao",
                "affiliation": "Shanghai Jiao Tong University",
                "contact": true
            },
            {
                "email": "hzfsls@sjtu.edu.cn",
                "first": "Tingrui",
                "last": "Yu",
                "affiliation": "Shanghai Jiao Tong University",
                "contact": true
            },
            {
                "email": "riken01@sjtu.edu.cn",
                "first": "Xuan",
                "last": "Li",
                "affiliation": "Shanghai Jiao Tong University",
                "contact": true
            },
            {
                "email": "qiuguanjie@sjtu.edu.cn",
                "first": "Guanjie",
                "last": "Qiu",
                "affiliation": "Shanghai Jiao Tong University",
                "contact": true
            },
            {
                "email": "xiaodong.gu@sjtu.edu.cn",
                "first": "Xiaodong",
                "last": "Gu",
                "affiliation": "School of Software, Shanghai Jiao Tong University",
                "contact": true
            },
            {
                "email": "bjshen@sjtu.edu.cn",
                "first": "Beijun",
                "last": "Shen",
                "affiliation": "School of Software, Shanghai Jiao Tong University",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering"
        ],
        "pc_conflicts": {
            "hongyujohn@gmail.com": true,
            "zhonghao@sjtu.edu.cn": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683373896,
        "modified_at": 1683374408,
        "tags": [
            "accept#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 583,
        "title": "DeepScaler: Holistic Autoscaling for Microservices Based on Spatiotemporal GNN with Adaptive Graph Learning",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-f8f7e2379f13d3802f7816e019c7c97e8b8ee6ff2160435f57cc2eacc17dbd72",
            "timestamp": 1683374455,
            "size": 1307502,
            "pages": 12
        },
        "abstract": "Autoscaling functions provide the foundation for achieving elasticity in the modern cloud computing paradigm. It enables dynamic provisioning or de-provisioning resources for cloud software services and applications without human intervention to adapt to workload fluctuations. However, autoscaling microservice is challenging due to various factors. \r\nIn particular, complex, time-varying service dependencies are difficult to quantify accurately and can lead to cascading effects when allocating resources. This paper presents DeepScaler, a deep learning-based holistic autoscaling approach for microservices that focus on coping with service dependencies to optimize service-level agreements (SLA) assurance and cost efficiency. DeepScaler employs (i) an expectation-maximization-based learning method to adaptively generate affinity matrices revealing service dependencies and (ii) an attention-based graph convolutional network to extract spatio-temporal features of microservices by aggregating neighbors' information of graph-structural data. Thus DeepScaler can capture more potential service dependencies and accurately estimate the resource requirements of all services under dynamic workloads. It allows DeepScaler to reconfigure the resources of the interacting services simultaneously in one resource provisioning operation, avoiding the cascading effect caused by service dependencies. Experimental results demonstrate that our method implements a more effective autoscaling mechanism for microservice that not only allocates resources accurately but also adapts to dependencies changes, significantly reducing SLA violations by an average of 41% at lower costs.",
        "authors": [
            {
                "email": "mengchy3@mail2.sysu.edu.cn",
                "first": "Chunyang",
                "last": "Meng",
                "affiliation": "Sun Yat-sen University",
                "contact": true
            },
            {
                "email": "songshj6@mail2.sysu.edu.cn",
                "first": "Shijie",
                "last": "Song",
                "affiliation": "Sun Yat-sen University",
                "contact": true
            },
            {
                "email": "tonghg@mail2.sysu.edu.cn",
                "first": "Haogang",
                "last": "Tong",
                "affiliation": "Sun Yat-sen University",
                "contact": true
            },
            {
                "email": "panml@mail.sysu.edu.cn",
                "first": "Maolin",
                "last": "Pan",
                "affiliation": "Sun Yat-sen University",
                "contact": true
            },
            {
                "email": "yuy@mail.sysu.edu.cn",
                "first": "Yang",
                "last": "Yu",
                "affiliation": "Sun Yat-sen University",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering",
            "Dependability, Safety, and Reliability"
        ],
        "pc_conflicts": {
            "mnayebi@yorku.ca": true,
            "xyzhang@cs.purdue.edu": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683374455,
        "modified_at": 1683374455,
        "tags": [
            "dpa_candidate#0",
            "dpa_yes#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 606,
        "title": "A Large-Scale Empirical Study on Semantic Versioning in Golang Ecosystem",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-4953bb656caf3485792dda26297a9df63bc36d4950c5b9784a8dd7760079fcd3",
            "timestamp": 1683373138,
            "size": 295662,
            "pages": 11
        },
        "abstract": "Third-party libraries (TPLs) have become an essential component of software, accelerating development and reducing maintenance costs. However, breaking changes often occur during the upgrades of TPLs and prevent client programs from moving forward. Semantic versioning (SemVer) has been applied to standardize the versions of releases according to compatibility, but not all releases follow SemVer compliance. Lots of work focuses on SemVer compliance in ecosystems such as Java and JavaScript beyond Golang (Go for short). Due to the lack of tools to detect breaking changes and dataset for Go, developers of TPLs do not know if breaking changes occur and affect client programs, and developers of client programs may hesitate to upgrade dependencies in terms of breaking changes.\r\n\r\nTo bridge this gap, we conduct the first large-scale empirical study in the Go ecosystem to study SemVer compliance in terms of breaking changes and their impact. In detail, we purpose \\textit{GoSVI (\\textbf{G}o \\textbf{S}emantic \\textbf{V}ersioning \\textbf{I}nsight)} to detect breaking changes and analyze their impact by resolving identifiers in client programs and comparing their types with breaking changes. Moreover, we collect the first large-scale Go dataset with a dependency graph from GitHub, including 124K TPLs and 532K client programs. Based on the dataset, our results show that 86.3\\% of library upgrades follow SemVer compliance and 28.6\\% of no-major upgrades introduce breaking changes. Furthermore, the tendency to comply with SemVer has improved over time from 63.7\\% in \\textit{2018\/09} to 92.2\\% in \\textit{2023\/03}. Finally, we find 33.3\\% of downstream client programs may be affected by breaking changes. These findings provide developers and users of TPLs with valuable insights to help make decisions related to SemVer.",
        "authors": [
            {
                "email": "winkli1@hust.edu.cn",
                "first": "Wenke",
                "last": "Li",
                "affiliation": "Huazhong University of Science and Technology",
                "contact": true
            },
            {
                "email": "barryfwu@tencent.com",
                "first": "Feng",
                "last": "Wu",
                "affiliation": "Tencent Technology (Shenzhen) Co. Ltd",
                "contact": true
            },
            {
                "email": "fucai@hust.edu.cn",
                "first": "Cai",
                "last": "Fu",
                "affiliation": "Huazhong University of Science and Technology",
                "contact": true
            },
            {
                "email": "fanzhou@tencent.com",
                "first": "Fan",
                "last": "Zhou",
                "affiliation": "Tencent Technology (Shenzhen) Co. Ltd",
                "contact": true
            }
        ],
        "supplementary_material": {
            "mimetype": "application\/zip",
            "hash": "sha2-a68d821e07d154c7f6aabcba35265cff430b1062bedad163c50cd1dd596ded43",
            "timestamp": 1683373083,
            "size": 178987503,
            "filename": "GoSVI.zip"
        },
        "topics": [
            "Dependability, Safety, and Reliability",
            "Maintenance and Evolution"
        ],
        "pc_conflicts": {
            "junsun@smu.edu.sg": true,
            "mnayebi@yorku.ca": true,
            "mwenaa@hust.edu.cn": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683373138,
        "modified_at": 1683373138
    },
    {
        "object": "paper",
        "pid": 608,
        "title": "AutoConf : Automated Configuration of Unsupervised Learning Systems using Metamorphic Testing and Bayesian Optimization",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-a9393e49dc1487a4bd2033b792feff10a3d4457457f4a3643df0866439d2011a",
            "timestamp": 1683374189,
            "size": 2220359,
            "pages": 12
        },
        "abstract": "Unsupervised learning systems using clustering have gained significant attention for numerous applications due to their unique ability to discover patterns and structures in large unlabeled datasets. However, their effectiveness highly depends on their configuration, which requires domain-specific expertise and often involves numerous manual trials. Specifically, selecting appropriate algorithms and hyperparameters adds to the complexity of the configuration process. In this paper, we propose, apply, and assess an automated approach (AutoConf) for configuring unsupervised learning systems using clustering, leveraging metamorphic testing and Bayesian optimization. Metamorphic testing is utilized to verify the configurations of unsupervised learning systems by applying a series of input transformations. We use Bayesian optimization guided by metamorphic-testing output to automatically identify the optimal configuration. The approach aims to streamline the configuration process and enhance the effectiveness of unsupervised learning systems. It has been evaluated through experiments on six datasets from three domains for anomaly detection. The evaluation results show that our approach can find configurations outperforming the baseline approaches as they achieved a recall of 0.89 and a precision of 0.84 (on average).",
        "authors": [
            {
                "email": "lkshar@smu.edu.sg",
                "first": "Lwin Khin",
                "last": "Shar",
                "affiliation": "Singapore Management University",
                "contact": true
            },
            {
                "email": "arda.goknil@sintef.no",
                "first": "Arda",
                "last": "Göknil",
                "affiliation": "SINTEF Digital",
                "contact": true
            },
            {
                "email": "erik.johannes.husom@sintef.no",
                "first": "Erik Johannes",
                "last": "Husom",
                "affiliation": "SINTEF Digital",
                "contact": true
            },
            {
                "email": "sagar.sen@sintef.no",
                "first": "Sagar",
                "last": "Sen",
                "affiliation": "SINTEF Digital",
                "contact": true
            },
            {
                "email": "yannaingtun@smu.edu.sg",
                "first": "Yan Naing",
                "last": "Tun",
                "affiliation": "Singapore Management University",
                "contact": true
            },
            {
                "email": "kisubkim@smu.edu.sg",
                "first": "Kisub",
                "last": "Kim",
                "affiliation": "Singapore Management University",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering",
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "junsun@smu.edu.sg": true,
            "y.tian@queensu.ca": true,
            "shaowei.wang@umanitoba.ca": true,
            "M.Sabetzadeh@uottawa.ca": true,
            "xfxie@smu.edu.sg": true,
            "taoyue@gmail.com": true,
            "domenico.bianculli@uni.lu": true,
            "mnayebi@yorku.ca": true,
            "davidlo@smu.edu.sg": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683334707,
        "modified_at": 1683374956,
        "tags": [
            "accept#0"
        ]
    },
    {
        "object": "paper",
        "pid": 617,
        "title": "To Share, or Not to Share: Exploring Test-Case Reusability in Fork Ecosystems",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-5056e4799f7a64138bdaccf985c67437defabcafca6dbb3b03f0516f07ab258b",
            "timestamp": 1683278341,
            "size": 432405,
            "pages": 12
        },
        "abstract": "Code is often reused to facilitate collaborative development, to create software variants, to experiment with new ideas, or to develop new features in isolation. Social-coding platforms such as GitHub enable enhanced code reuse with forking, pull requests, and cross-project traceability. With these concepts, forking has become a common strategy to reuse code by creating clones (i.e., forks) of projects. Thereby, forking establishes fork ecosystems of co-existing projects that are similar, but developed in parallel, often with rather sporadic code propagation and synchronization. Consequently, forked projects vary in quality and often involve redundant development efforts. Unfortunately, as we show, many projects do not benefit from test cases created in other forks, while those test cases could actually be propagated to substantially enhance the quality of other projects.\r\nWe believe that reusing test cases---in addition to implementation code--can improve the quality, coding efficiency, and software maintainability in fork ecosystems. While researchers have worked on test-reuse techniques, their potential to improve the quality of real-world open-source software is largely unknown.\r\nIn this paper, we study to what extent test cases can be reused across forked projects. We mined a dataset of test cases from 305 fork ecosystems on GitHub ---totaling 1,089 projects---and assessed the potential for reusing test cases among the forked projects. \r\nBy performing a manual inspection of test cases' applicability, transplanting test cases, and analyzing causes for potential non-applicability, we contribute an understanding of the benefits (e.g., uncovering bugs) and challenges (e.g., automated code transplantation, deciding about applicability) of reusing test cases in fork ecosystems.",
        "authors": [
            {
                "email": "mukelabai.mukelabai@unza.zm",
                "first": "Mukelabai",
                "last": "Mukelabai",
                "affiliation": "The University of Zambia, Zambia",
                "contact": true
            },
            {
                "email": "christoph.derks@rub.de",
                "first": "Christoph",
                "last": "Derks",
                "affiliation": "Ruhr-University Bochum, Germany",
                "contact": true
            },
            {
                "email": "j.kruger@tue.nl",
                "first": "Jacob",
                "last": "Krüger",
                "affiliation": "Eindhoven University of Technology, Netherlands",
                "contact": true
            },
            {
                "email": "thorsten.berger@rub.de",
                "first": "Thorsten",
                "last": "Berger",
                "affiliation": "Ruhr-University Bochum, Germany, and Chalmers | University of Gothenburg, Sweden",
                "contact": true
            }
        ],
        "topics": [
            "Maintenance and Evolution",
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "thorsten.berger@rub.de": "collaborator author",
            "contact@stefanstanciulescu.com": true,
            "dirk.beyer@sosy-lab.org": true,
            "paul.gruenbacher@jku.at": true,
            "danstru@chalmers.se": true,
            "mnayebi@yorku.ca": true,
            "HandanGul.Calikli@glasgow.ac.uk": true,
            "koziolek@kit.edu": true,
            "kevin.borgolte@rub.de": true,
            "ayala@lcc.uma.es": true,
            "philipp.leitner@chalmers.se": true,
            "michael.vierhauser@uibk.ac.at": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683278341,
        "final_submitted": true,
        "final_submitted_at": 1690409090,
        "modified_at": 1690409090,
        "tags": [
            "accept#0"
        ]
    },
    {
        "object": "paper",
        "pid": 626,
        "title": "Using Deep Learning to Automatically Improve Code Readability",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-add4380ed5796cfb7f14b7c9d04016f2811a8fd6b52c3a8701f0ce39ce5fc248",
            "timestamp": 1683368302,
            "size": 323781,
            "pages": 12
        },
        "abstract": "Reading source code occupies most of developer’s daily activities. Any maintenance and evolution task requires developers to read and understand the code they are going to modify. For this reason, previous research focused on the definition of techniques to automatically assess the readability of a\r\ngiven snippet. However, when many unreadable code sections are detected, developers might be required to manually modify them all to improve their readability. While existing approaches aim\r\nat solving specific readability-related issues, such as improving variable names or fixing styling issues, there is still no approach to automatically suggest which actions should be taken to improve\r\ncode readability.\r\n\r\nIn this paper, we define the first holistic readability-improving approach. As a first contribution, we introduce a methodology for automatically identifying readability-improving commits, and we use it to built a large dataset of 122k commits by mining the whole revision history of all the projects hosted on GitHub between 2015 and 2022. We show that such a methodology has a ∼86% accuracy. As a second contribution, we train and test the T5 model to emulate what developers did to improve readability. We show that our model achieves a perfect prediction accuracy between 21% and 28%. The results of a manual evaluation we performed on 500 predictions shows that when the model does not change the behavior of the input and and it applies changes (34% of the cases), in the large majority of the cases (79.4%) it allows to improve code readability.",
        "authors": [
            {
                "email": "a.vitale8@studenti.unimol.it",
                "first": "Antonio",
                "last": "Vitale",
                "affiliation": "University of Molise, Italy",
                "contact": true
            },
            {
                "email": "valentina.piantadosi@unimol.it",
                "first": "Valentina",
                "last": "Piantadosi",
                "affiliation": "University of Molise, Italy",
                "contact": true
            },
            {
                "email": "simone.scalabrino@unimol.it",
                "first": "Simone",
                "last": "Scalabrino",
                "affiliation": "University of Molise, Italy",
                "contact": true
            },
            {
                "email": "rocco.oliveto@unimol.it",
                "first": "Rocco",
                "last": "Oliveto",
                "affiliation": "University of Molise, Italy",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering",
            "Maintenance and Evolution"
        ],
        "pc_conflicts": {
            "dposhyvanyk@gmail.com": true,
            "mnayebi@yorku.ca": true,
            "vendomcg@miamioh.edu": true,
            "fer.madeiral@gmail.com": true,
            "nathanacoop@gmail.com": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683359163,
        "modified_at": 1683368497,
        "tags": [
            "accept#0"
        ]
    },
    {
        "object": "paper",
        "pid": 627,
        "title": "From Commit Message Generation to History-Aware Commit Message Completion",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-d4f54868ec8ecc7e072ac1222de37b2e323a85a976727dbac14806ad669aacd3",
            "timestamp": 1683331372,
            "size": 355514,
            "pages": 12
        },
        "abstract": "Commit messages are crucial to software development, allowing developers to track changes and collaborate effectively. Despite their utility, most commit messages lack important information since writing high-quality commit messages is tedious and time-consuming. The active research on commit message generation (CMG) has not yet led to wide adoption in practice. We argue that if we could shift the focus from commit message generation to \\textit{commit message completion} and use previous \\textit{commit history} as additional context, we could significantly improve the quality and the personal nature of the resulting commit messages.\r\n\r\nIn this paper, we propose and evaluate both of these novel ideas. Since the existing datasets lack  historical data, we create and present to the community a novel dataset of 10.7M commits across 20 programming languages. We use this dataset to evaluate the completion setting and the usefulness of the historical context for state-of-the-art CMG models and GPT-3.5-turbo. Our results show that in some contexts, commit message completion shows better results than generation, and that even though in general GPT-3.5-turbo performs worse, it shows potential for long and detailed messages. As for the history, the results show that historical information improves the performance of CMG models in the generation task, and the performance of GPT-3.5-turbo in both generation and completion.",
        "authors": [
            {
                "email": "alexandra.eliseeva@jetbrains.com",
                "first": "Aleksandra",
                "last": "Eliseeva",
                "affiliation": "JetBrains Research",
                "contact": true
            },
            {
                "email": "yaroslav.sokolov@jetbrains.com",
                "first": "Yaroslav",
                "last": "Sokolov",
                "affiliation": "JetBrains"
            },
            {
                "email": "egor.bogomolov@jetbrains.com",
                "first": "Egor",
                "last": "Bogomolov",
                "affiliation": "JetBrains Research",
                "contact": true
            },
            {
                "email": "yaroslav.golubev@jetbrains.com",
                "first": "Yaroslav",
                "last": "Golubev",
                "affiliation": "JetBrains Research",
                "contact": true
            },
            {
                "email": "danny.dig@jetbrains.com",
                "first": "Danny",
                "last": "Dig",
                "affiliation": "JetBrains Research",
                "contact": true
            },
            {
                "email": "timofey.bryksin@jetbrains.com",
                "first": "Timofey",
                "last": "Bryksin",
                "affiliation": "JetBrains Research",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering",
            "Maintenance and Evolution"
        ],
        "pc_conflicts": {
            "arie.vandeursen@tudelft.nl": true,
            "ch@iittp.ac.in": true,
            "vladimir.kovalenko@jetbrains.com": true,
            "timofey.bryksin@jetbrains.com": "collaborator author",
            "foutse.khomh@polymtl.ca": true,
            "bacchelli@ifi.uzh.ch": true,
            "mnayebi@yorku.ca": true,
            "davidlo@smu.edu.sg": true,
            "fatemeh.fard@ubc.ca": true,
            "iftekha@uci.edu": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683331372,
        "modified_at": 1683331372,
        "tags": [
            "accept#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 637,
        "title": "ZC3 Zero-Shot Cross-Language Code Clone Detection",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-2de4b17e1311f8ae4d1b9bb40f1b161860a4b57de1a2311ea79dcaa790f702bf",
            "timestamp": 1683375301,
            "size": 490709,
            "pages": 12
        },
        "abstract": "There is growing interest in code clone detection since it can help developers reuse existing code to improve programming productivity in the development of software engineering. Many existing researches have achieved consistent improvements in code clone detection. Despite the great performance, they are mainly applied to detect clones in the same programming language. However, there is an increasing demand to develop semantically aligned but linguistically distinct programs to support various platforms and help developers translate codes from one language to another. The cross-language code clone detection becomes a necessary scenario. Considering that collecting cross-language clone pairs, especially for low-resource languages, is expensive and time-consuming, how designing an effective cross-language model that does not rely on any parallel data is a critical and significant problem. \r\nIn this paper, we propose a novel method named ZC3 for Zero-shot Cross-language Code Clone detection. ZC3 designs the contrastive snippet prediction to form an isomorphic structure among different programming languages. Based on this, ZC3 exploits domain-aware learning and cycle consistency learning to further constrain the model to generate aligned and diacritical representations. To evaluate the effectiveness of our proposed approach, we conduct extensive experiments on four benchmarks. Experimental results show that ZC3 outperforms the state-of-the-art baselines by 64.93, 51.39, 14.85, and 48.34 on the MAP score, respectively. We further investigate the representational distribution of different languages and discuss the effectiveness of our method.",
        "authors": [
            {
                "email": "lijiaa@pku.edu.cn",
                "first": "Jia",
                "last": "Li",
                "affiliation": "Peking University",
                "contact": true
            },
            {
                "email": "chongyangtao@gmail.com",
                "first": "Chongyang",
                "last": "Tao",
                "affiliation": "Peking University",
                "contact": true
            },
            {
                "email": "zhijin@pku.edu.cn",
                "first": "Zhi",
                "last": "Jin",
                "affiliation": "Peking University",
                "contact": true
            },
            {
                "email": "fangliu@buaa.edu.cn",
                "first": "Fang",
                "last": "Liu",
                "affiliation": "Beihang University",
                "contact": true
            },
            {
                "email": "lijia@stu.pku.edu.cn",
                "first": "Jia Allen",
                "last": "Li",
                "affiliation": "Peking University",
                "contact": true
            },
            {
                "email": "lige@pku.edu.cn",
                "first": "Ge",
                "last": "Li",
                "affiliation": "Peking University",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering"
        ],
        "pc_conflicts": {
            "zp.chen@ucl.ac.uk": true,
            "xin.xia@acm.org": true,
            "haodan@pku.edu.cn": true,
            "ding_li@pku.edu.cn": true,
            "ma.lei@acm.org": true,
            "louyiling610@gmail.com": true,
            "davidlo@smu.edu.sg": true,
            "taoxie@pku.edu.cn": true,
            "wurongxin@xmu.edu.cn": true,
            "wangbo_cs@bjtu.edu.cn": true,
            "xuwang@buaa.edu.cn": true,
            "wangdi95@pku.edu.cn": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683357435,
        "modified_at": 1692476009,
        "tags": [
            "accept#0"
        ]
    },
    {
        "object": "paper",
        "pid": 645,
        "title": "ESRO: Experience Assisted Service Reliability against Outages",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-71f5efa1ef839b45e0d6e684785a9ea5c1a2b98b2e70a17f9c1b6076da065601",
            "timestamp": 1683370274,
            "size": 6357958,
            "pages": 12
        },
        "abstract": "Modern cloud services are prone to failures due to their complex architecture, making diagnosis a critical process. Site Reliability Engineers (SREs) spend hours leveraging multiple sources of data, including the alerts, error logs, and domain expertise through past experiences to find the root cause(s). These experiences are documented as natural language text in outage reports for previous outages. However, utilizing the raw yet rich unstructured information in the reports systematically is time-consuming. Structured information, on the other hand, such as alerts that are often used during fault diagnosis, is voluminous and requires expert knowledge to discern. Several strategies have been proposed to use each source of data separately for root cause analysis. In this work, we build a diagnosis service called \\textit{ESRO} that recommends root causes and remediation for failures by utilizing structured as well as unstructured sources of data systematically. \\textit{ESRO} constructs a causal graph using alerts and a knowledge graph using outage reports, and merges them in a novel way to form a unified graph during training. A retrieval-based mechanism is then used to search the unified graph and rank the likely root causes and remediation techniques based on the alerts fired during an outage at inference time. Not only the individual alerts, but their respective importance in predicting an outage group, is taken into account during recommendation. We evaluated our model on several cloud service outages of a large SaaS enterprise over the course of ~2 years, and obtained an average improvement of 27\\% in rouge scores after comparing the likely root causes against the ground truth over state-of-the-art baselines. We further establish the effectiveness of \\textit{ESRO} through multiple qualitative analysis on real outage case studies.",
        "authors": [
            {
                "email": "sarchakr@adobe.com",
                "first": "Sarthak",
                "last": "Chakraborty",
                "affiliation": "Adobe Research",
                "contact": true
            },
            {
                "email": "shagarw@adobe.com",
                "first": "Shubham",
                "last": "Agarwal",
                "affiliation": "Adobe Research",
                "contact": true
            },
            {
                "email": "shadgarg@adobe.com",
                "first": "Shaddy",
                "last": "Garg",
                "affiliation": "Adobe",
                "contact": true
            },
            {
                "email": "abhimanyusethia12@gmail.com",
                "first": "Abhimanyu",
                "last": "Sethia",
                "affiliation": "Indian Institute of Technology Kanpur"
            },
            {
                "email": "udit.pusp@gmail.com",
                "first": "Udit Narayan",
                "last": "Pandey",
                "affiliation": "Indian Institute of Technology Kanpur",
                "contact": true
            },
            {
                "email": "videh1aggarwal@gmail.com",
                "first": "Videh",
                "last": "Aggarwal",
                "affiliation": "Indian Institute of Technology Kanpur",
                "contact": true
            },
            {
                "email": "shsaini@adobe.com",
                "first": "Shiv",
                "last": "Saini",
                "affiliation": "Adobe Research",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering",
            "Dependability, Safety, and Reliability"
        ],
        "pc_conflicts": {
            "mnayebi@yorku.ca": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683365217,
        "modified_at": 1683370274,
        "tags": [
            "accept#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 647,
        "title": "Causality-Aided Trade-off Analysis for Machine Learning Fairness",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-90301cdb61524663a655a1c98b16029899589c065dd39cfe3ae86c01dd1f5dea",
            "timestamp": 1683373511,
            "size": 1347223,
            "pages": 12
        },
        "abstract": "There has been an increasing interest in enhancing the fairness of machine learning (ML). Despite the growing number of fairness-improving methods, we lack a systematic understanding of the trade-offs among factors considered in the ML pipeline when fairness-improving methods are applied. This understanding is essential for developers to make informed decisions regarding the provision of fair ML services. Nonetheless, it is extremely difficult to analyze the trade-offs when there are multiple fairness parameters and other crucial metrics involved, coupled, and even in conflict with one another. \r\n\r\nThis paper uses causality analysis as a principled method for analyzing trade-offs between fairness parameters and other crucial metrics in ML pipelines. To practically and effectively conduct causality analysis, we propose a set of domain-specific optimizations to facilitate accurate causal discovery and a unified, novel interface for trade-off analysis based on well-established causal inference methods. We conduct a comprehensive empirical study using three real-world datasets on a collection of widely used fairness-improving techniques. Our study obtains actionable suggestions for users and developers of fair ML. We further demonstrate the versatile usage of our approach in selecting the optimal fairness-improving method, paving the way for more ethical and socially responsible AI technologies.",
        "authors": [
            {
                "email": "zjiae@cse.ust.hk",
                "first": "Zhenlan",
                "last": "Ji",
                "affiliation": "HKUST",
                "contact": true
            },
            {
                "email": "pmaab@cse.ust.hk",
                "first": "Pingchuan",
                "last": "Ma",
                "affiliation": "HKUST",
                "contact": true
            },
            {
                "email": "shuaiw@cse.ust.hk",
                "first": "Shuai",
                "last": "Wang",
                "affiliation": "HKUST",
                "contact": true
            },
            {
                "email": "yanhuili@nju.edu.cn",
                "first": "Yanhui",
                "last": "Li",
                "affiliation": "State Key Laboratory for Novel Software Technology, Nanjing University",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering",
            "Dependability, Safety, and Reliability",
            "Social Aspects of Software Engineering"
        ],
        "pc_conflicts": {
            "pwng@google.com": true,
            "fengyang@nju.edu.cn": true,
            "shihan@microsoft.com": true,
            "changxu@nju.edu.cn": true,
            "shuaiw@cse.ust.hk": "collaborator author",
            "xfxie@smu.edu.sg": true,
            "ma.lei@acm.org": true,
            "taoyue@gmail.com": true,
            "saikatc@microsoft.com": true,
            "fangchunrong@nju.edu.cn": true,
            "jordan.henkel@microsoft.com": true,
            "juanzhai@umass.edu": true,
            "jyy@nju.edu.cn": true,
            "zqzuo@nju.edu.cn": true,
            "why@nju.edu.cn": true,
            "minghuama@microsoft.com": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683363821,
        "modified_at": 1683526963,
        "tags": [
            "accept#0"
        ]
    },
    {
        "object": "paper",
        "pid": 650,
        "title": "Maat: Performance Metric Anomaly Anticipation for Cloud Services with Conditional Diffusion",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-4ef15cc7af803cf8c07ac352006da222612240110765bfb170b164ab75156e34",
            "timestamp": 1683374379,
            "size": 4291835,
            "pages": 12
        },
        "abstract": "Ensuring the reliability and user satisfaction of cloud services necessitates prompt anomaly detection followed by diagnosis.\r\n    Existing techniques for anomaly detection focus solely on real-time detection, meaning that anomaly alerts are issued as soon as anomalies occur.\r\n    However, anomalies can propagate and evolve into failures, making faster-than-real-time anomaly detection highly desirable for expediting downstream analysis and intervention.\r\n    This paper proposes Maat, the first work to address anomaly anticipation of performance metrics in cloud services.\r\n    Maat adopts a novel two-stage paradigm for anomaly anticipation, consisting of metric forecasting and anomaly detection on forecasts.\r\n    The metric forecasting stage employs a conditional denoising diffusion model to enable multi-step forecasting in an auto-regressive manner. \r\n    The detection stage establishes anomaly-indicating features and applies isolation forest with incremental learning to detect upcoming anomalies.\r\n    Driven by domain knowledge and data, our method can uncover anomalies that better conform to human expertise.\r\n    Evaluations on three publicly available datasets demonstrate that Maat can anticipate anomalies faster than real-time comparatively or more effectively compared with state-of-the-art real-time anomaly detectors.\r\n    We also present cases highlighting Maat's success in forecasting abnormal metrics and discovering anomalies.",
        "authors": [
            {
                "email": "cheryllee@link.cuhk.edu.hk",
                "first": "Cheryl",
                "last": "Lee",
                "affiliation": "The Chinese University of Hong Kong",
                "contact": true
            },
            {
                "email": "tyyang@cse.cuhk.edu.hk",
                "first": "Tianyi",
                "last": "Yang",
                "affiliation": "The Chinese University of Hong Kong",
                "contact": true
            },
            {
                "email": "chenzhb36@mail.sysu.edu.cn",
                "first": "Zhuangbin",
                "last": "Chen",
                "affiliation": "Sun Yat-sen University",
                "contact": true
            },
            {
                "email": "suyx35@mail.sysu.edu.cn",
                "first": "Yuxin",
                "last": "Su",
                "affiliation": "Sun Yat-sen University",
                "contact": true
            },
            {
                "email": "lyu@cse.cuhk.edu.hk",
                "first": "Michael",
                "last": "Lyu",
                "affiliation": "The Chinese University of Hong Kong",
                "contact": true
            }
        ],
        "supplementary_material": {
            "mimetype": "application\/pdf",
            "hash": "sha2-8d1b75ac4d45ce9858a05e26fb8b73c4c5f649bfffb7b4616a74c1d9b5b705a1",
            "timestamp": 1683369932,
            "size": 4291761,
            "filename": "_ASE__Maat__IEEE_ (1).pdf",
            "pages": 12
        },
        "topics": [
            "AI and Software Engineering"
        ],
        "pc_conflicts": {
            "j.xue@unsw.edu.au": true,
            "michael@binaervarianz.de": true,
            "junsun@smu.edu.sg": true,
            "junjiechen@tju.edu.cn": true,
            "chunyang.chen@monash.edu": true,
            "y.tian@queensu.ca": true,
            "zp.chen@ucl.ac.uk": true,
            "lingming@illinois.edu": true,
            "tianyi@purdue.edu": true,
            "xin.xia@acm.org": true,
            "fengyang@nju.edu.cn": true,
            "changxu@nju.edu.cn": true,
            "senchen@tju.edu.cn": true,
            "shuaiw@cse.ust.hk": true,
            "haodan@pku.edu.cn": true,
            "xusheng.xiao@asu.edu": true,
            "xfxie@smu.edu.sg": true,
            "liuhui08@bit.edu.cn": true,
            "zhendong@fudan.edu.cn": true,
            "ding_li@pku.edu.cn": true,
            "gaocuiyun@hit.edu.cn": true,
            "ma.lei@acm.org": true,
            "taoyue@gmail.com": true,
            "lilicoding@ieee.org": true,
            "csxluo@comp.polyu.edu.hk": true,
            "wenwen@cs.uga.edu": true,
            "louyiling610@gmail.com": true,
            "fangchunrong@nju.edu.cn": true,
            "hongyujohn@gmail.com": true,
            "linglingfan@nankai.edu.cn": true,
            "wangying@swc.neu.edu.cn": true,
            "jie.zhang@kcl.ac.uk": true,
            "davidlo@smu.edu.sg": true,
            "taoxie@pku.edu.cn": true,
            "tazhang@must.edu.mo": true,
            "yutian.tang@glasgow.ac.uk": true,
            "xyzhang@cs.purdue.edu": true,
            "y.sui@unsw.edu.au": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1692027419,
        "modified_at": 1692027419,
        "tags": [
            "invalid_abstract#0"
        ]
    },
    {
        "object": "paper",
        "pid": 651,
        "title": "HexT5: Unified Pre-training for Stripped Binary Code Information Inference",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-4504eb157f18816391749c5c9ed7aacb9e737e2c83b8f2aedede97e54c3607cd",
            "timestamp": 1683821962,
            "size": 1153292,
            "pages": 12
        },
        "abstract": "Decompilation is a widely used process by reverse engineers to significantly enhance code readability by lifting assembly code to a higher-level C-like language, pseudo-code. Nevertheless, the process of compilation and stripping irreversibly discards \\emph{high-level semantic information} that is crucial to code comprehension, such as comments, identifier names, and types. Existing approaches typically recover only one type of information, making them suboptimal for semantic inference. In this paper, we present a unified pre-trained model, HexT5, that is trained on vast amounts of natural language comments, source identifiers, and pseudo-code using novel pseudo-code-based pre-training objectives. We fine-tune HexT5 on various downstream tasks, including code summarization, variable name recovery, function name recovery, and similarity detection. Comprehensive experiments show that HexT5 achieves state-of-the-art performance on four downstream tasks, and it demonstrates the robust effectiveness and generalizability of HexT5 for binary-related tasks.",
        "authors": [
            {
                "email": "jqxiong@mail.ustc.edu.cn",
                "first": "Jiaqi",
                "last": "Xiong",
                "affiliation": "University of Science and Technology of China",
                "contact": true
            },
            {
                "email": "ch3nye@mail.ustc.edu.cn",
                "first": "Guoqiang",
                "last": "Chen",
                "affiliation": "University of Science and Technology of China",
                "contact": true
            },
            {
                "email": "chenkj@ustc.edu.cn",
                "first": "Kejiang",
                "last": "Chen",
                "affiliation": "University of Science and Technology of China",
                "contact": true
            },
            {
                "email": "gh2018@mail.ustc.edu.cn",
                "first": "Han",
                "last": "Gao",
                "affiliation": "University of Science and Technology of China",
                "contact": true
            },
            {
                "email": "sycheng@ustc.edu.cn",
                "first": "Shaoyin",
                "last": "Cheng",
                "affiliation": "University of Science and Technology of China",
                "contact": true
            },
            {
                "email": "zhangwm@ustc.edu.cn",
                "first": "Weiming",
                "last": "Zhang",
                "affiliation": "University of Science and Technology of China",
                "contact": true
            }
        ],
        "supplementary_material": {
            "mimetype": "application\/zip",
            "hash": "sha2-6ba9c4ee22bb9690e57b5e9a85ec04359dad0d514d34eb418ccc10c7d6f9b887",
            "timestamp": 1683373621,
            "size": 7928986,
            "filename": "ASE_submit.zip"
        },
        "topics": [
            "AI and Software Engineering",
            "Software Analytics"
        ],
        "pc_conflicts": {
            "mnayebi@yorku.ca": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1682693962,
        "modified_at": 1683821962,
        "tags": [
            "accept#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 665,
        "title": "An Empirical Study on Fine-tuning Large Language Models of Code for Automated Program Repair",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-97eedc028e035e44154c074cef121dcaefc9c481a0138f8593ec385e28f26eaa",
            "timestamp": 1683371791,
            "size": 965077,
            "pages": 12
        },
        "abstract": "The advent of large language models (LLMs) has opened up new opportunities for automated program repair (APR). In particular, some recent studies have explored how to leverage large language models of code (LLMCs) for program repair tasks and show promising results. However, most of them adopt the zero\/few-shot learning paradigm for APR by directly using LLMCs to generate the possibly correct code given its surrounding context. Though effective, the repair capabilities of LLMCs based on the fine-tuning paradigm have yet to be extensively explored. Also, it remains unknown whether LLMCs have the potential to repair more complicated bugs (e.g., multi-hunk bugs). To fill the gap, in this work, we conduct a comprehensive study on the program repair capability of LLMC in the fine-tuning paradigm. We select 5 popular LLMCs with representative pre-training architectures, including CodeBERT, GraphCodeBERT, PLBART, CodeT5, and UniXcoder. We consider 3 typical program repair scenarios (i.e., common bugs, vulnerabilities, and errors) involving 3 programming languages (i.e., Java, C\/C++, and JavaScript). Notably, we take both single-hunk and multi-hunk bugs\/vulnerabilities into account. We then fine-tune them on our collected large-scale datasets and compare them with existing state-of-the-art APR tools. We also investigate the impact of different technical strategies, which include code abstractions, code representations, and model evaluation metrics. Our experimental results show that LLMCs in the fine-tuning paradigm can significantly outperform previous SOTA APR tools. Through in-depth analysis, we provide insights into choosing appropriate strategies to guide LLMC for better performance. Lastly, we reveal several limitations of LLMCs for APR and make suggestions for future research on LLMC-based APR.",
        "authors": [
            {
                "email": "huangk@nipc.org.cn",
                "first": "Kai",
                "last": "Huang",
                "affiliation": "University of Chinese Academy of Sciences; Zhongguancun Laboratory",
                "contact": true
            },
            {
                "email": "mengxx@act.buaa.edu.cn",
                "first": "Xiangxin",
                "last": "Meng",
                "affiliation": "Beihang University",
                "contact": true
            },
            {
                "email": "jian_zhang@ntu.edu.sg",
                "first": "Jian",
                "last": "Zhang",
                "affiliation": "Nanyang Technological University",
                "contact": true
            },
            {
                "email": "yangliu@ntu.edu.sg",
                "first": "Yang",
                "last": "Liu",
                "affiliation": "Nanyang Technological University",
                "contact": true
            },
            {
                "email": "wangwj@ucas.ac.cn",
                "first": "Wenjie",
                "last": "Wang",
                "affiliation": "University of Chinese Academy of Sciences",
                "contact": true
            },
            {
                "email": "lishuhao@zgclab.edu.cn",
                "first": "Shuhao",
                "last": "Li",
                "affiliation": "Zhongguancun Laboratory",
                "contact": true
            },
            {
                "email": "zhangyq@nipc.org.cn",
                "first": "Yuqing",
                "last": "Zhang",
                "affiliation": "University of Chinese Academy of Sciences; Zhongguancun Laboratory",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering"
        ],
        "pc_conflicts": {
            "junsun@smu.edu.sg": true,
            "lxiao6@stevens.edu": true,
            "senchen@tju.edu.cn": true,
            "xfxie@smu.edu.sg": true,
            "gaocuiyun@hit.edu.cn": true,
            "ma.lei@acm.org": true,
            "lilicoding@ieee.org": true,
            "louyiling610@gmail.com": true,
            "fangchunrong@nju.edu.cn": true,
            "linglingfan@nankai.edu.cn": true,
            "jie.zhang@kcl.ac.uk": true,
            "szy_@pku.edu.cn": true,
            "xxie@whu.edu.cn": true,
            "y.sui@unsw.edu.au": true,
            "tsu@sei.ecnu.edu.cn": true,
            "xuwang@buaa.edu.cn": true,
            "yli044@e.ntu.edu.sg": true,
            "mengguozhu@iie.ac.cn": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683368208,
        "modified_at": 1683371791,
        "tags": [
            "accept#0",
            "dpa_candidate#0",
            "dpa_yes#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 672,
        "title": "Repeated Builds During Code Review: An Empirical Study of the OpenStack Community",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-ccde53bb0b8a959409e4e615f3731e5249f3e6190ae95097c9466e39bbd76dd5",
            "timestamp": 1683320939,
            "size": 1076848,
            "pages": 12
        },
        "abstract": "Code review is a popular practice where developers critique each others' changes. \r\nSince automated builds can identify low-level issues (e.g., syntactic errors, regression bugs), it is not uncommon for software organizations to incorporate automated builds in the code review process. In such code review deployment scenarios, submitted change sets must be approved for integration by both peer code reviewers and automated build bots.\r\nSince automated builds may produce an unreliable signal of the status of a change set (e.g., due to \"flaky\" or non-deterministic execution behaviour), code review tools, such as Gerrit, allow developers to request a \"recheck\", which repeats the build process without updating the change set. We conjecture that an unconstrained recheck command will waste time and resources if it is not applied judiciously.\r\nTo explore how the recheck command is applied in a practical setting, in this paper, we conduct an empirical study of 66,932 code reviews from the OpenStack community.\r\n\r\nWe quantitatively analyze (i) how often build failures are rechecked; (ii) the extent to which invoking recheck changes build failure outcomes; and (iii) how much waste is generated by invoking recheck. We observe that (i) 55% of code reviews invoke the recheck command after a failing build is reported; (ii) invoking the recheck command only changes the outcome of a failing build in 42% of the cases; and (iii) invoking the recheck command increases review waiting time by an average of 2,200% and equates to 187.4 compute years of waste---enough compute resources to compete with the oldest land living animal on earth.\r\n\r\nOur observations indicate that the recheck command is frequently used after the builds fail, but does not achieve a high likelihood of build success.\r\nWhile recheck currently generates plenty of wasted computational resources and bloats waiting times, it also presents exciting future opportunities for researchers and tool builders to propose solutions that can reduce waste.",
        "authors": [
            {
                "email": "rungroj.maipradit@uwaterloo.ca",
                "first": "Rungroj",
                "last": "Maipradit",
                "affiliation": "University of Waterloo",
                "contact": true
            },
            {
                "email": "d.wang@ait.kyushu-u.ac.jp",
                "first": "Dong",
                "last": "Wang",
                "affiliation": "Kyushu University",
                "contact": true
            },
            {
                "email": "patanamon.t@unimelb.edu.au",
                "first": "Patanamon",
                "last": "Thongtanunam",
                "affiliation": "The University of Melbourne",
                "contact": true
            },
            {
                "email": "raula-k@is.naist.jp",
                "first": "Raula Gaikovina",
                "last": "Kula",
                "affiliation": "Nara Institute of Science and Technology",
                "contact": true
            },
            {
                "email": "kamei@ait.kyushu-u.ac.jp",
                "first": "Yasutaka",
                "last": "Kamei",
                "affiliation": "Kyushu University",
                "contact": true
            },
            {
                "email": "shane.mcintosh@uwaterloo.ca",
                "first": "Shane",
                "last": "McIntosh",
                "affiliation": "University of Waterloo",
                "contact": true
            }
        ],
        "topics": [
            "Software Analytics",
            "Tools and Processes"
        ],
        "pc_conflicts": {
            "shang@encs.concordia.ca": true,
            "shaowei.wang@umanitoba.ca": true,
            "raula-k@is.naist.jp": "author",
            "ma.lei@acm.org": true,
            "lilicoding@ieee.org": true,
            "csaba.nagy@usi.ch": true,
            "foutse.khomh@polymtl.ca": true,
            "hoa@uow.edu.au": true,
            "davidlo@smu.edu.sg": true,
            "s.proksch@tudelft.nl": true,
            "maxime.lamothe@polymtl.ca": true,
            "rdyer@unl.edu": true,
            "sahraouh@iro.umontreal.ca": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1692027367,
        "modified_at": 1692027367
    },
    {
        "object": "paper",
        "pid": 679,
        "title": "Generative Model-Based Testing on Decision-Making Policies",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-715ebbab6cfbd188e02b92aa7481ba3ab7c37869a8486e7720f04c7fed9ebec9",
            "timestamp": 1683370265,
            "size": 1643225,
            "pages": 12
        },
        "abstract": "The reliability of decision-making policies is urgently important today as they have established the fundamentals of many critical applications such as autonomous driving and robotics. To ensure reliability, there have been a number of research efforts on testing model-based decision-making policies. However, the test generation techniques proposed so far are inefficient due to two limitations: first, search-based techniques often modify the intermediate state during the execution which violates the continuity of the trajectory in real-world applications and hence compromises the practicality and validity of the generated cases. Second, the guidance of existing techniques does not diversify agent behavior, exhibiting low testing effectiveness and poor diversity.\r\n\r\nIn this paper, we present a scalable and effective testing framework for decision-making policies. First, we adopt a generative model-based test case generator that can easily adopt various search spaces to ensure the practicality and validity of test cases. Then, we propose a termination state novelty-based guidance that can diversify agent behaviors and improve state space coverage to ensure the effectiveness and diversity of the generated test cases. We evaluate our framework on five widely used decision-making tasks, including scenarios of autonomous driving, aircraft collision avoidance, and gaming. The results demonstrate that our approach identifies more unique failure-triggering test cases compared to the current state-of-the-art techniques. Moreover, we employ the detected failure trajectories to repair the evaluated models, achieving better robustness enhancement compared to the baseline method.",
        "authors": [
            {
                "email": "li.zhuo.786@s.kyushu-u.ac.jp",
                "first": "Zhuo",
                "last": "Li",
                "affiliation": "Kyushu University",
                "contact": true
            },
            {
                "email": "xiongfei.wu.a94@s.kyushu-u.ac.jp",
                "first": "Xiongfei",
                "last": "Wu",
                "affiliation": "Kyushu University",
                "contact": true
            },
            {
                "email": "derui.zhu@tum.de",
                "first": "Derui",
                "last": "Zhu",
                "affiliation": "Technical University of Munich",
                "contact": true
            },
            {
                "email": "snowbirds.mf@gmail.com",
                "first": "Mingfei",
                "last": "Cheng",
                "affiliation": "Singapore Management University",
                "contact": true
            },
            {
                "email": "chen.siyuan.388@s.kyushu-u.ac.jp",
                "first": "Siyuan",
                "last": "Chen",
                "affiliation": "Kyushu University",
                "contact": true
            },
            {
                "email": "fuyuanzhang@163.com",
                "first": "Fuyuan",
                "last": "Zhang",
                "affiliation": "Kyushu University",
                "contact": true
            },
            {
                "email": "xfxie@smu.edu.sg",
                "first": "Xiaofei",
                "last": "Xie",
                "affiliation": "Singapore Management University",
                "contact": true
            },
            {
                "email": "ma.lei@acm.org",
                "first": "Lei",
                "last": "Ma",
                "affiliation": "The University of Tokyo & University of Alberta",
                "contact": true
            },
            {
                "email": "zhao@ait.kyushu-u.ac.jp",
                "first": "Jianjun",
                "last": "Zhao",
                "affiliation": "Kyushu University",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering"
        ],
        "pc_conflicts": {
            "shang@encs.concordia.ca": true,
            "junsun@smu.edu.sg": true,
            "chunyang.chen@monash.edu": true,
            "y.tian@queensu.ca": true,
            "shaowei.wang@umanitoba.ca": true,
            "lingming@illinois.edu": true,
            "tianyi@purdue.edu": true,
            "xin.xia@acm.org": true,
            "dirk.beyer@sosy-lab.org": true,
            "shuaiw@cse.ust.hk": true,
            "xfxie@smu.edu.sg": "author",
            "ma.lei@acm.org": "author",
            "lilicoding@ieee.org": true,
            "jie.zhang@kcl.ac.uk": true,
            "davidlo@smu.edu.sg": true,
            "zhonghao@sjtu.edu.cn": true,
            "seongmin.lee@mpi-sp.org": true,
            "tsu@sei.ecnu.edu.cn": true,
            "yli044@e.ntu.edu.sg": true,
            "mengguozhu@iie.ac.cn": true,
            "andrea.stocco@tum.de": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683305011,
        "modified_at": 1683370265,
        "tags": [
            "accept#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 699,
        "title": "Symbolic Fixpoint Algorithms for Logical LTL Games",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-9a3d08e67546c3e8e0230810e24de474ca9ad4b62f299cdb3151d49ad886bfff",
            "timestamp": 1683374244,
            "size": 562610,
            "pages": 11
        },
        "abstract": "Two-player games are a fruitful way to represent and reason about\r\nseveral important synthesis tasks.\r\nThese tasks include controller synthesis (where one asks for a controller for a\r\ngiven plant such that the controlled plant satisfies a given temporal\r\nspecification), program repair (setting values of variables to avoid\r\nexceptions), and synchronization synthesis (adding lock\/unlock\r\nstatements in multi-threaded programs to satisfy safety assertions).\r\nIn all these applications, a solution directly corresponds to a\r\nwinning strategy for one of the players in the induced game.\r\nIn turn, \\emph{logically-specified} games offer a powerful way to model these\r\ntasks for large or infinite-state systems. Much\r\nof the techniques proposed for solving such games typically\r\nrely on abstraction-refinement or template-based solutions.\r\nIn this paper, we show how to apply classical fixpoint algorithms, that\r\nhave hitherto been used in explicit, finite-state, settings, to a\r\nsymbolic logical setting.\r\nWe implement our techniques in a tool called WSynth-LTL and show that\r\nthey are not only effective in synthesizing\r\nvalid controllers for a variety of challenging benchmarks from the\r\nliterature, but often compute maximal winning regions and\r\nmaximally-permissive controllers.  We achieve \\textbf{46.38X speed-up} over the state of the art and also scale well for non-trivial LTL specifications.",
        "authors": [
            {
                "email": "stanly@iisc.ac.in",
                "first": "Stanly",
                "last": "Samuel",
                "affiliation": "Indian Institute of Science, Bangalore, India",
                "contact": true
            },
            {
                "email": "deepakd@iisc.ac.in",
                "first": "Deepak",
                "last": "D'Souza",
                "affiliation": "Indian Institute of Science, Bangalore, India",
                "contact": true
            },
            {
                "email": "raghavan@iisc.ac.in",
                "first": "Raghavan",
                "last": "Komondoor",
                "affiliation": "Indian Institute of Science, Bengaluru, India",
                "contact": true
            }
        ],
        "supplementary_material": {
            "mimetype": "application\/zip",
            "hash": "sha2-5a45654e46dbf058bcfcb30a72f0e572fa22e4cd47d48c6a2705f1c5eeea5ba0",
            "timestamp": 1683374135,
            "size": 156922700,
            "filename": "Archive.zip"
        },
        "topics": [
            "AI and Software Engineering",
            "Formal Aspects of Software Engineering",
            "Testing and Analysis",
            "Tools and Processes"
        ],
        "pc_conflicts": {
            "mnayebi@yorku.ca": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683371943,
        "modified_at": 1683374244,
        "tags": [
            "accept#0"
        ]
    },
    {
        "object": "paper",
        "pid": 708,
        "title": "Increasing the Responsiveness of Web Applications by Introducing Lazy Loading",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-bdd892b3ce09c8994761b06d7c9fffb868eabb050903f4f1a22e09a8c54eb72e",
            "timestamp": 1683333995,
            "size": 297787,
            "pages": 11
        },
        "abstract": "Front-end developers want their applications to contain no more code than is needed in order to minimize the amount of time that elapses between visiting a web page and the page becoming responsive. \r\nHowever, front-end code is typically written in JavaScript,  the ubiquitous \"language of the web\", and tends to rely heavily on third-party packages. \r\nWhile the reuse of packages improves developer productivity, it is notorious for resulting in very large \"bloated\" applications, resulting in a degraded end-user experience. \r\nOne way to combat such bloat is to _lazily load_ external packages on an as-needed basis, for which support was added to JavaScript in 2020 when _asynchronous, dynamic_ imports were added to the language standard.\r\nUnfortunately, migrating existing projects to take advantage of this feature is nontrivial, as the code changes required to introduce asynchrony may involve complex, non-local transformations.\r\n\r\nIn this work, we propose an approach for automatically introducing lazy loading of third-party packages in JavaScript applications.\r\nOur approach relies on static analysis to identify external packages that can be loaded lazily and generates the code transformations required to lazily load those packages. \r\nSince the static analysis is unsound, these transformations are presented as suggestions\r\nthat programmers should review and test carefully.\r\nWe implement this approach in a tool called _Lazifier_, and evaluate _Lazifier_ on 10 open-source front-end JavaScript applications, showing that each application was successfully refactored, reducing initial application size and load times in all cases.\r\nOn average, for these applications, _Lazifier_ reduces initial application size by 36.2%, initial load time by 29.7%, and unsoundness did not arise in any of these applications.",
        "authors": [
            {
                "email": "turcotte.al@northeastern.edu",
                "first": "Alexi",
                "last": "Turcotte",
                "affiliation": "Northeastern University",
                "contact": true
            },
            {
                "email": "gokhale.sa@northeastern.edu",
                "first": "Satyajit",
                "last": "Gokhale",
                "affiliation": "Northeastern University",
                "contact": true
            },
            {
                "email": "f.tip@northeastern.edu",
                "first": "Frank",
                "last": "Tip",
                "affiliation": "Northeastern University",
                "contact": true
            }
        ],
        "topics": [
            "Maintenance and Evolution",
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "michael@binaervarianz.de": true,
            "dolby@us.ibm.com": true,
            "j.bell@northeastern.edu": true,
            "wangying@swc.neu.edu.cn": true,
            "mnayebi@yorku.ca": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683333995,
        "modified_at": 1683340306
    },
    {
        "object": "paper",
        "pid": 732,
        "title": "Mutation-based Fault Localization of Deep Neural Networks",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-597257c62d21ea8cb2aad3c46abf575247b7b2711d7d5fa8c5a9070f22f0d8f2",
            "timestamp": 1683368716,
            "size": 517725,
            "pages": 12
        },
        "abstract": "Deep neural networks (DNNs) are susceptible to bugs, just like other types of software systems.\r\nA significant uptick in using DNN, and its applications in wide-ranging areas, including safety-critical systems, warrant extensive research on software engineering tools for improving the reliability of DNN-based systems.\r\nOne such tool that has gained significant attention in the recent years is DNN fault localization.\r\nThis paper revisits mutation-based fault localization in the context of DNN models and proposes a novel technique, named deepmufl, applicable to a wide range of DNN models.\r\nWe have implemented deepmufl and have evaluated its effectiveness using 109 bugs obtained from StackOverflow.\r\nOur results show that deepmufl detects 53\/109 of the bugs by ranking the buggy layer in top-1 position, outperforming state-of-the-art static and dynamic DNN fault localization systems that are also designed to target the class of bugs supported by deepmufl.\r\nAdditionally, we observed that we can cut down the end-to-end fault localization time by half via mutation selection by losing only 7.55% of the bugs localized in top-1 position.",
        "authors": [
            {
                "email": "alig@iastate.edu",
                "first": "Ali",
                "last": "Ghanbari",
                "affiliation": "Dept. of Computer Science, Iowa State University",
                "contact": true
            },
            {
                "email": "dgthomas@iastate.edu",
                "first": "Deepak-George",
                "last": "Thomas",
                "affiliation": "Dept. of Computer Science, Iowa State University",
                "contact": true
            },
            {
                "email": "arbab@iastate.edu",
                "first": "Muhammad Arbab",
                "last": "Arshad",
                "affiliation": "Dept. of Computer Science, Iowa State University",
                "contact": true
            },
            {
                "email": "hridesh@iastate.edu",
                "first": "Hridesh",
                "last": "Rajan",
                "affiliation": "Dept. of Computer Science, Iowa State University",
                "contact": true
            }
        ],
        "supplementary_material": {
            "mimetype": "text\/plain",
            "hash": "sha2-f9c687111ace5bb556dcaa50af3352afef9eb6df0ad8c42d12fc3b559be88d6c",
            "timestamp": 1683341951,
            "size": 219,
            "filename": "Data Availability.txt"
        },
        "topics": [
            "AI and Software Engineering",
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "hridesh@iastate.edu": "author",
            "junjiechen@tju.edu.cn": true,
            "gunel.jahangirova@kcl.ac.uk": true,
            "lingming@illinois.edu": true,
            "tianyi@purdue.edu": true,
            "j.bell@northeastern.edu": true,
            "haodan@pku.edu.cn": true,
            "louyiling610@gmail.com": true,
            "foutse.khomh@polymtl.ca": true,
            "jie.zhang@kcl.ac.uk": true,
            "mnayebi@yorku.ca": true,
            "bagheri@unl.edu": true,
            "rdyer@unl.edu": true,
            "mbagherzadeh@oakland.edu": true,
            "sumon@case.edu": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683339497,
        "modified_at": 1683368716,
        "tags": [
            "accept#0",
            "dpa_candidate#0",
            "dpa_yes#0",
            "invalid_abstract#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 746,
        "title": "NaturalFuzz: Natural Input Generation for Big Data Analytics",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-d09e4b1e796a3bc2dda98dc22cffe5c44d1a18f9440057ed0a98b6bba62b6b1a",
            "timestamp": 1683777225,
            "size": 839501,
            "pages": 11
        },
        "abstract": "Fuzzing applies input mutations iteratively with the only goal of finding more bugs, resulting in synthetic tests that tend to lack realism. Big data analytics are expected to ingest real-world data as input. Therefore, when synthetic test data are not easily comprehensible, they are less likely to facilitate the downstream task of fixing errors. Our position is that fuzzing in this domain must achieve both high naturalness and high code coverage. We propose a new natural synthetic test generation tool for big data analytics, called NaturalFuzz. It generates both unstructured, semi-structured, and structured data with corresponding semantics such as ’zipcode’ and ’age.’ The key insights behind NaturalFuzz are two-fold. First, though existing test data may be small and lack coverage, we can grow this data to increase code coverage. Second, we can strategically mix constituent parts across different rows and columns to construct new realistic synthetic data by leveraging fine-grained data provenance. On commercial big data application benchmarks, NaturalFuzz achieves an additional 19.9% coverage and detects 1.9× more faults than an ML-based synthetic data generator SDV when generating comparably sized inputs. This is because an ML-based synthetic data generator does not consider which code branches are exercised by which input rows from which tables, while NaturalFuzz is able to select input rows that have a high potential to increase code coverage and mutate the selected data towards unseen, new program behavior. NaturalFuzz’s test data is more realistic than the test data generated by two baseline fuzzers (BigFuzz and Jazz), while increasing code coverage and fault detection potential. NaturalFuzz is the first fuzzing methodology with three benefits: (1) exclusively generate natural inputs, (2) fuzz multiple input sources simultaneously, and (3) find deeper semantics faults.",
        "authors": [
            {
                "email": "ahmad35@vt.edu",
                "first": "Ahmad",
                "last": "Humayun",
                "affiliation": "Virginia Tech",
                "contact": true
            },
            {
                "email": "thaddywu@cs.ucla.edu",
                "first": "Yaoxuan",
                "last": "Wu",
                "affiliation": "UCLA",
                "contact": true
            },
            {
                "email": "miryung@cs.ucla.edu",
                "first": "Miryung",
                "last": "Kim",
                "affiliation": "UCLA",
                "contact": true
            },
            {
                "email": "gulzar@cs.vt.edu",
                "first": "Muhammad Ali",
                "last": "Gulzar",
                "affiliation": "Virginia Tech",
                "contact": true
            }
        ],
        "supplementary_material": {
            "mimetype": "text\/plain",
            "hash": "sha2-0465eadef484ee45864cb4180d62e9130ed69adbce72c5060d57523bd29c805e",
            "timestamp": 1683371321,
            "size": 69898,
            "filename": "NaturalnessScore.ipynb"
        },
        "topics": [
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "rayb@cs.columbia.edu": true,
            "hridesh@iastate.edu": true,
            "tianyi@purdue.edu": true,
            "a.filieri@imperial.ac.uk": true,
            "mnayebi@yorku.ca": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683370525,
        "modified_at": 1683777225,
        "tags": [
            "accept#0",
            "dpa_candidate#0",
            "dpa_no#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 755,
        "title": "An Intentional Forgetting-Driven Self-Healing Method For Deep Reinforcement Learning Systems",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-1e26ae39aceea41ed853992bd6add30b4fe67ad461f2f1a8f6c59d9b7b00a50f",
            "timestamp": 1683372531,
            "size": 919788,
            "pages": 12
        },
        "abstract": "Deep reinforcement learning (DRL) is increasingly applied in large-scale productions like Netflix and Facebook. As with most data-driven systems, DRL systems can exhibit undesirable behaviors due to environmental drifts, which often occur in constantly-changing production settings. Continual Learning (CL) is the inherent self-healing approach for adapting the DRL agent in response to the environment's conditions shifts. However, successive shifts of considerable magnitude may cause the production environment to drift from its original state. Recent studies have shown that these environmental drifts tend to drive CL into long, or even unsuccessful, healing cycles, which arise from inefficiencies such as catastrophic forgetting, warm-starting failure, and slow convergence. In this paper, we propose Dr. DRL, an effective self-healing approach for DRL systems that integrates a novel mechanism of intentional forgetting into vanilla CL to overcome its main issues. Dr. DRL deliberately erases the DRL system's minor behaviors to systematically prioritize the adaptation of the key problem-solving skills. Using well-established DRL algorithms, Dr. DRL is compared with vanilla CL on various drifted environments. Dr. DRL is able to reduce, on average, the healing time and fine-tuning episodes by, respectively, 18.74% and 17.72%. Dr. DRL successfully helps agents to adapt to 19.63% of drifted environments left unsolved by vanilla CL while maintaining and even enhancing by up to 45% the obtained rewards for drifted environments that are resolved by both approaches.",
        "authors": [
            {
                "email": "ahmed.haj-yahmed@polymtl.ca",
                "first": "Ahmed Haj",
                "last": "Yahmed",
                "affiliation": "Polytechnique Montréal",
                "contact": true
            },
            {
                "email": "rached.bouchoucha@polymtl.ca",
                "first": "Rached",
                "last": "Bouchoucha",
                "affiliation": "Polytechnique Montréal",
                "contact": true
            },
            {
                "email": "houssem.ben-braiek@polymtl.ca",
                "first": "Houssem Ben",
                "last": "Braiek",
                "affiliation": "Polytechnique Montréal",
                "contact": true
            },
            {
                "email": "foutse.khomh@polymtl.ca",
                "first": "Foutse",
                "last": "Khomh",
                "affiliation": "Polytechnique Montréal",
                "contact": true
            }
        ],
        "supplementary_material": {
            "mimetype": "application\/zip",
            "hash": "sha2-17cfc79c57b1bf9763d1b45ebf84b7d40cead4be6254a371e84dc409c9c3252f",
            "timestamp": 1683368805,
            "size": 335490,
            "filename": "replication_package.zip"
        },
        "topics": [
            "AI and Software Engineering",
            "Maintenance and Evolution",
            "Testing and Analysis",
            "Tools and Processes"
        ],
        "pc_conflicts": {
            "sfakhoury@microsoft.com": true,
            "marcelo.maia@ufu.br": true,
            "csaba.nagy@usi.ch": true,
            "foutse.khomh@polymtl.ca": "author",
            "davidlo@smu.edu.sg": true,
            "maxime.lamothe@polymtl.ca": true,
            "mhamdaqa@polymtl.ca": true,
            "sahraouh@iro.umontreal.ca": true,
            "Naouel.Moha@etsmtl.ca": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683368609,
        "modified_at": 1683564814,
        "tags": [
            "accept#0"
        ]
    },
    {
        "object": "paper",
        "pid": 769,
        "title": "Fast and Reliable Program Synthesis via User Interaction",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-40ef3114ba5e57507e700fd8e5c2a825613e6107d08a937edeb2b75f581b5719",
            "timestamp": 1683361683,
            "size": 1392282,
            "pages": 12
        },
        "abstract": "Program synthesis from examples has recently received significant attention due to its potential to automate tedious programming tasks. While existing tools have been shown to scale to challenging problems, their performance remains erratic and hard to control or even anticipate. For instance, it can vary significantly across different programming tasks and even across different examples for the same task. The key issue is that the search space depends on the given examples in a complex way. In particular, scalable synthesizers typically rely on a combination of machine learning to prioritize search order and deduction to prune search space, making it hard to quantitatively reason about how much an example speeds up the search. We propose a novel approach for quantifying the effectiveness of an example at reducing synthesis time. Based on this technique, we devise an algorithm that actively queries the user to obtain additional examples that significantly reduce synthesis time. We evaluate our approach on 30 challenging benchmarks across two different data science domains. On average, our approach achieves a 6.0$\\times$ speed-up in synthesis time compared to state-of-the-art synthesizers. Furthermore, when the initial user-provided examples are ineffective at pruning the search space, our approach can query the user to obtain additional examples that are significantly more effective.",
        "authors": [
            {
                "email": "yanju@cs.ucsb.edu",
                "first": "Yanju",
                "last": "Chen",
                "affiliation": "University of California, Santa Barbara",
                "contact": true
            },
            {
                "email": "chenglong.wang@microsoft.com",
                "first": "Chenglong",
                "last": "Wang",
                "affiliation": "Microsoft Research",
                "contact": true
            },
            {
                "email": "xwangsd@umich.edu",
                "first": "Xinyu",
                "last": "Wang",
                "affiliation": "University of Michigan",
                "contact": true
            },
            {
                "email": "obastani@seas.upenn.edu",
                "first": "Osbert",
                "last": "Bastani",
                "affiliation": "University of Pennsylvania",
                "contact": true
            },
            {
                "email": "yufeng@cs.ucsb.edu",
                "first": "Yu",
                "last": "Feng",
                "affiliation": "University of California, Santa Barbara",
                "contact": true
            }
        ],
        "supplementary_material": {
            "mimetype": "application\/pdf",
            "hash": "sha2-763168971beeca64a698f44e08e9b6b61090c8b4fe994d9aafbc1f258787083d",
            "timestamp": 1683361683,
            "size": 314042,
            "filename": "faery-supp.pdf",
            "pages": 4
        },
        "topics": [
            "AI and Software Engineering",
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "tianyi@purdue.edu": true,
            "xin.xia@acm.org": true,
            "shihan@microsoft.com": true,
            "sfakhoury@microsoft.com": true,
            "saikatc@microsoft.com": true,
            "mnayebi@yorku.ca": true,
            "davidlo@smu.edu.sg": true,
            "taoxie@pku.edu.cn": true,
            "jordan.henkel@microsoft.com": true,
            "minghuama@microsoft.com": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683361683,
        "modified_at": 1684479106,
        "tags": [
            "accept#0",
            "ChrisCoI#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 771,
        "title": "Improving code extraction from coding screencasts using a code-aware encoder-decoder model",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-70b5657689733c210c1e08549e93cf348a757268f6015ca5eecf7440adb42cd0",
            "timestamp": 1683371656,
            "size": 468863,
            "pages": 12
        },
        "abstract": "Accurate automatic code extraction from tutorial videos is crucial for software developers seeking to reuse the code contained in these videos. Current methods using optical character recognition (OCR) often yield inaccurate results due to code complexity and variations in screencast formats. To address this issue, we introduce CodeT5-OCRfix, an approach that leverages the pre-trained code-aware large language model CodeT5 to enhance code extraction accuracy by post-processing OCRed code. We first collect a large and diverse dataset of source code screenshots captured from more than 10K Java projects from GitHub. We then apply the most widely used OCR engine for the task of code extraction from videos, Tesseract, on these screenshots and collect the OCRed code along with the ground truth code extracted from the Java files. We built a training dataset of more than 585K pairs of OCRed and ground truth code pairs, which we then used to fine-tune CodeT5, obtaining our model CodeT5-OCRfix. An empirical evaluation on both screenshots and screencast frames shows that CodeT5-OCRfix outperforms baseline code extraction models and is also more time-efficient. Our approach therefore improves the state-of-the-art in code extraction techniques from screencasts and images.",
        "authors": [
            {
                "email": "malkadi@cs.fsu.edu",
                "first": "Abdulkarim",
                "last": "Malkadi",
                "affiliation": "Florida State University",
                "contact": true
            },
            {
                "email": "tayeb@cs.fsu.edu",
                "first": "Ahmad",
                "last": "Tayeb",
                "affiliation": "Florida State University",
                "contact": true
            },
            {
                "email": "shaiduc@fsu.edu",
                "first": "Sonia",
                "last": "Haiduc",
                "affiliation": "Florida State University",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering",
            "Maintenance and Evolution"
        ],
        "pc_conflicts": {
            "cmc@nd.edu": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683371357,
        "modified_at": 1683371998,
        "tags": [
            "accept#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 783,
        "title": "Software Entity Recognition with Noise-Robust Learning",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-27a12e850e5942ed686b5beb35e61c59fc38db86dc84ccd8682a1788061a4492",
            "timestamp": 1683372301,
            "size": 387676,
            "pages": 12
        },
        "abstract": "Recognizing software entities such as library names from free-form text is essential to enable many software engineering (SE) technologies, such as traceability link recovery, automated documentation, and API recommendation. While many approaches have been proposed to address this problem, they suffer from small entity vocabularies or noisy training data, hindering their capability of recognizing software entities mentioned in sophisticated narratives. To address this challenge, we first leverage the Wikipedia taxonomy to develop a comprehensive entity lexicon with 79K unique software entities in 12 fine-grained categories, as well as a large labeled dataset with 1.7M sentences and 3.4M entity labels. Then, we propose a noise-robust learning approach called self-regularization to regularize the training and prediction consistency of a software entity recognition model through a dropout mechanism. Our evaluation shows that models trained with self-regularization outperform both the vanilla models and two state-of-the-art methods on both our Wikipedia dataset and two other datasets obtained from Stack Overflow. We release our corpus and code publicly for future research.",
        "authors": [
            {
                "email": "taing@seas.upenn.edu",
                "first": "Tai",
                "last": "Nguyen",
                "affiliation": "University of Pennsylvania",
                "contact": true
            },
            {
                "email": "di5@purdue.edu",
                "first": "Yifeng",
                "last": "Di",
                "affiliation": "Purdue University",
                "contact": true
            },
            {
                "email": "joohanl@usc.edu",
                "first": "Joohan",
                "last": "Lee",
                "affiliation": "University of Southern California",
                "contact": true
            },
            {
                "email": "muhaoche@usc.edu",
                "first": "Muhao",
                "last": "Chen",
                "affiliation": "University of Southern California",
                "contact": true
            },
            {
                "email": "tianyi@purdue.edu",
                "first": "Tianyi",
                "last": "Zhang",
                "affiliation": "Purdue University",
                "contact": true
            }
        ],
        "supplementary_material": {
            "mimetype": "application\/pdf",
            "hash": "sha2-a1fb899cad19f2e692117155ee3009ef548d35d3b60336767860457cd82affc6",
            "timestamp": 1683368458,
            "size": 70727,
            "filename": "ASE_NER4SE_Supplementary.pdf",
            "pages": 1
        },
        "topics": [
            "AI and Software Engineering"
        ],
        "pc_conflicts": {
            "rayb@cs.columbia.edu": true,
            "hridesh@iastate.edu": true,
            "tianyi@purdue.edu": "author",
            "gaocuiyun@hit.edu.cn": true,
            "ma.lei@acm.org": true,
            "louyiling610@gmail.com": true,
            "xyzhang@cs.purdue.edu": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683358309,
        "modified_at": 1683372301,
        "tags": [
            "accept#0"
        ]
    },
    {
        "object": "paper",
        "pid": 800,
        "title": "On-the-fly Improving Performance of Deep Code Models via Input Denoising",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-660ced1d7f4759c9aef2893c9e7bea3b545216b3618cea16e818d416050ec92c",
            "timestamp": 1683373887,
            "size": 492940,
            "pages": 12
        },
        "abstract": "Deep learning has been widely adopted to tackle various code-based tasks by building deep code models based on a large amount of code snippets. While these deep code models have achieved great success, even state-of-the-art models suffer from noise present in inputs leading to erroneous predictions. While it is possible to enhance models through retraining\/fine-tuning, this is not a once-and-for-all approach and incurs significant overhead. In particular, these techniques cannot on-the-fly improve performance of (deployed) models. There are currently some techniques for input denoising in other domains (such as image processing), but since code input is discrete and must strictly abide by complex syntactic and semantic constraints, input denoising techniques in other fields are almost not applicable. In this work, we propose the first input denoising technique (i.e., CodeDenoise) for deep code models. Its key idea is to localize noisy identifiers in (likely) mispredicted inputs, and denoise such inputs by cleansing the located identifiers. It does not need to retrain or reconstruct the model, but only needs to cleanse inputs on-the-fly to improve performance. Our experiments on 18 deep code models (i.e., three pre-trained models with six code-based datasets) demonstrate the effectiveness and efficiency of CodeDenoise. For example, on average, CodeDenoise successfully denoises 21.91% of mispredicted inputs and improves the original models by 2.04% in terms of the model accuracy across all the subjects in an average of 0.48 second spent on each input, substantially outperforming the widely-used fine-tuning strategy.",
        "authors": [
            {
                "email": "tianzhao@tju.edu.cn",
                "first": "Zhao",
                "last": "Tian",
                "affiliation": "College of Intelligence and Computing, Tianjin University",
                "contact": true
            },
            {
                "email": "junjiechen@tju.edu.cn",
                "first": "Junjie",
                "last": "Chen",
                "affiliation": "College of Intelligence and Computing, Tianjin University",
                "contact": true
            },
            {
                "email": "xyzhang@cs.purdue.edu",
                "first": "Xiangyu",
                "last": "Zhang",
                "affiliation": "Department of Computer Science, Purdue University",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering",
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "dolby@us.ibm.com": true,
            "junsun@smu.edu.sg": true,
            "junjiechen@tju.edu.cn": "author",
            "lingming@illinois.edu": true,
            "tianyi@purdue.edu": true,
            "fengyang@nju.edu.cn": true,
            "senchen@tju.edu.cn": true,
            "haodan@pku.edu.cn": true,
            "xfxie@smu.edu.sg": true,
            "louyiling610@gmail.com": true,
            "fangchunrong@nju.edu.cn": true,
            "hongyujohn@gmail.com": true,
            "mnayebi@yorku.ca": true,
            "guowei.yang@uq.edu.au": true,
            "wurongxin@xmu.edu.cn": true,
            "xyzhang@cs.purdue.edu": "author",
            "juanzhai@umass.edu": true,
            "jiangjiajun@tju.edu.cn": true,
            "mwenaa@hust.edu.cn": true,
            "minghuama@microsoft.com": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683373887,
        "modified_at": 1683374195,
        "tags": [
            "accept#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 813,
        "title": "Detecting Memory Errors in Python Native Code by Tracking Object Lifecycle with Reference Count",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-b01810778540d281bd3f5d8176506aa01baa65211dc490a270e07953bce1b789",
            "timestamp": 1683373663,
            "size": 789400,
            "pages": 11
        },
        "abstract": "Third-party Python modules are usually implemented as binary extensions by using native code (C\/C++) to provide additional features and runtime acceleration. In native code, the heap-allocated PyObjects are managed by the reference counting mechanism provided in Python\/C APIs for automatic reclaiming. Hence, improper refcount manipulation can lead to memory leaks and use-after-free problems, which cannot be detected by simply pairing the occurrence of source and sink points. To detect such problems, state-of-the-art approaches have made groundbreaking contributions to identifying inappropriate final refcount values before returning from native code to Python. However, not all problems can be exposed at the end of a path. To detect those hidden in the middle of a path in native code, it is also crucial to track the lifecycle state of PyObjects through the refcount and lifecycle operations in API calls.\r\n\r\nTo achieve this goal, we propose the PyObject State Transition Model (PSTM) recording the lifecycle states and refcount values of PyObjects to describe the effects of Python\/C API calls and pointer operations. We track state transitions of PyObjects with symbolic execution based on the model and report problems when a statement triggers a transition to buggy states. The program state is also expanded to handle pointer nullity checks and smart pointers of PyObjects. We conduct experiments on 12 open-source projects and detect 256 real problems out of 277 reports, which is twice as many bugs as state-of-the-art approaches. We submit 165 real bugs to those active projects, and 106 issues are either confirmed or resolved.",
        "authors": [
            {
                "email": "maxt@ios.ac.cn",
                "first": "Xutong",
                "last": "Ma",
                "affiliation": "State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing, China",
                "contact": true
            },
            {
                "email": "yanjw@ios.ac.cn",
                "first": "Jiwei",
                "last": "Yan",
                "affiliation": "Technology Center of Software Engineering, Institute of Software, Chinese Academy of Sciences",
                "contact": true
            },
            {
                "email": "zhanghao19@ios.ac.cn",
                "first": "Hao",
                "last": "Zhang",
                "affiliation": "State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences",
                "contact": true
            },
            {
                "email": "yanjun@ios.ac.cn",
                "first": "Jun",
                "last": "Yan",
                "affiliation": "Institute of Software, Chinese Academy of Sciences",
                "contact": true
            },
            {
                "email": "zj@ios.ac.cn",
                "first": "Jian",
                "last": "Zhang",
                "affiliation": "State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing, China",
                "contact": true
            }
        ],
        "supplementary_material": {
            "mimetype": "application\/zip",
            "hash": "sha2-d30760a3b530ea8f0461436f6285fcb893e2eb4c0befbdebaf521f2bef5cb7a0",
            "timestamp": 1683356280,
            "size": 117414939,
            "filename": "ase2023-pyrefcon-artifacts.zip"
        },
        "topics": [
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "mnayebi@yorku.ca": true,
            "xuwang@buaa.edu.cn": true,
            "jyy@nju.edu.cn": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683373663,
        "modified_at": 1683373705,
        "tags": [
            "accept#0"
        ]
    },
    {
        "object": "paper",
        "pid": 814,
        "title": "An Integrated Program Analysis Framework for Graduate Courses in Programming Languages and Software Engineering",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-ec9d0762dc322e94ff53d09e7d6774c9d56cc39b438f48ccf0ce47a384a70a1d",
            "timestamp": 1683365021,
            "size": 486309,
            "pages": 12
        },
        "abstract": "Program analysis, verification and testing are important topics in programming languages and software engineering. They aim to produce engineers who are not only capable of empirically evaluating but, also formally reasoning on the correctness of software systems. We propose a specialized framework, CHIRON, designed to teach graduate-level courses on these topics. CHIRON has a small code base for easy understanding, uses a unified intermediate representation across all its analysis modules, maintains a modular architecture for plugging of new algorithms and uses a ``fun\" programming language to provide a gamified experience. Currently, it packages a dataflow analysis engine for driving compiler optimizations; an abstract interpretation engine for verification; a symbolic execution engine, a fuzzer and an evolutionary test generator for program testing; and a spectrum based statistical bug localization module. \r\n\r\nWithin CHIRON, program analysis tasks are posed in an unconventional setting (as adventures of a turtle) to provide a gamified experience; the accompanying animations (showing the movements of the turtle) allow the student to understand the underlying concepts better, and the detailed logs allow the teaching assistants in their grading activities.\r\n\r\nCHIRON has been used in two offerings of a graduate level course on program analysis, verification and testing. In response to our survey questionnaire, all the students unanimously held the opinion that CHIRON was extremely helpful in aiding their learning, and recommended its use in similar courses.",
        "authors": [
            {
                "email": "prantik@cse.iitk.ac.in",
                "first": "Prantik",
                "last": "Chatterjee",
                "affiliation": "Indian Institute Of Technology Kanpur and MathWorks",
                "contact": true
            },
            {
                "email": "pkalita@cse.iitk.ac.in",
                "first": "Pankaj Kumar",
                "last": "Kalita",
                "affiliation": "Indian Institute Of Technology Kanpur",
                "contact": true
            },
            {
                "email": "sumitl@cse.iitk.ac.in",
                "first": "Sumit",
                "last": "Lahiri",
                "affiliation": "Indian Institute Of Technology Kanpur",
                "contact": true
            },
            {
                "email": "smuduli@cse.iitk.ac.in",
                "first": "Sujit",
                "last": "Muduli",
                "affiliation": "Indian Institute of Technology Kanpur",
                "contact": true
            },
            {
                "email": "vshlsng@cse.iitk.ac.in",
                "first": "Vishal",
                "last": "Singh",
                "affiliation": "Indian Institute of Technology Kanpur",
                "contact": true
            },
            {
                "email": "tgourav@cse.iitk.ac.in",
                "first": "Gourav",
                "last": "Takhar",
                "affiliation": "Indian Institute of Technology Kanpur",
                "contact": true
            },
            {
                "email": "subhajit@iitk.ac.in",
                "first": "Subhajit",
                "last": "Roy",
                "affiliation": "Indian Institute Of Technology Kanpur",
                "contact": true
            }
        ],
        "supplementary_material": {
            "mimetype": "application\/zip",
            "hash": "sha2-d287dba566f501f76ff6ae78907fd31b35d797b0235f25829ba8639413262158",
            "timestamp": 1683365021,
            "size": 156452,
            "filename": "ASE_814_Supplementary_material.zip"
        },
        "topics": [
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "sudipta_chattopadhyay@sutd.edu.sg": true,
            "rma@fe.up.pt": true,
            "mnayebi@yorku.ca": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683281748,
        "modified_at": 1683365021,
        "tags": [
            "accept#0"
        ]
    },
    {
        "object": "paper",
        "pid": 815,
        "title": "Domain Adaptive Code Completion via Language Models and Decoupled Domain Databases",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-ba9a70b09b160c9bcba18f605b58424f1ae757c2d2f14d7399ec3dbeb411b2dd",
            "timestamp": 1683374574,
            "size": 1284239,
            "pages": 12
        },
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance in code completion. However, due to the lack of domain-specific knowledge, they may not be optimal in completing code that requires intensive domain knowledge for example completing the library names. \r\nAlthough there are several works that have confirmed the effectiveness of fine-tuning techniques to adapt language models for code completion in specific domains. They are limited by the need for constant fine-tuning of the model when the project is in constant iteration.\r\n\r\nTo address this limitation, in this paper, we propose $k$NM-LM, a retrieval-augmented language model (R-LM), that integrates domain knowledge into language models without fine-tuning. Different from previous techniques, our approach is able to automatically adapt to different language models and domains. \r\nSpecifically, it utilizes the in-domain code to build the retrieval-based database decoupled from LM, and then combines it with LM through Bayesian inference to complete the code. The extensive experiments on the completion of intra-project and intra-scenario have confirmed that $k$NM-LM provides a significant improvement of 10-15\\% against CodeGPT and UnixCoder. A deep analysis of our tool including the responding speed, storage usage, specific type code completion, and API invocation completion has confirmed that $k$NM-LM provides satisfactory performance, which renders it highly appropriate for domain adaptive code completion. Furthermore, our approach is also orthogonal to  black-box code completion tools. It is easy to integrate our approach as a plugin to further enhance the performance of these tools.",
        "authors": [
            {
                "email": "2228291607@qq.com",
                "first": "Ze",
                "last": "Tang",
                "affiliation": "State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China",
                "contact": true
            },
            {
                "email": "gjd@nju.edu.cn",
                "first": "Jidong",
                "last": "Ge",
                "affiliation": "State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China",
                "contact": true
            },
            {
                "email": "shangqingliu666@gmail.com",
                "first": "Shangqing",
                "last": "Liu",
                "affiliation": "Nanyang Technological University",
                "contact": true
            },
            {
                "email": "tingweizhu33@smail.nju.edu.cn",
                "first": "Tingwei",
                "last": "Zhu",
                "affiliation": "State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China",
                "contact": true
            },
            {
                "email": "xutongtong9@huawei.com",
                "first": "Tongtong",
                "last": "Xu",
                "affiliation": "Huawei",
                "contact": true
            },
            {
                "email": "lghuang@lyle.smu.edu",
                "first": "Liguo",
                "last": "Huang",
                "affiliation": "Department of Computer Science, Southern Methodist University, Dallas, Texas, USA 75275-0122",
                "contact": true
            },
            {
                "email": "luobin@nju.edu.cn",
                "first": "Bin",
                "last": "Luo",
                "affiliation": "State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China",
                "contact": true
            }
        ],
        "supplementary_material": {
            "mimetype": "application\/pdf",
            "hash": "sha2-5cc9b960ce4d95792e24a3e5ee18451152f51a38c0fac07417550f92b943264a",
            "timestamp": 1683374791,
            "size": 11053,
            "filename": "codes.pdf",
            "pages": 1
        },
        "topics": [
            "AI and Software Engineering"
        ],
        "pc_conflicts": {
            "dposhyvanyk@gmail.com": true,
            "junsun@smu.edu.sg": true,
            "chunyang.chen@monash.edu": true,
            "shaowei.wang@umanitoba.ca": true,
            "xin.xia@acm.org": true,
            "fengyang@nju.edu.cn": true,
            "changxu@nju.edu.cn": true,
            "zhendong@fudan.edu.cn": true,
            "gaocuiyun@hit.edu.cn": true,
            "taoyue@gmail.com": true,
            "louyiling610@gmail.com": true,
            "fangchunrong@nju.edu.cn": true,
            "juanzhai@umass.edu": true,
            "wei.yang@utdallas.edu": true,
            "tsu@sei.ecnu.edu.cn": true,
            "yli044@e.ntu.edu.sg": true,
            "jyy@nju.edu.cn": true,
            "zqzuo@nju.edu.cn": true,
            "why@nju.edu.cn": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683374599,
        "modified_at": 1683374599,
        "tags": [
            "accept#0",
            "dpa_candidate#0",
            "dpa_yes#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 822,
        "title": "Thunderkaller: Profiling and Improving the Performance of Syzkaller",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-74c2a2c59b19b98ed7e77338700ba8536db850ea9b281d9f99d761921471ae4c",
            "timestamp": 1683373069,
            "size": 1262761,
            "pages": 11
        },
        "abstract": "Fuzzing is widely adopted to discover vulnerabilities in software, including the kernel. One of the most popular and state-of-the-art fuzzers for kernels is Syzkaller. However, Syzkaller has a much lower testing throughput compared to other user-space fuzzers, which affects the efficiency of both Syzkaller and other Syzkaller-based fuzzers. In this paper, we profiled the performance of Syzkaller, recognized that the major cost comes from program isolation and kernel instrumentation, and then proposed kernel image duplication and three optimization techniques to mitigate such overheads and present the solution Thunderkaller. Our solution does not change or depend on the fuzzing algorithm in any way, orthogonal to other refinements to Syzkaller. Our evaluation shows that, in 24 hours, Thunderkaller speeds up 2.8× compared to vanilla Syzkaller, achieves 25.8% more basic block coverage, detects 21 more unique bugs, and triggers the common bugs 6.3× faster. In a long time of fuzzing, we have found 5 unique Linux kernel bugs.",
        "authors": [
            {
                "email": "lanyang0908@gmail.com",
                "first": "Yang",
                "last": "Lan",
                "affiliation": "Institute for Network Science and Cyberspace of Tsinghua University",
                "contact": true
            },
            {
                "email": "di_jin@brown.edu",
                "first": "Di",
                "last": "Jin",
                "affiliation": "Brown University",
                "contact": true
            },
            {
                "email": "wz906234737@gmail.com",
                "first": "Zhun",
                "last": "Wang",
                "affiliation": "Institute for Network Science and Cyberspace of Tsinghua University",
                "contact": true
            },
            {
                "email": "twd2.me@gmail.com",
                "first": "Wende",
                "last": "Tan",
                "affiliation": "Institute for Network Science and Cyberspace of Tsinghua University",
                "contact": true
            },
            {
                "email": "mzy20@mails.tsinghua.edu.cn",
                "first": "Zheyu",
                "last": "Ma",
                "affiliation": "Institute for Network Science and Cyberspace of Tsinghua University",
                "contact": true
            },
            {
                "email": "chaoz@tsinghua.edu.cn",
                "first": "Chao",
                "last": "Zhang",
                "affiliation": "Tsinghua University",
                "contact": true
            }
        ],
        "topics": [
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "csxluo@comp.polyu.edu.hk": true,
            "mnayebi@yorku.ca": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683369786,
        "modified_at": 1683373069,
        "tags": [
            "accept#0"
        ]
    },
    {
        "object": "paper",
        "pid": 823,
        "title": "Identify and Update Test Cases when Production Code Changes: A Transformer-based Approach",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-804576cdef2aa19cf225aa70464fc95c53d365ddafb28c6c54501c4f2ad2eded",
            "timestamp": 1683367323,
            "size": 544477,
            "pages": 12
        },
        "abstract": "Software testing is one of the most essential parts of the software lifecycle and requires a substantial amount of time and effort.\r\n During the software evolution, test cases should co-evolve with the production code.\r\n However, the co-evolution of test cases often fails due to tight project schedules and other reasons.   Obsolete test cases improve the cost of software maintenance and may fail to reveal faults and even lead to future bugs.\r\n Therefore, it is essential to detect and update these obsolete test cases in time. \r\nIn this paper, we propose a novel approach\r\nCeprot (\\underline{\\textbf{C}}o-\\underline{\\textbf{E}}volution of \\underline{\\textbf{Pro}}duction-\\underline{\\textbf{T}}est Code)\r\nto identify outdated test cases and update them automatically according to changes in the production code. \r\nCeprot consists of two stages, i.e., obsolete test identification and updating.\r\nSpecifically, given a production code change and a corresponding test case, Ceprot first identifies whether the test case should be updated.\r\nIf the test is identified as obsolete, Ceprot will update it to a new version of test case.\r\nTo evaluate the effectiveness of the two stages, we construct two datasets.\r\nOur dataset focuses on method-level production code changes and updates on their obsolete test cases.\r\nThe experimental results show that Ceprot can effectively identify obsolete test cases with precision and recall of  98.3\\% and 90.0\\%, respectively.\r\nIn addition, test cases generated by Ceprot are identical to the ground truth for  12.3\\% of samples that are identified obsolete by Ceprot.\r\nWe also conduct dynamic evaluation and human evaluation to measure the effectiveness of the updated test cases by Ceprot.\r\n48.0\\% updated test cases can be compiled and the average coverage of updated cases is 34.2\\% which achieves 89\\% coverage improvement over the obsolete tests.\r\nWe believe that this study can motivate the co-evolution of production and test code.",
        "authors": [
            {
                "email": "xinghu@zju.edu.cn",
                "first": "Xing",
                "last": "Hu",
                "affiliation": "Zhejiang University",
                "contact": true
            },
            {
                "email": "liuzhuang@zju.edu.cn",
                "first": "Zhuang",
                "last": "Liu",
                "affiliation": "Zhejiang University",
                "contact": true
            },
            {
                "email": "xin.xia@acm.org",
                "first": "Xin",
                "last": "Xia",
                "affiliation": "Zhejiang University",
                "contact": true
            },
            {
                "email": "liu_zx@zju.edu.cn",
                "first": "Zhongxin",
                "last": "Liu",
                "affiliation": "Zhejiang University",
                "contact": true
            },
            {
                "email": "xutongtong9@huawei.com",
                "first": "Tongtong",
                "last": "Xu",
                "affiliation": "Huawei",
                "contact": true
            },
            {
                "email": "yangxh@zju.edu.cn",
                "first": "Xiaohu",
                "last": "Yang",
                "affiliation": "Zhejiang University",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering"
        ],
        "pc_conflicts": {
            "dposhyvanyk@gmail.com": true,
            "shang@encs.concordia.ca": true,
            "pcorina@cmu.edu": true,
            "junsun@smu.edu.sg": true,
            "chunyang.chen@monash.edu": true,
            "shaowei.wang@umanitoba.ca": true,
            "xin.xia@acm.org": "author",
            "shihan@microsoft.com": true,
            "gaocuiyun@hit.edu.cn": true,
            "ma.lei@acm.org": true,
            "lilicoding@ieee.org": true,
            "csxluo@comp.polyu.edu.hk": true,
            "saikatc@microsoft.com": true,
            "wangying@swc.neu.edu.cn": true,
            "davidlo@smu.edu.sg": true,
            "taoxie@pku.edu.cn": true,
            "tazhang@must.edu.mo": true,
            "fatemeh.fard@ubc.ca": true,
            "jieshan.chen@data61.csiro.au": true,
            "jordan.henkel@microsoft.com": true,
            "xinghu@zju.edu.cn": "author",
            "jiangjiajun@tju.edu.cn": true,
            "liu.chao@cqu.edu.cn": true,
            "minghuama@microsoft.com": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683307682,
        "modified_at": 1683527238,
        "tags": [
            "accept#0",
            "ChrisCoI#0"
        ]
    },
    {
        "object": "paper",
        "pid": 840,
        "title": "From Misuse to Mastery: Enhancing Code Generation with Knowledge-Driven AI Chaining",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-1c062c79e21246b202f503d9892f798761ebb2d2d1f80f58705d2deaa430806c",
            "timestamp": 1683360924,
            "size": 1169438,
            "pages": 12
        },
        "abstract": "Large Language Models (LLMs) have shown promising results in automatic code generation by improving coding efficiency to a certain extent. However, generating high-quality and reliable code remains a formidable task because of LLMs' lack of good programming practice, especially in exception handling. In this paper, we first conduct an empirical study and summarize three crucial challenges of LLMs in exception handling, i.e., incomplete exception handling, incorrect exception handling and abuse of try-catch.  We then try prompts with different granularities to address such challenges, finding fine-grained knowledge-driven prompts works best. Based on our empirical study, we propose a novel Knowledge-driven Prompt Chaining-based code generation approach, name KPC, which decomposes code generation into an AI chain with iterative check-rewrite steps and chains fine-grained knowledge-driven prompts to assist LLMs in considering exception-handling specifications. We evaluate our KPC-based approach with 3,079 code generation tasks extracted from the Java official API documentation. Extensive experimental results demonstrate that the KPC-based approach has considerable potential to ameliorate the quality of code generated by LLMs.  It achieves this through proficiently managing exceptions and obtaining remarkable enhancements of 109.86% and 578.57% with static evaluation methods, as well as a reduction of 18 runtime bugs in the sampled dataset with dynamic validation.",
        "authors": [
            {
                "email": "xxren@zju.edu.cn",
                "first": "Xiaoxue",
                "last": "Ren",
                "affiliation": "Zhejiang University",
                "contact": true
            },
            {
                "email": "xinyuan.ye@anu.edu.au",
                "first": "Xinyuan",
                "last": "Ye",
                "affiliation": "Australian National University",
                "contact": true
            },
            {
                "email": "dehai.zhao@data61.csiro.au",
                "first": "Dehai",
                "last": "Zhao",
                "affiliation": "CSIRO's Data61",
                "contact": true
            },
            {
                "email": "zhenchang.xing@data61.csiro.au",
                "first": "Zhenchang",
                "last": "Xing",
                "affiliation": "CSIRO's Data61 & Australian National University",
                "contact": true
            },
            {
                "email": "yangxh@zju.edu.cn",
                "first": "Xiaohu",
                "last": "Yang",
                "affiliation": "Zhejiang University",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering",
            "API design and management.",
            "Maintenance and Evolution",
            "Software Analytics"
        ],
        "pc_conflicts": {
            "junsun@smu.edu.sg": true,
            "xin.xia@acm.org": true,
            "mnayebi@yorku.ca": true,
            "davidlo@smu.edu.sg": true,
            "jieshan.chen@data61.csiro.au": true,
            "xinghu@zju.edu.cn": true,
            "liu.chao@cqu.edu.cn": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683356113,
        "modified_at": 1683361923
    },
    {
        "object": "paper",
        "pid": 863,
        "title": "What Makes Good In-context Demonstrations for Code Intelligence Tasks with LLMs?",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-eb2025eea83f1244ee7e12697c1da8e3335347c98f2ee141127bdf0049038a81",
            "timestamp": 1683373191,
            "size": 726877,
            "pages": 12
        },
        "abstract": "Pre-trained models of source code have gained widespread popularity in many code intelligence tasks. Recently, with the scaling of the model and corpus size, large language models have shown the ability of in-context learning (ICL). ICL employs task instructions and a few examples as demonstrations, and then inputs the demonstrations to the language models for making predictions. This new learning paradigm is training-free and has shown impressive performance in various natural language processing and code intelligence tasks. However, the performance of ICL heavily relies on the quality of demonstrations, e.g., the selected examples. It is important to systematically investigate how to construct a good demonstration for code-related tasks. In this paper, we empirically explore the impact of three key factors on the performance of ICL in code intelligence tasks: the selection, order, and number of demonstration examples. We conduct extensive experiments on three code intelligence tasks including code summarization, bug fixing, and program synthesis. Our experimental results demonstrate that all the above three factors dramatically impact the performance of ICL in code intelligence tasks. Additionally, we summarize our findings and provide takeaway suggestions on how to construct effective demonstrations, taking into account these three perspectives. We also show that a carefully-designed demonstration based on our findings can lead to substantial improvements over widely-used demonstration construction methods, e.g., improving BLEU-4, EM, and EM by at least 9.90%, 175.96%, and 50.81% on code summarization, bug fixing, and program synthesis, respectively.",
        "authors": [
            {
                "email": "21s051041@stu.hit.edu.cn",
                "first": "Shuzheng",
                "last": "Gao",
                "affiliation": "Harbin Institute of Technology",
                "contact": true
            },
            {
                "email": "xiamenwxc@foxmail.com",
                "first": "Xin-Cheng",
                "last": "Wen",
                "affiliation": "Harbin Institute of Technology",
                "contact": true
            },
            {
                "email": "gaocuiyun@hit.edu.cn",
                "first": "Cuiyun",
                "last": "Gao",
                "affiliation": "Harbin Institute of Technology",
                "contact": true
            },
            {
                "email": "wxwang@cse.cuhk.edu.hk",
                "first": "Wenxuan",
                "last": "Wang",
                "affiliation": "The Chinese University of Hong Kong",
                "contact": true
            },
            {
                "email": "hyzhang@cqu.edu.cn",
                "first": "Hongyu",
                "last": "Zhang",
                "affiliation": "School of Big Data and Software Engineering, Chongqing University",
                "contact": true
            },
            {
                "email": "lyu@cse.cuhk.edu.hk",
                "first": "Michael R.",
                "last": "Lyu",
                "affiliation": "The Chinese University of Hong Kong",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering"
        ],
        "pc_conflicts": {
            "rayb@cs.columbia.edu": true,
            "j.xue@unsw.edu.au": true,
            "michael@binaervarianz.de": true,
            "giovaniguizzo@gmail.com": true,
            "dolby@us.ibm.com": true,
            "nan.niu@uc.edu": true,
            "junsun@smu.edu.sg": true,
            "junjiechen@tju.edu.cn": true,
            "chunyang.chen@monash.edu": true,
            "gunel.jahangirova@kcl.ac.uk": true,
            "contact@stefanstanciulescu.com": true,
            "zp.chen@ucl.ac.uk": true,
            "shaowei.wang@umanitoba.ca": true,
            "arie.vandeursen@tudelft.nl": true,
            "lingming@illinois.edu": true,
            "tianyi@purdue.edu": true,
            "m.kechagia@ucl.ac.uk": true,
            "xin.xia@acm.org": true,
            "fengyang@nju.edu.cn": true,
            "shihan@microsoft.com": true,
            "changxu@nju.edu.cn": true,
            "senchen@tju.edu.cn": true,
            "shuaiw@cse.ust.hk": true,
            "haodan@pku.edu.cn": true,
            "xfxie@smu.edu.sg": true,
            "liuhui08@bit.edu.cn": true,
            "zhendong@fudan.edu.cn": true,
            "ding_li@pku.edu.cn": true,
            "gaocuiyun@hit.edu.cn": "author",
            "ma.lei@acm.org": true,
            "j.petke@ucl.ac.uk": true,
            "mark.harman@ucl.ac.uk": true,
            "mfazzini@umn.edu": true,
            "csxluo@comp.polyu.edu.hk": true,
            "saikatc@microsoft.com": true,
            "louyiling610@gmail.com": true,
            "fangchunrong@nju.edu.cn": true,
            "skim131@meta.com": true,
            "hongyujohn@gmail.com": "collaborator author",
            "domenico.bianculli@uni.lu": true,
            "linglingfan@nankai.edu.cn": true,
            "wangying@swc.neu.edu.cn": true,
            "bacchelli@ifi.uzh.ch": true,
            "jie.zhang@kcl.ac.uk": true,
            "rma@fe.up.pt": true,
            "cmc@nd.edu": true,
            "davidlo@smu.edu.sg": true,
            "taoxie@pku.edu.cn": true,
            "tazhang@must.edu.mo": true,
            "rebecca.moussa.18@ucl.ac.uk": true,
            "s.proksch@tudelft.nl": true,
            "g.bai@uq.edu.au": true,
            "yutian.tang@glasgow.ac.uk": true,
            "fatemeh.fard@ubc.ca": true,
            "shivakumar.pentyala@salesforce.com": true,
            "y.sui@unsw.edu.au": true,
            "jiangjiajun@tju.edu.cn": true,
            "liu.chao@cqu.edu.cn": true,
            "sahraouh@iro.umontreal.ca": true,
            "xuwang@buaa.edu.cn": true,
            "michael.vierhauser@uibk.ac.at": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683366005,
        "modified_at": 1683564638,
        "tags": [
            "accept#0",
            "FeCoI#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 864,
        "title": "ReuNify: A Step Towards Whole Program Analysis for React Native Android App",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-b3e93f4838ed2440261b368ae37d6ad4ecef99a2dfa11e37f2d9c2563a61897f",
            "timestamp": 1683374262,
            "size": 1908993,
            "pages": 12
        },
        "abstract": "React Native is a popular open-source framework for building mobile apps where JavaScript co-exists and interacts with native-side code through the React Native underlying mechanism to deliver rich native app functionalities. Yet, the current research and the state-of-the-art tools mostly overlooked the executable code from both JavaScript-side code and native-side code of one React Native app. The lack of a complete view for code in one React Native app poses a severe threat to validity in a large range of static analyses. To address this issue, we propose a new advance in the ambitious research direction to facilitate the complete code analysis for React-Native Android apps. \r\n\r\nThe REUNIFY approach presented in this paper is a significant step towards such a model. We extract and unify the code from Dalvik bytecode and JavaScript-side code into the intermediate language adopted by Soot, and further implement static analysis techniques on those intermediate languages to enable whole app analysis for React-Native Android apps. Our empirical investigations demonstrate that with REUNIFY, a significant amount of unreachable Dalvik bytecode methods called from the React Native’s JavaScript code are reached in app call-graphs, in both goodware and malware. Using REUNIFY , we were able to enable static analyzers to reveal cases where malicious code was attempting to hide sensitive or malicious behavior within the React Native code, such as stealing user data or making unauthorized network calls. REUNIFY’s model can help state-of-the-art tools achieve better precision and recall in detecting data leaks inside React Native Android apps.",
        "authors": [
            {
                "email": "yonghui.liu@monash.edu",
                "first": "Yonghui",
                "last": "Liu",
                "affiliation": "Monash University",
                "contact": true
            },
            {
                "email": "Xiao.Chen@monash.edu",
                "first": "Xiao",
                "last": "Chen",
                "affiliation": "Monash University",
                "contact": true
            },
            {
                "email": "Pei.Liu@data61.csiro.au",
                "first": "Pei",
                "last": "Liu",
                "affiliation": "Data61, CSIRO, Australia"
            },
            {
                "email": "John.Grundy@monash.edu",
                "first": "John",
                "last": "Grundy",
                "affiliation": "Monash University",
                "contact": true
            },
            {
                "email": "Chunyang.Chen@monash.edu",
                "first": "Chunyang",
                "last": "Chen",
                "affiliation": "Monash University",
                "contact": true
            },
            {
                "email": "lilicoding@ieee.org",
                "first": "Li",
                "last": "Li",
                "affiliation": "Beihang University",
                "contact": true
            }
        ],
        "topics": [
            "Software Analytics",
            "Testing and Analysis"
        ],
        "pc_conflicts": {
            "grunske@informatik.hu-berlin.de": true,
            "chunyang.chen@monash.edu": "collaborator author",
            "hkhalajzadeh@deakin.edu.au": true,
            "xin.xia@acm.org": true,
            "changxu@nju.edu.cn": true,
            "senchen@tju.edu.cn": true,
            "haodan@pku.edu.cn": true,
            "gaocuiyun@hit.edu.cn": true,
            "ma.lei@acm.org": true,
            "mfazzini@umn.edu": true,
            "lilicoding@ieee.org": "collaborator author",
            "csxluo@comp.polyu.edu.hk": true,
            "fangchunrong@nju.edu.cn": true,
            "domenico.bianculli@uni.lu": true,
            "linglingfan@nankai.edu.cn": true,
            "hoa@uow.edu.au": true,
            "rma@fe.up.pt": true,
            "mnayebi@yorku.ca": true,
            "davidlo@smu.edu.sg": true,
            "g.bai@uq.edu.au": true,
            "jieshan.chen@data61.csiro.au": true,
            "fabrizio.pastore@uni.lu": true,
            "liu.chao@cqu.edu.cn": true,
            "renzo.degiovanni@uni.lu": true,
            "xuwang@buaa.edu.cn": true,
            "mojtaba.shahin@rmit.edu.au": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683373070,
        "modified_at": 1692351935,
        "tags": [
            "accept#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 870,
        "title": "iASTMapper: An Iterative Similarity-Based Abstract Syntax Tree Mapping Algorithm",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-8f5c2ca4b6c4af5acdbd3d31d92c2f2b65e73ee6400be532dde92dd15de831ea",
            "timestamp": 1683337905,
            "size": 491273,
            "pages": 11
        },
        "abstract": "Abstract syntax tree (AST) mapping algorithms are widely used to locate the code changes in a file revision by mapping the AST nodes of the source code before and after the code changes. A recent differential testing of three state-of-the-art AST mapping algorithms, i.e., GumTree, MTDiff, and IJM, reveals that the algorithms generate inaccurate mappings for a considerable number of file revisions. We find that the inaccurate mappings could be caused by the mutual influence: the mappings of lower-level AST nodes (e.g., tokens) have impacts on the mappings of higher-level AST nodes (e.g., statements) and vice versa. This mutual influence issue is rarely considered by existing algorithms.\r\n\r\nIn this paper, we propose an algorithm, called iASTMapper, that iteratively map two ASTs based on the similarities between AST nodes. Given a file revision, we extract three types of AST nodes in different levels of program structures (i.e., tokens, statements, and inner-statements) from the ASTs of the two source code files. We first build mappings of the unchanged statements and inner-statements. Then, we use an iterative method to map the rest of the nodes without mapping. For each of the three types of nodes, we iteratively map the nodes based on their similarities measured using heuristic rules. We further use an iterative mechanism to connect the three iterative mapping processes by considering the mutual influence between the mappings of different types of nodes. Finally, a series of code edit actions are generated from the node mappings to help users understand and locate the code changes during revisions. We conduct experiments to compare iASTMapper with three baselines, i.e., GumTree, MTDiff, and IJM, by automatically evaluating 210,997 file revisions from ten Java projects. Furthermore, we manually evaluate the correctness of the code edit actions generated for 200 file revisions with 12 evaluators. The results demonstrate that iASTMapper outperforms the baselines. iASTMapper can generate shorter code edit actions by at least 1.24% than the baselines, with a high accuracy of 96.23%.",
        "authors": [
            {
                "email": "zhangn279@mail.sysu.edu.cn",
                "first": "Neng",
                "last": "Zhang",
                "affiliation": "School of Software Engineering, Sun Yat-sen University",
                "contact": true
            },
            {
                "email": "chenqd6@mail2.sysu.edu.cn",
                "first": "Qinde",
                "last": "Chen",
                "affiliation": "School of Software Engineering, Sun Yat-sen University",
                "contact": true
            },
            {
                "email": "zhzibin@mail.sysu.edu.cn",
                "first": "Zibin",
                "last": "Zheng",
                "affiliation": "School of Software Engineering, Sun Yat-sen University",
                "contact": true
            },
            {
                "email": "ying.zou@queensu.ca",
                "first": "Ying",
                "last": "Zou",
                "affiliation": "Department of Electrical and Computer Engineering, Queen's University",
                "contact": true
            }
        ],
        "topics": [
            "Software Analytics"
        ],
        "pc_conflicts": {
            "shang@encs.concordia.ca": true,
            "y.tian@queensu.ca": true,
            "shaowei.wang@umanitoba.ca": true,
            "m.kechagia@ucl.ac.uk": true,
            "xin.xia@acm.org": true,
            "foutse.khomh@polymtl.ca": true,
            "davidlo@smu.edu.sg": true,
            "xyzhang@cs.purdue.edu": true,
            "liu.chao@cqu.edu.cn": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683337905,
        "modified_at": 1683337905
    },
    {
        "object": "paper",
        "pid": 877,
        "title": "How Android Apps Break the Data Minimization Principle: An Empirical Study",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-f57de6dd4d02aa665d43b7338e19074caa17d5f2801815e84cb1e0bd48c86279",
            "timestamp": 1683366950,
            "size": 15691475,
            "pages": 12
        },
        "abstract": "The Data Minimization Principle is crucial for protecting individual privacy. However, existing Android runtime permissions do not guarantee this principle. Moreover, the lack of an automatic enforcement mechanism leads to uncertainty as to whether apps strictly comply with this principle. To bridge this gap, we conduct the first systematic empirical study on violations of the Data Minimization Principle and design new enforcement techniques to detect them. The empirical research mainly answers the prevalence of violations, the responses of administrators to violations, and the potential factors and characteristics that lead to violations, such as typical violations, app categories, and personal data types. Our study reveals that 83.5% of apps contain at least one privacy violation, with health apps being the most severe. In addition, telephony information is the most commonly leaked personal data type, accounting for 71.1%. In terms of detection techniques, we first define the violations of the Data Minimization Principle. Then we propose a novel tool GUIMind, which consists of two components: Explorer and Fidelity Checker. The former utilizes a reinforcement learning model to explore app activities and monitor access to sensitive APIs that require sensitive permissions. The latter leverages the existing tool to detect such violations. We evaluate the performance of GUIMind using 120 realistic Android apps from the Xiaomi market. The results indicate that GUIMind can achieve a detection accuracy of 96.1%, effectively accelerating our empirical study. Furthermore, we randomly select 60 non-compliant apps for reporting to the administrator, whose responses confirm the practicality of our approach.",
        "authors": [
            {
                "email": "skzhang@pku.edu.cn",
                "first": "Shaokun",
                "last": "Zhang",
                "affiliation": "Peking University",
                "contact": true
            },
            {
                "email": "lei_hanwen@stu.pku.edu.cn",
                "first": "Hanwen",
                "last": "Lei",
                "affiliation": "Peking University",
                "contact": true
            },
            {
                "email": "yuanpeng_wang@pku.edu.cn",
                "first": "Yuanpeng",
                "last": "Wang",
                "affiliation": "Peking University",
                "contact": true
            },
            {
                "email": "ding_li@pku.edu.cn",
                "first": "Ding",
                "last": "Li",
                "affiliation": "Peking University",
                "contact": true
            },
            {
                "email": "yaoguo@pku.edu.cn",
                "first": "Yao",
                "last": "Guo",
                "affiliation": "Peking University",
                "contact": true
            },
            {
                "email": "cherry@pku.edu.cn",
                "first": "Xiangqun",
                "last": "Chen",
                "affiliation": "Peking University",
                "contact": true
            }
        ],
        "topics": [
            "Software Analytics"
        ],
        "pc_conflicts": {
            "zp.chen@ucl.ac.uk": true,
            "haodan@pku.edu.cn": true,
            "xusheng.xiao@asu.edu": true,
            "ding_li@pku.edu.cn": "author",
            "lilicoding@ieee.org": true,
            "louyiling610@gmail.com": true,
            "taoxie@pku.edu.cn": true,
            "jiangjiajun@tju.edu.cn": true,
            "wangbo_cs@bjtu.edu.cn": true,
            "wangdi95@pku.edu.cn": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683366950,
        "modified_at": 1683366950,
        "tags": [
            "accept#0",
            "metareview-ready#0"
        ]
    },
    {
        "object": "paper",
        "pid": 883,
        "title": "A Comparative Study of Transformer-based Neural Text Representation Techniques on Bug Triaging",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-f73316a86dc84d82299a47dcaf3298860f9278500b877dff991f9e45c9bf50db",
            "timestamp": 1683372367,
            "size": 482511,
            "pages": 12
        },
        "abstract": "Assigning appropriate developer or component to bug reports known as bug triaging is a common task in Deep Learning for Software Engineering (DL4SE) research domain. Past studies have used the limited textual data of bug reports and train a text classification model from the scratch. This process involves a long training time and a huge computational resources. Transformer-based pre-tained neural text representation techniques like ALBERT, BERT, CodeBERT, DeBERTa, DistilBERT and RoBERTa have achieved greater performance and faster development even with limited data and resources in several natural language processing tasks including text classification. However, these techniques have not been studied for bug triaging.\r\n\r\nFor the first time, we fine-tune these techniques for bug triaging on four open source datasets and investigate their performance. Our investigation includes both quantitative and qualitative analysis of their performance. Based on our quantitative study, DeBERTa's performance is statistically significant compared to others. However, each technique possesses orthogonal behavior which find from our qualitative analysis. In addition, we study the False Positives of these techniques to understand their common failure.",
        "authors": [
            {
                "email": "akumardi@gmu.edu",
                "first": "Atish Kumar",
                "last": "Dipongkor",
                "affiliation": "George Mason University",
                "contact": true
            },
            {
                "email": "kpmoran@gmu.edu",
                "first": "Kevin",
                "last": "Moran",
                "affiliation": "George Mason University",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering",
            "Maintenance and Evolution",
            "Tools and Processes"
        ],
        "pc_conflicts": {
            "dposhyvanyk@gmail.com": true,
            "lingming@illinois.edu": true,
            "j.bell@northeastern.edu": true,
            "mfazzini@umn.edu": true,
            "mnayebi@yorku.ca": true,
            "johnsonb@gmu.edu": true,
            "cmc@nd.edu": true,
            "wei.yang@utdallas.edu": true,
            "vendomcg@miamioh.edu": true,
            "nathanacoop@gmail.com": true,
            "kpmoran@ucf.edu": "author"
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683372367,
        "modified_at": 1692208092,
        "tags": [
            "accept#0"
        ]
    },
    {
        "object": "paper",
        "pid": 894,
        "title": "Dynamic Graph Neural Networks-based Alert Link Prediction for Online Service Systems",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-8b46138e4bd6ce0d443dd01729787185df680756b1be79824cc8a8fdc842b8aa",
            "timestamp": 1683374249,
            "size": 1591469,
            "pages": 12
        },
        "abstract": "A fault in large online service systems often triggers numerous alerts due to the complex business and component dependencies among services, which is known as ``alert storm''. In a short time,  an online service system may generate a huge amount of alert data.  This poses a challenge for on-call engineers to identify alerts that are associated with a system failure for root cause analysis.  In this paper, we propose DyAlert, a dynamic graph neural network-based approach for linking alerts that might be triggered by a same fault to reduce the burden of on-call engineers in the fault analysis. Our insight is that alerts are often triggered by alert propagation when a system failure occurs, e.g., alert a would lead to the occurrence of alert $b$. Whether two alerts should be linked depends on if one alert is triggered by the propagation of the other. Leveraging this insight, we design a dynamic graph (namely Alert-Metric Dynamic Graph) that describes the propagation process of alerts. Based on the dynamic graph, we train a neural network-based model to predict alert links.  We evaluate DyAlert with real-world data collected from an online service system running 85 business units and about 30,000 different services in a large enterprise. The results show that DyAlert is effective in predicting alert links and it outperforms the state-of-the-art approaches with an average increase of 0.259 in F1-score.",
        "authors": [
            {
                "email": "yiruchen21@m.fudan.edu.cn",
                "first": "Yiru",
                "last": "Chen",
                "affiliation": "Fudan University",
                "contact": true
            },
            {
                "email": "cxzhang20@fudan.edu.cn",
                "first": "Chenxi",
                "last": "Zhang",
                "affiliation": "Fudan University",
                "contact": true
            },
            {
                "email": "zhendong@fudan.edu.cn",
                "first": "Zhen",
                "last": "Dong",
                "affiliation": "Fudan University",
                "contact": true
            },
            {
                "email": "dingyu.ydy@alibaba-inc.com",
                "first": "Dingyu",
                "last": "Yang",
                "affiliation": "Alibaba Group",
                "contact": true
            },
            {
                "email": "pengxin@fudan.edu.cn",
                "first": "Xin",
                "last": "Peng",
                "affiliation": "Fudan University",
                "contact": true
            },
            {
                "email": "jiayu.ojy@alibaba-inc.com",
                "first": "Jiayu",
                "last": "Ou",
                "affiliation": "Alibaba Group",
                "contact": true
            },
            {
                "email": "21212010043@m.fudan.edu.cn",
                "first": "Hong",
                "last": "Yang",
                "affiliation": "Fudan University",
                "contact": true
            },
            {
                "email": "zheshun.wzs@alibaba-inc.com",
                "first": "Zheshun",
                "last": "Wu",
                "affiliation": "Alibaba Group",
                "contact": true
            },
            {
                "email": "mikong.qxj@alipay.com",
                "first": "Xiaojun",
                "last": "Qu",
                "affiliation": "Alibaba Group",
                "contact": true
            },
            {
                "email": "jianhao@taobao.com",
                "first": "Wei",
                "last": "Li",
                "affiliation": "Alibaba Group",
                "contact": true
            }
        ],
        "topics": [
            "AI and Software Engineering"
        ],
        "pc_conflicts": {
            "junsun@smu.edu.sg": true,
            "zp.chen@ucl.ac.uk": true,
            "lxiao6@stevens.edu": true,
            "xin.xia@acm.org": true,
            "zhendong@fudan.edu.cn": "author",
            "louyiling610@gmail.com": true,
            "davidlo@smu.edu.sg": true,
            "taoxie@pku.edu.cn": true,
            "tsu@sei.ecnu.edu.cn": true,
            "mengguozhu@iie.ac.cn": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683374545,
        "modified_at": 1683374753,
        "tags": [
            "accept#0"
        ]
    },
    {
        "object": "paper",
        "pid": 897,
        "title": "LogOnline: A Semi-supervised Log-based Anomaly Detector Aided with Online Learning Mechanism",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-8fec0944b12dbaa94d900f7578440a4a3c42177c4b6c0db94c23b47ae3955234",
            "timestamp": 1683373526,
            "size": 1212258,
            "pages": 11
        },
        "abstract": "Logs are prevalent in modern cloud systems and serve as a valuable source of information for system maintenance. Over the years, a lot of research and industrial efforts have been devoted to the field of log-based anomaly detection. Through analyzing the limitations of existing approaches, we find that most of them still suffer from practical issues and are thus hard to be applied in real-world scenarios. For example, supervised approaches are dependent on a large amount of labeled log data for training, which can require much manual labeling effort. Besides, log instability, which is a pervasive issue in real-world systems, poses great challenge to existing methods, especially under the presence of many dissimilar new log events. To overcome these problems, we propose LogOnline, which is a semi-supervised anomaly detector aided with online learning mechanism. The semi-supervised nature of LogOnline makes it able to get rid of the erroneous and time-consuming manual labeling of log data. Based on our proposed online learning mechanism, LogOnline can learn the normal sequence patterns continuously as new log sequences emerge, thus staying robust to unstable log data. Unlike previous works, the proposed online learning mechanism requires no labeled log data nor human intervention in the process. We have evaluated LogOnline on two widely-used public datasets, and the experimental results demonstrate the effectiveness of LogOnline. In particular, LogOnline achieves a comparable result with the studied supervised approaches, outperforming all semi-supervised counterparts. When the log instability issue is more common, LogOnline exhibits the best performance over all compared approaches, further confirming its practicability",
        "authors": [
            {
                "email": "wxh20@mails.tsinghua.edu.cn",
                "first": "Xuheng",
                "last": "Wang",
                "affiliation": "Tsinghua University",
                "contact": true
            },
            {
                "email": "jxsong@tsinghua.edu.cn",
                "first": "Jiaxing",
                "last": "Song",
                "affiliation": "Tsinghua University",
                "contact": true
            },
            {
                "email": "xuzhang2@microsoft.com",
                "first": "Xu",
                "last": "Zhang",
                "affiliation": "Microsoft, Beijing, China",
                "contact": true
            },
            {
                "email": "tangjs@sjtu.edu.cn",
                "first": "Junshu",
                "last": "Tang",
                "affiliation": "Shanghai Jiao Tong University",
                "contact": true
            },
            {
                "email": "gao.weihe@outlook.com",
                "first": "Weihe",
                "last": "Gao",
                "affiliation": "Tsinghua University",
                "contact": true
            },
            {
                "email": "qlin@microsoft.com",
                "first": "Qingwei",
                "last": "Lin",
                "affiliation": "Microsoft, Beijing, China",
                "contact": true
            }
        ],
        "supplementary_material": {
            "mimetype": "application\/zip",
            "hash": "sha2-97e60a908acdb27f2dd5982f8e17747fb0673e669469ff1715b228657c114d0b",
            "timestamp": 1683372832,
            "size": 402286389,
            "filename": "LogOnline.zip"
        },
        "topics": [
            "AI and Software Engineering",
            "Maintenance and Evolution"
        ],
        "pc_conflicts": {
            "shang@encs.concordia.ca": true,
            "junjiechen@tju.edu.cn": true,
            "xin.xia@acm.org": true,
            "shihan@microsoft.com": true,
            "haodan@pku.edu.cn": true,
            "sfakhoury@microsoft.com": true,
            "saikatc@microsoft.com": true,
            "hongyujohn@gmail.com": true,
            "mnayebi@yorku.ca": true,
            "taoxie@pku.edu.cn": true,
            "zhonghao@sjtu.edu.cn": true,
            "jordan.henkel@microsoft.com": true,
            "jiangjiajun@tju.edu.cn": true,
            "minghuama@microsoft.com": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683346928,
        "modified_at": 1683527367,
        "tags": [
            "ChrisCoI#0"
        ]
    },
    {
        "object": "paper",
        "pid": 921,
        "title": "Cell2Doc: ML Pipeline for Generating Documentation in Computational Notebooks",
        "submission": {
            "mimetype": "application\/pdf",
            "hash": "sha2-9d985fd84848f2111eb73fb4e7733722fdf68e36666c500052ef958a6ae0e18c",
            "timestamp": 1683374914,
            "size": 389339,
            "pages": 12
        },
        "abstract": "Computational notebooks have become the go-to way for solving data-science problems.\r\nWhile they are designed to combine code and documentation, prior work shows that documentation is largely ignored by the developers because of the manual effort. Automated documentation generation can help, but existing techniques fail to capture algorithmic details and developers often end up editing the generated text to provide more explanation and sub-steps.\r\n\r\nThis paper proposes a novel machine-learning pipeline, Cell2Doc, for code cell documentation in Python data science notebooks. Our approach works by identifying different logical contexts within a code cell, generating documentation for them separately, and finally combining them to arrive at the documentation for the entire code cell. Cell2Doc takes advantage of the capabilities of existing pre-trained language models and improves their efficiency for code cell documentation. We also provide a new benchmark dataset for this task, along with a data-preprocessing pipeline that can be used to create new datasets. We also investigate an appropriate input representation for this task. Our automated evaluation suggests that our best input representation improves the pre-trained model's performance by 2.5x on average. Further, Cell2Doc achieves 1.33x improvement during human evaluation in terms of correctness, informativeness, and readability against the corresponding standalone pre-trained model.",
        "authors": [
            {
                "email": "cs21mtech12001@iith.ac.in",
                "first": "Tamal",
                "last": "Mondal",
                "affiliation": "Indian Institute of Technology Hyderabad",
                "contact": true
            },
            {
                "email": "scott.barnett@deakin.edu.au",
                "first": "Scott",
                "last": "Barnett",
                "affiliation": "Deakin University",
                "contact": true
            },
            {
                "email": "akashl@microsoft.com",
                "first": "Akash",
                "last": "Lal",
                "affiliation": "Microsoft Research",
                "contact": true
            },
            {
                "email": "jyothiv@cse.iith.ac.in",
                "first": "Jyothi",
                "last": "Vedurada",
                "affiliation": "IIT Hyderabad",
                "contact": true
            }
        ],
        "supplementary_material": {
            "mimetype": "application\/zip",
            "hash": "sha2-1971d515cc93f7da660b95ff71ca634d0ae400ee61e904bafeafd383e931a929",
            "timestamp": 1683377455,
            "size": 376257,
            "filename": "ASE Supplementary Repository.zip"
        },
        "topics": [
            "AI and Software Engineering",
            "Maintenance and Evolution",
            "Tools and Processes"
        ],
        "pc_conflicts": {
            "hkhalajzadeh@deakin.edu.au": true,
            "xin.xia@acm.org": true,
            "shihan@microsoft.com": true,
            "sfakhoury@microsoft.com": true,
            "saikatc@microsoft.com": true,
            "mnayebi@yorku.ca": true,
            "jordan.henkel@microsoft.com": true,
            "minghuama@microsoft.com": true
        },
        "decision": "Accepted",
        "status": "accept",
        "submitted": true,
        "submitted_at": 1683373621,
        "modified_at": 1683527411,
        "tags": [
            "accept#0",
            "ChrisCoI#0"
        ]
    }
]
