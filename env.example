# =============================================================================
# LLM Provider Configuration
# =============================================================================
# Choose your LLM provider: 'azure' for Azure OpenAI or 'openai' for OpenAI
# This setting determines which configuration section below will be used.
#
# LLM_PROVIDER=azure
# LLM_PROVIDER=openai


# =============================================================================
# Azure OpenAI Configuration
# =============================================================================
# Use these settings if LLM_PROVIDER=azure
#
# Azure OpenAI uses "deployments" - you deploy a model (like GPT-4) and give it
# a deployment name. The deployment name is what you reference in API calls.
#
# Find these values in Azure Portal > Azure OpenAI Resource > Keys and Endpoint

# Your Azure OpenAI endpoint URL
# Example: https://your-resource-name.openai.azure.com/
# AZURE_OPENAI_ENDPOINT=https://your-endpoint.cognitiveservices.azure.com/

# Your Azure OpenAI API key (Key 1 or Key 2 from Azure Portal)
# AZURE_OPENAI_KEY=your-api-key-here

# Azure OpenAI API version (check Azure docs for latest version)
# Common versions: 2024-12-01-preview, 2024-08-01-preview
# AZURE_OPENAI_API_VERSION=2024-12-01-preview

# Deployment name for tag generation (typically a more powerful model like GPT-5)
# This is the name YOU chose when deploying the model in Azure Portal
# Example: If you deployed gpt-5 and named it "gpt-5-production", use that name
# AZURE_OPENAI_TAG_GENERATION_DEPLOYMENT=gpt-5-production

# Deployment name for tag assignment (can be a smaller model like GPT-5-mini)
# This task runs once per paper, so a faster/cheaper model may be preferable
# AZURE_OPENAI_TAG_ASSIGNMENT_DEPLOYMENT=gpt-5-mini-production

# Deployment name for session title generation (can be a smaller model)
# This task runs once per session, so a faster/cheaper model is often sufficient
# AZURE_OPENAI_TITLE_GENERATION_DEPLOYMENT=gpt-5-mini-production

# =============================================================================
# OpenAI Configuration
# =============================================================================
# Use these settings if LLM_PROVIDER=openai
#
# OpenAI uses model names directly (no deployment step required).
# Find your API key at: https://platform.openai.com/api-keys

# Your OpenAI API key
# OPENAI_API_KEY=sk-proj-...your-key-here...

# OpenAI API version (optional, defaults to latest if not specified)
# OPENAI_API_VERSION=v1

# Model for tag generation (recommend a more powerful model like gpt-5)
# Tag generation analyzes the entire corpus to identify themes
# Common options: gpt-5, gpt-5-mini
# OPENAI_TAG_GENERATION_MODEL=gpt-5

# Model for tag assignment (can use a smaller/faster model like gpt-5-mini)
# Tag assignment runs once per paper, so speed/cost matters
# Common options: gpt-5, gpt-5-mini
# OPENAI_TAG_ASSIGNMENT_MODEL=gpt-5-mini

# Model for session title generation (can use a smaller/faster model)
# Title generation runs once per session
# Common options: gpt-5, gpt-5-mini
# OPENAI_TITLE_GENERATION_MODEL=gpt-5-mini

# =============================================================================
# Configuration Tips
# =============================================================================
#
# Cost Optimization:
#   - Use powerful models (GPT-5) for tag generation (runs 1-5 times)
#   - Use cheaper models (GPT-5-mini) for tag assignment (runs per paper)
#   - Use cheaper models (GPT-5-mini) for title generation (runs per session)
#
# Quality vs Speed:
#   - Tag generation quality is critical - use your best model
#   - Tag assignment can use a smaller model if tags are well-defined
#   - Title generation benefits from a good model but mini versions work well
#
#
# Testing Your Configuration:
#   After setting up your .env file, test it by running:
#     python scripts/llm_client.py
#   This will validate your configuration and show which provider/models are configured.
#
